{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10daae06",
   "metadata": {},
   "source": [
    "# Travel insurance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78df287",
   "metadata": {},
   "source": [
    "# Setting up Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309d637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e748c8",
   "metadata": {},
   "source": [
    "# Data \n",
    "\n",
    "Source: [Travel insurance predictions](https://www.kaggle.com/datasets/tejashvi14/travel-insurance-prediction-data)\n",
    "\n",
    "Upload and clean dataset. It was checked from the source the data was clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cd39363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Employment Type</th>\n",
       "      <th>GraduateOrNot</th>\n",
       "      <th>AnnualIncome</th>\n",
       "      <th>FamilyMembers</th>\n",
       "      <th>ChronicDiseases</th>\n",
       "      <th>FrequentFlyer</th>\n",
       "      <th>EverTravelledAbroad</th>\n",
       "      <th>TravelInsurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>Government Sector</td>\n",
       "      <td>Yes</td>\n",
       "      <td>400000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>Private Sector/Self Employed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1250000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>Private Sector/Self Employed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>Private Sector/Self Employed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>700000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>Private Sector/Self Employed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>700000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Age               Employment Type GraduateOrNot  AnnualIncome  \\\n",
       "0           0   31             Government Sector           Yes        400000   \n",
       "1           1   31  Private Sector/Self Employed           Yes       1250000   \n",
       "2           2   34  Private Sector/Self Employed           Yes        500000   \n",
       "3           3   28  Private Sector/Self Employed           Yes        700000   \n",
       "4           4   28  Private Sector/Self Employed           Yes        700000   \n",
       "\n",
       "   FamilyMembers  ChronicDiseases FrequentFlyer EverTravelledAbroad  \\\n",
       "0              6                1            No                  No   \n",
       "1              7                0            No                  No   \n",
       "2              4                1            No                  No   \n",
       "3              3                1            No                  No   \n",
       "4              8                1           Yes                  No   \n",
       "\n",
       "   TravelInsurance  \n",
       "0                0  \n",
       "1                0  \n",
       "2                1  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"TravelInsurancePrediction.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33d20fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Age', 'Employment Type', 'GraduateOrNot', 'AnnualIncome',\n",
       "       'FamilyMembers', 'ChronicDiseases', 'FrequentFlyer',\n",
       "       'EverTravelledAbroad', 'TravelInsurance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e892df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Employment Type</th>\n",
       "      <th>AnnualIncome</th>\n",
       "      <th>FamilyMembers</th>\n",
       "      <th>ChronicDiseases</th>\n",
       "      <th>FrequentFlyer</th>\n",
       "      <th>EverTravelledAbroad</th>\n",
       "      <th>TravelInsurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>400000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1250000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>700000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>700000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Employment Type  AnnualIncome  FamilyMembers  ChronicDiseases  \\\n",
       "0   31                2        400000              6                1   \n",
       "1   31                1       1250000              7                0   \n",
       "2   34                1        500000              4                1   \n",
       "3   28                1        700000              3                1   \n",
       "4   28                1        700000              8                1   \n",
       "\n",
       "   FrequentFlyer  EverTravelledAbroad  TravelInsurance  \n",
       "0              1                    1                0  \n",
       "1              1                    1                0  \n",
       "2              1                    1                1  \n",
       "3              1                    1                0  \n",
       "4              2                    1                0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop([\"Unnamed: 0\",\"GraduateOrNot\"], axis = 1)\n",
    "#data['GraduateOrNot'] = data['GraduateOrNot'].map({'Yes': 2, 'No': 1})\n",
    "data['FrequentFlyer']  = data['FrequentFlyer'].map({'Yes': 2, 'No': 1})\n",
    "\n",
    "data['EverTravelledAbroad']  = data['EverTravelledAbroad'].map({'Yes': 2, 'No': 1})\n",
    "#data[\"TravelInsurance\"]  = data[\"TravelInsurance\"].map({1: 2, 0: 1})\n",
    "data['Employment Type']  = data['Employment Type'].map({'Government Sector': 2, \n",
    "                                                        'Private Sector/Self Employed': 1})\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00c09329",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu  = np.mean(data['AnnualIncome'])\n",
    "std = np.std(data['AnnualIncome'])\n",
    "data['AnnualIncome'] =(data['AnnualIncome'] - mu)/std\n",
    "                                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29501e88",
   "metadata": {},
   "source": [
    "# Prepare data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa192a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.TravelInsurance.values\n",
    "X = data.drop([\"TravelInsurance\"], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.40, \n",
    "                                                    random_state = 42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, \n",
    "                                                    test_size = 0.40, \n",
    "                                                    random_state = 42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85e98d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Employment Type', 'AnnualIncome', 'FamilyMembers',\n",
       "       'ChronicDiseases', 'FrequentFlyer', 'EverTravelledAbroad'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0889d0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1442    1\n",
       "957     1\n",
       "820     1\n",
       "1419    1\n",
       "1752    1\n",
       "       ..\n",
       "1017    1\n",
       "702     1\n",
       "20      1\n",
       "1783    1\n",
       "387     1\n",
       "Name: EverTravelledAbroad, Length: 715, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.EverTravelledAbroad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db2c8dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Employment Type</th>\n",
       "      <th>AnnualIncome</th>\n",
       "      <th>FamilyMembers</th>\n",
       "      <th>ChronicDiseases</th>\n",
       "      <th>FrequentFlyer</th>\n",
       "      <th>EverTravelledAbroad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.148641</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.148641</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.576591</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0.311171</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.148641</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Employment Type  AnnualIncome  FamilyMembers  ChronicDiseases  \\\n",
       "1442   26                1     -1.148641              2                0   \n",
       "957    28                1     -1.148641              5                1   \n",
       "820    25                1      0.576591              4                0   \n",
       "1419   27                2      0.311171              5                0   \n",
       "1752   26                2     -1.148641              5                1   \n",
       "\n",
       "      FrequentFlyer  EverTravelledAbroad  \n",
       "1442              1                    1  \n",
       "957               1                    1  \n",
       "820               1                    1  \n",
       "1419              1                    1  \n",
       "1752              1                    1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88b3de99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Employment Type</th>\n",
       "      <th>AnnualIncome</th>\n",
       "      <th>FamilyMembers</th>\n",
       "      <th>ChronicDiseases</th>\n",
       "      <th>FrequentFlyer</th>\n",
       "      <th>EverTravelledAbroad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.148641</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842012</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>1.505563</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.709302</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.709302</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Employment Type  AnnualIncome  FamilyMembers  ChronicDiseases  \\\n",
       "1426   26                2     -1.148641              6                1   \n",
       "144    31                1      0.842012              4                0   \n",
       "1230   31                2      1.505563              6                0   \n",
       "1206   29                1      0.709302              3                0   \n",
       "1560   28                1      0.709302              4                0   \n",
       "\n",
       "      FrequentFlyer  EverTravelledAbroad  \n",
       "1426              1                    1  \n",
       "144               1                    1  \n",
       "1230              2                    2  \n",
       "1206              1                    1  \n",
       "1560              1                    1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4f457c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Employment Type</th>\n",
       "      <th>AnnualIncome</th>\n",
       "      <th>FamilyMembers</th>\n",
       "      <th>ChronicDiseases</th>\n",
       "      <th>FrequentFlyer</th>\n",
       "      <th>EverTravelledAbroad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.485090</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1.240142</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.709302</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.414061</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1.505563</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Employment Type  AnnualIncome  FamilyMembers  ChronicDiseases  \\\n",
       "212    28                1     -0.485090              5                1   \n",
       "1517   26                1      1.240142              4                1   \n",
       "785    29                1      0.709302              7                0   \n",
       "1175   33                2     -1.414061              4                1   \n",
       "1760   34                1      1.505563              3                0   \n",
       "\n",
       "      FrequentFlyer  EverTravelledAbroad  \n",
       "212               1                    1  \n",
       "1517              1                    2  \n",
       "785               1                    2  \n",
       "1175              1                    1  \n",
       "1760              2                    2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b573ab8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "715"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "500f0115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "477"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9ad70dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "795"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158eb86",
   "metadata": {},
   "source": [
    "# Create, compile, and train a model\n",
    "8 columns = 8 neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa5163c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 7)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               2048      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,305\n",
      "Trainable params: 2,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(7,)),\n",
    "    tf.keras.layers.Dense(256, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d5b342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c86e9441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "23/23 [==============================] - 1s 10ms/step - loss: 0.6854 - accuracy: 0.6000 - val_loss: 0.6454 - val_accuracy: 0.6583\n",
      "Epoch 2/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.6476 - val_loss: 0.6435 - val_accuracy: 0.6583\n",
      "Epoch 3/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.6476 - val_loss: 0.6466 - val_accuracy: 0.6583\n",
      "Epoch 4/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6517 - accuracy: 0.6476 - val_loss: 0.6462 - val_accuracy: 0.6583\n",
      "Epoch 5/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6485 - accuracy: 0.6476 - val_loss: 0.6543 - val_accuracy: 0.6583\n",
      "Epoch 6/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6481 - accuracy: 0.6476 - val_loss: 0.6382 - val_accuracy: 0.6583\n",
      "Epoch 7/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.6476 - val_loss: 0.6380 - val_accuracy: 0.6583\n",
      "Epoch 8/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.6476 - val_loss: 0.6405 - val_accuracy: 0.6583\n",
      "Epoch 9/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.6476 - val_loss: 0.6348 - val_accuracy: 0.6583\n",
      "Epoch 10/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6448 - accuracy: 0.6476 - val_loss: 0.6337 - val_accuracy: 0.6583\n",
      "Epoch 11/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6410 - accuracy: 0.6476 - val_loss: 0.6330 - val_accuracy: 0.6583\n",
      "Epoch 12/1000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.6476 - val_loss: 0.6404 - val_accuracy: 0.6583\n",
      "Epoch 13/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6424 - accuracy: 0.6476 - val_loss: 0.6383 - val_accuracy: 0.6583\n",
      "Epoch 14/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6397 - accuracy: 0.6476 - val_loss: 0.6328 - val_accuracy: 0.6583\n",
      "Epoch 15/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.6476 - val_loss: 0.6297 - val_accuracy: 0.6583\n",
      "Epoch 16/1000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.6476 - val_loss: 0.6277 - val_accuracy: 0.6583\n",
      "Epoch 17/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.6476 - val_loss: 0.6272 - val_accuracy: 0.6583\n",
      "Epoch 18/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6476 - val_loss: 0.6264 - val_accuracy: 0.6583\n",
      "Epoch 19/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6302 - accuracy: 0.6476 - val_loss: 0.6248 - val_accuracy: 0.6583\n",
      "Epoch 20/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.6476 - val_loss: 0.6338 - val_accuracy: 0.6583\n",
      "Epoch 21/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.6490 - val_loss: 0.6227 - val_accuracy: 0.6583\n",
      "Epoch 22/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.6476 - val_loss: 0.6231 - val_accuracy: 0.6583\n",
      "Epoch 23/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6294 - accuracy: 0.6476 - val_loss: 0.6213 - val_accuracy: 0.6583\n",
      "Epoch 24/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.6476 - val_loss: 0.6300 - val_accuracy: 0.6583\n",
      "Epoch 25/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.6476 - val_loss: 0.6303 - val_accuracy: 0.6583\n",
      "Epoch 26/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.6462 - val_loss: 0.6196 - val_accuracy: 0.6583\n",
      "Epoch 27/1000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.6476 - val_loss: 0.6179 - val_accuracy: 0.6583\n",
      "Epoch 28/1000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.6476 - val_loss: 0.6184 - val_accuracy: 0.6583\n",
      "Epoch 29/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.6503 - val_loss: 0.6152 - val_accuracy: 0.6583\n",
      "Epoch 30/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.6490 - val_loss: 0.6158 - val_accuracy: 0.6583\n",
      "Epoch 31/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.6462 - val_loss: 0.6181 - val_accuracy: 0.6583\n",
      "Epoch 32/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6176 - accuracy: 0.6476 - val_loss: 0.6195 - val_accuracy: 0.6583\n",
      "Epoch 33/1000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6184 - accuracy: 0.6490 - val_loss: 0.6147 - val_accuracy: 0.6583\n",
      "Epoch 34/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6205 - accuracy: 0.6476 - val_loss: 0.6115 - val_accuracy: 0.6583\n",
      "Epoch 35/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6199 - accuracy: 0.6476 - val_loss: 0.6102 - val_accuracy: 0.6583\n",
      "Epoch 36/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6204 - accuracy: 0.6517 - val_loss: 0.6358 - val_accuracy: 0.7820\n",
      "Epoch 37/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.6517 - val_loss: 0.6313 - val_accuracy: 0.7757\n",
      "Epoch 38/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.6503 - val_loss: 0.6148 - val_accuracy: 0.6667\n",
      "Epoch 39/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6191 - accuracy: 0.6531 - val_loss: 0.6058 - val_accuracy: 0.6583\n",
      "Epoch 40/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6145 - accuracy: 0.6517 - val_loss: 0.6087 - val_accuracy: 0.6604\n",
      "Epoch 41/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6172 - accuracy: 0.6490 - val_loss: 0.6038 - val_accuracy: 0.6583\n",
      "Epoch 42/1000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.6629 - val_loss: 0.6030 - val_accuracy: 0.6583\n",
      "Epoch 43/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.6476 - val_loss: 0.6022 - val_accuracy: 0.6583\n",
      "Epoch 44/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6122 - accuracy: 0.6559 - val_loss: 0.6011 - val_accuracy: 0.6583\n",
      "Epoch 45/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6448 - val_loss: 0.6033 - val_accuracy: 0.6604\n",
      "Epoch 46/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6103 - accuracy: 0.6503 - val_loss: 0.6039 - val_accuracy: 0.6771\n",
      "Epoch 47/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.6629 - val_loss: 0.6030 - val_accuracy: 0.6792\n",
      "Epoch 48/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.6587 - val_loss: 0.6167 - val_accuracy: 0.6583\n",
      "Epoch 49/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6060 - accuracy: 0.6545 - val_loss: 0.6138 - val_accuracy: 0.7820\n",
      "Epoch 50/1000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.6629 - val_loss: 0.5961 - val_accuracy: 0.6604\n",
      "Epoch 51/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6038 - accuracy: 0.6629 - val_loss: 0.5974 - val_accuracy: 0.6792\n",
      "Epoch 52/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6009 - accuracy: 0.6643 - val_loss: 0.5986 - val_accuracy: 0.6583\n",
      "Epoch 53/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5989 - accuracy: 0.6615 - val_loss: 0.5980 - val_accuracy: 0.6583\n",
      "Epoch 54/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6002 - accuracy: 0.6601 - val_loss: 0.5998 - val_accuracy: 0.6583\n",
      "Epoch 55/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6034 - accuracy: 0.6629 - val_loss: 0.6031 - val_accuracy: 0.7736\n",
      "Epoch 56/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.6755 - val_loss: 0.5951 - val_accuracy: 0.6583\n",
      "Epoch 57/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5958 - accuracy: 0.6587 - val_loss: 0.6405 - val_accuracy: 0.6436\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5977 - accuracy: 0.6783 - val_loss: 0.5888 - val_accuracy: 0.6625\n",
      "Epoch 59/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.6727 - val_loss: 0.5882 - val_accuracy: 0.6583\n",
      "Epoch 60/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5946 - accuracy: 0.6741 - val_loss: 0.5942 - val_accuracy: 0.6583\n",
      "Epoch 61/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5930 - accuracy: 0.6839 - val_loss: 0.5921 - val_accuracy: 0.6583\n",
      "Epoch 62/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.6699 - val_loss: 0.5856 - val_accuracy: 0.6813\n",
      "Epoch 63/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5905 - accuracy: 0.6937 - val_loss: 0.5848 - val_accuracy: 0.6876\n",
      "Epoch 64/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5940 - accuracy: 0.6741 - val_loss: 0.5952 - val_accuracy: 0.7799\n",
      "Epoch 65/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5901 - accuracy: 0.6881 - val_loss: 0.6138 - val_accuracy: 0.7379\n",
      "Epoch 66/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5899 - accuracy: 0.7021 - val_loss: 0.6027 - val_accuracy: 0.7757\n",
      "Epoch 67/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5902 - accuracy: 0.7007 - val_loss: 0.5848 - val_accuracy: 0.7505\n",
      "Epoch 68/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.6909 - val_loss: 0.5875 - val_accuracy: 0.7841\n",
      "Epoch 69/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.7105 - val_loss: 0.5818 - val_accuracy: 0.7484\n",
      "Epoch 70/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5881 - accuracy: 0.7217 - val_loss: 0.5825 - val_accuracy: 0.6604\n",
      "Epoch 71/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.6853 - val_loss: 0.5808 - val_accuracy: 0.6625\n",
      "Epoch 72/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5861 - accuracy: 0.6853 - val_loss: 0.5785 - val_accuracy: 0.7296\n",
      "Epoch 73/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5859 - accuracy: 0.6979 - val_loss: 0.5772 - val_accuracy: 0.6897\n",
      "Epoch 74/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.7035 - val_loss: 0.5782 - val_accuracy: 0.6667\n",
      "Epoch 75/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.7063 - val_loss: 0.5913 - val_accuracy: 0.6583\n",
      "Epoch 76/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5909 - accuracy: 0.6951 - val_loss: 0.5748 - val_accuracy: 0.7128\n",
      "Epoch 77/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5865 - accuracy: 0.7063 - val_loss: 0.5744 - val_accuracy: 0.7065\n",
      "Epoch 78/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.7035 - val_loss: 0.5808 - val_accuracy: 0.7925\n",
      "Epoch 79/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5783 - accuracy: 0.7259 - val_loss: 0.5752 - val_accuracy: 0.6771\n",
      "Epoch 80/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5810 - accuracy: 0.7035 - val_loss: 0.5749 - val_accuracy: 0.7841\n",
      "Epoch 81/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5806 - accuracy: 0.7147 - val_loss: 0.5716 - val_accuracy: 0.7170\n",
      "Epoch 82/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.7413 - val_loss: 0.5721 - val_accuracy: 0.7044\n",
      "Epoch 83/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5817 - accuracy: 0.7007 - val_loss: 0.5725 - val_accuracy: 0.6897\n",
      "Epoch 84/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5804 - accuracy: 0.7119 - val_loss: 0.5697 - val_accuracy: 0.7547\n",
      "Epoch 85/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.7287 - val_loss: 0.5691 - val_accuracy: 0.7547\n",
      "Epoch 86/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7357 - val_loss: 0.5763 - val_accuracy: 0.6667\n",
      "Epoch 87/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5705 - accuracy: 0.7063 - val_loss: 0.6221 - val_accuracy: 0.6352\n",
      "Epoch 88/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.7357 - val_loss: 0.5674 - val_accuracy: 0.7736\n",
      "Epoch 89/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5746 - accuracy: 0.7259 - val_loss: 0.5664 - val_accuracy: 0.7547\n",
      "Epoch 90/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.7357 - val_loss: 0.5755 - val_accuracy: 0.6667\n",
      "Epoch 91/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5712 - accuracy: 0.7175 - val_loss: 0.5663 - val_accuracy: 0.7275\n",
      "Epoch 92/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.7371 - val_loss: 0.5674 - val_accuracy: 0.7128\n",
      "Epoch 93/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.7399 - val_loss: 0.5709 - val_accuracy: 0.6897\n",
      "Epoch 94/1000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.7063 - val_loss: 0.5759 - val_accuracy: 0.6667\n",
      "Epoch 95/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.7245 - val_loss: 0.5631 - val_accuracy: 0.7589\n",
      "Epoch 96/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.7385 - val_loss: 0.5647 - val_accuracy: 0.7275\n",
      "Epoch 97/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.7329 - val_loss: 0.5672 - val_accuracy: 0.7904\n",
      "Epoch 98/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.7469 - val_loss: 0.5615 - val_accuracy: 0.7841\n",
      "Epoch 99/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.7427 - val_loss: 0.5628 - val_accuracy: 0.7463\n",
      "Epoch 100/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5710 - accuracy: 0.7287 - val_loss: 0.5609 - val_accuracy: 0.7799\n",
      "Epoch 101/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5628 - accuracy: 0.7357 - val_loss: 0.5872 - val_accuracy: 0.7065\n",
      "Epoch 102/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5681 - accuracy: 0.7343 - val_loss: 0.5697 - val_accuracy: 0.7778\n",
      "Epoch 103/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7636 - val_loss: 0.5597 - val_accuracy: 0.7631\n",
      "Epoch 104/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.7385 - val_loss: 0.5605 - val_accuracy: 0.7966\n",
      "Epoch 105/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7455 - val_loss: 0.5977 - val_accuracy: 0.6709\n",
      "Epoch 106/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5730 - accuracy: 0.7441 - val_loss: 0.5891 - val_accuracy: 0.6625\n",
      "Epoch 107/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.7329 - val_loss: 0.5768 - val_accuracy: 0.6751\n",
      "Epoch 108/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.7273 - val_loss: 0.5603 - val_accuracy: 0.7966\n",
      "Epoch 109/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5617 - accuracy: 0.7469 - val_loss: 0.5861 - val_accuracy: 0.6939\n",
      "Epoch 110/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.7371 - val_loss: 0.5608 - val_accuracy: 0.7904\n",
      "Epoch 111/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.7524 - val_loss: 0.5599 - val_accuracy: 0.7883\n",
      "Epoch 112/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5628 - accuracy: 0.7497 - val_loss: 0.5588 - val_accuracy: 0.7862\n",
      "Epoch 113/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5638 - accuracy: 0.7524 - val_loss: 0.5589 - val_accuracy: 0.7505\n",
      "Epoch 114/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5638 - accuracy: 0.7524 - val_loss: 0.5591 - val_accuracy: 0.7925\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.7455 - val_loss: 0.5575 - val_accuracy: 0.7883\n",
      "Epoch 116/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5590 - accuracy: 0.7399 - val_loss: 0.5602 - val_accuracy: 0.7442\n",
      "Epoch 117/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5617 - accuracy: 0.7552 - val_loss: 0.5631 - val_accuracy: 0.7379\n",
      "Epoch 118/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.7469 - val_loss: 0.5564 - val_accuracy: 0.7673\n",
      "Epoch 119/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5554 - accuracy: 0.7580 - val_loss: 0.5628 - val_accuracy: 0.7463\n",
      "Epoch 120/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5591 - accuracy: 0.7427 - val_loss: 0.5763 - val_accuracy: 0.7149\n",
      "Epoch 121/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.7483 - val_loss: 0.5751 - val_accuracy: 0.7023\n",
      "Epoch 122/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5668 - accuracy: 0.7580 - val_loss: 0.5632 - val_accuracy: 0.7673\n",
      "Epoch 123/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5578 - accuracy: 0.7455 - val_loss: 0.5567 - val_accuracy: 0.7841\n",
      "Epoch 124/1000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7441 - val_loss: 0.5515 - val_accuracy: 0.7925\n",
      "Epoch 125/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.7538 - val_loss: 0.5532 - val_accuracy: 0.7841\n",
      "Epoch 126/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5543 - accuracy: 0.7552 - val_loss: 0.6034 - val_accuracy: 0.6415\n",
      "Epoch 127/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7566 - val_loss: 0.5558 - val_accuracy: 0.7841\n",
      "Epoch 128/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.7455 - val_loss: 0.5503 - val_accuracy: 0.8008\n",
      "Epoch 129/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.7566 - val_loss: 0.5518 - val_accuracy: 0.7925\n",
      "Epoch 130/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.7538 - val_loss: 0.5562 - val_accuracy: 0.7673\n",
      "Epoch 131/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.7552 - val_loss: 0.5545 - val_accuracy: 0.7841\n",
      "Epoch 132/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.7469 - val_loss: 0.6144 - val_accuracy: 0.6226\n",
      "Epoch 133/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7469 - val_loss: 0.5493 - val_accuracy: 0.7987\n",
      "Epoch 134/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.7497 - val_loss: 0.5499 - val_accuracy: 0.7945\n",
      "Epoch 135/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.7594 - val_loss: 0.5488 - val_accuracy: 0.7987\n",
      "Epoch 136/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5514 - accuracy: 0.7608 - val_loss: 0.5490 - val_accuracy: 0.7987\n",
      "Epoch 137/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5520 - accuracy: 0.7497 - val_loss: 0.5530 - val_accuracy: 0.7841\n",
      "Epoch 138/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.7510 - val_loss: 0.5567 - val_accuracy: 0.7736\n",
      "Epoch 139/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.7552 - val_loss: 0.5590 - val_accuracy: 0.7505\n",
      "Epoch 140/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.7497 - val_loss: 0.5755 - val_accuracy: 0.6960\n",
      "Epoch 141/1000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.7552 - val_loss: 0.5484 - val_accuracy: 0.7966\n",
      "Epoch 142/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7580 - val_loss: 0.5529 - val_accuracy: 0.7820\n",
      "Epoch 143/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7566 - val_loss: 0.5495 - val_accuracy: 0.7862\n",
      "Epoch 144/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.7664 - val_loss: 0.5524 - val_accuracy: 0.7862\n",
      "Epoch 145/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.7357 - val_loss: 0.6011 - val_accuracy: 0.6331\n",
      "Epoch 146/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5525 - accuracy: 0.7510 - val_loss: 0.5478 - val_accuracy: 0.7966\n",
      "Epoch 147/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5480 - accuracy: 0.7636 - val_loss: 0.5882 - val_accuracy: 0.6520\n",
      "Epoch 148/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.7552 - val_loss: 0.5515 - val_accuracy: 0.7862\n",
      "Epoch 149/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.7538 - val_loss: 0.5558 - val_accuracy: 0.7547\n",
      "Epoch 150/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5549 - accuracy: 0.7469 - val_loss: 0.5486 - val_accuracy: 0.7841\n",
      "Epoch 151/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7441 - val_loss: 0.5794 - val_accuracy: 0.7107\n",
      "Epoch 152/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5521 - accuracy: 0.7552 - val_loss: 0.5459 - val_accuracy: 0.8008\n",
      "Epoch 153/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.7552 - val_loss: 0.5625 - val_accuracy: 0.7547\n",
      "Epoch 154/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5514 - accuracy: 0.7608 - val_loss: 0.5485 - val_accuracy: 0.7925\n",
      "Epoch 155/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.7566 - val_loss: 0.5469 - val_accuracy: 0.7987\n",
      "Epoch 156/1000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5530 - accuracy: 0.7413 - val_loss: 0.5590 - val_accuracy: 0.7736\n",
      "Epoch 157/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7538 - val_loss: 0.5570 - val_accuracy: 0.7505\n",
      "Epoch 158/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5549 - accuracy: 0.7469 - val_loss: 0.5479 - val_accuracy: 0.7820\n",
      "Epoch 159/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.7524 - val_loss: 0.5453 - val_accuracy: 0.8008\n",
      "Epoch 160/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7510 - val_loss: 0.5913 - val_accuracy: 0.6478\n",
      "Epoch 161/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.7427 - val_loss: 0.5453 - val_accuracy: 0.7966\n",
      "Epoch 162/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.7538 - val_loss: 0.5579 - val_accuracy: 0.7757\n",
      "Epoch 163/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7441 - val_loss: 0.5449 - val_accuracy: 0.7945\n",
      "Epoch 164/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7510 - val_loss: 0.5723 - val_accuracy: 0.6939\n",
      "Epoch 165/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5489 - accuracy: 0.7497 - val_loss: 0.5476 - val_accuracy: 0.7799\n",
      "Epoch 166/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.7455 - val_loss: 0.5446 - val_accuracy: 0.7966\n",
      "Epoch 167/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7538 - val_loss: 0.5454 - val_accuracy: 0.7925\n",
      "Epoch 168/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.7469 - val_loss: 0.5469 - val_accuracy: 0.7799\n",
      "Epoch 169/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5492 - accuracy: 0.7524 - val_loss: 0.5441 - val_accuracy: 0.7987\n",
      "Epoch 170/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5546 - accuracy: 0.7524 - val_loss: 0.5439 - val_accuracy: 0.7987\n",
      "Epoch 171/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7580 - val_loss: 0.5440 - val_accuracy: 0.7966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7594 - val_loss: 0.5455 - val_accuracy: 0.7987\n",
      "Epoch 173/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.7483 - val_loss: 0.5450 - val_accuracy: 0.7841\n",
      "Epoch 174/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7510 - val_loss: 0.5650 - val_accuracy: 0.7086\n",
      "Epoch 175/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.7413 - val_loss: 0.5450 - val_accuracy: 0.7841\n",
      "Epoch 176/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.7483 - val_loss: 0.5481 - val_accuracy: 0.7966\n",
      "Epoch 177/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.7510 - val_loss: 0.5783 - val_accuracy: 0.6751\n",
      "Epoch 178/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7566 - val_loss: 0.5437 - val_accuracy: 0.7925\n",
      "Epoch 179/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7580 - val_loss: 0.5607 - val_accuracy: 0.7799\n",
      "Epoch 180/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.7538 - val_loss: 0.5456 - val_accuracy: 0.7799\n",
      "Epoch 181/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7385 - val_loss: 0.5466 - val_accuracy: 0.7757\n",
      "Epoch 182/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.7538 - val_loss: 0.5635 - val_accuracy: 0.7149\n",
      "Epoch 183/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.7497 - val_loss: 0.5440 - val_accuracy: 0.7841\n",
      "Epoch 184/1000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7510 - val_loss: 0.5655 - val_accuracy: 0.7694\n",
      "Epoch 185/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7497 - val_loss: 0.5494 - val_accuracy: 0.7966\n",
      "Epoch 186/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5472 - accuracy: 0.7622 - val_loss: 0.5471 - val_accuracy: 0.7966\n",
      "Epoch 187/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5451 - accuracy: 0.7538 - val_loss: 0.5986 - val_accuracy: 0.6289\n",
      "Epoch 188/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7343 - val_loss: 0.5437 - val_accuracy: 0.7987\n",
      "Epoch 189/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7413 - val_loss: 0.5454 - val_accuracy: 0.7987\n",
      "Epoch 190/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5464 - accuracy: 0.7524 - val_loss: 0.5455 - val_accuracy: 0.7987\n",
      "Epoch 191/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7524 - val_loss: 0.5650 - val_accuracy: 0.7086\n",
      "Epoch 192/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7580 - val_loss: 0.5434 - val_accuracy: 0.7987\n",
      "Epoch 193/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7580 - val_loss: 0.5700 - val_accuracy: 0.6855\n",
      "Epoch 194/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5521 - accuracy: 0.7441 - val_loss: 0.5423 - val_accuracy: 0.7987\n",
      "Epoch 195/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7524 - val_loss: 0.5431 - val_accuracy: 0.7862\n",
      "Epoch 196/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7566 - val_loss: 0.5554 - val_accuracy: 0.7841\n",
      "Epoch 197/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.7594 - val_loss: 0.5626 - val_accuracy: 0.7799\n",
      "Epoch 198/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7594 - val_loss: 0.5618 - val_accuracy: 0.7191\n",
      "Epoch 199/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7524 - val_loss: 0.5549 - val_accuracy: 0.7379\n",
      "Epoch 200/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7497 - val_loss: 0.5472 - val_accuracy: 0.7694\n",
      "Epoch 201/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.7524 - val_loss: 0.5419 - val_accuracy: 0.7945\n",
      "Epoch 202/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7608 - val_loss: 0.5419 - val_accuracy: 0.7987\n",
      "Epoch 203/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7552 - val_loss: 0.5420 - val_accuracy: 0.7925\n",
      "Epoch 204/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5438 - accuracy: 0.7692 - val_loss: 0.5565 - val_accuracy: 0.7358\n",
      "Epoch 205/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5451 - accuracy: 0.7538 - val_loss: 0.5497 - val_accuracy: 0.7966\n",
      "Epoch 206/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.7483 - val_loss: 0.5438 - val_accuracy: 0.7736\n",
      "Epoch 207/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.7385 - val_loss: 0.5918 - val_accuracy: 0.7233\n",
      "Epoch 208/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.7413 - val_loss: 0.5523 - val_accuracy: 0.7945\n",
      "Epoch 209/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7483 - val_loss: 0.6008 - val_accuracy: 0.6268\n",
      "Epoch 210/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.7469 - val_loss: 0.5690 - val_accuracy: 0.7736\n",
      "Epoch 211/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.7524 - val_loss: 0.5434 - val_accuracy: 0.7736\n",
      "Epoch 212/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.7483 - val_loss: 0.5493 - val_accuracy: 0.7568\n",
      "Epoch 213/1000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.7566 - val_loss: 0.5416 - val_accuracy: 0.7966\n",
      "Epoch 214/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.7538 - val_loss: 0.5419 - val_accuracy: 0.7987\n",
      "Epoch 215/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7552 - val_loss: 0.5598 - val_accuracy: 0.7191\n",
      "Epoch 216/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7469 - val_loss: 0.5536 - val_accuracy: 0.7400\n",
      "Epoch 217/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7510 - val_loss: 0.5456 - val_accuracy: 0.7966\n",
      "Epoch 218/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.7469 - val_loss: 0.5613 - val_accuracy: 0.7862\n",
      "Epoch 219/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7650 - val_loss: 0.5471 - val_accuracy: 0.7652\n",
      "Epoch 220/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7399 - val_loss: 0.5459 - val_accuracy: 0.7966\n",
      "Epoch 221/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.7580 - val_loss: 0.5457 - val_accuracy: 0.7966\n",
      "Epoch 222/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.7413 - val_loss: 0.5522 - val_accuracy: 0.7966\n",
      "Epoch 223/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.7497 - val_loss: 0.5415 - val_accuracy: 0.7966\n",
      "Epoch 224/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7538 - val_loss: 0.5413 - val_accuracy: 0.7966\n",
      "Epoch 225/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7580 - val_loss: 0.5570 - val_accuracy: 0.7317\n",
      "Epoch 226/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7538 - val_loss: 0.5405 - val_accuracy: 0.8008\n",
      "Epoch 227/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7524 - val_loss: 0.5825 - val_accuracy: 0.6520\n",
      "Epoch 228/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5464 - accuracy: 0.7441 - val_loss: 0.5404 - val_accuracy: 0.7987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7566 - val_loss: 0.5445 - val_accuracy: 0.7736\n",
      "Epoch 230/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.7483 - val_loss: 0.5564 - val_accuracy: 0.7317\n",
      "Epoch 231/1000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7455 - val_loss: 0.5410 - val_accuracy: 0.7841\n",
      "Epoch 232/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7441 - val_loss: 0.5649 - val_accuracy: 0.7862\n",
      "Epoch 233/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7566 - val_loss: 0.5427 - val_accuracy: 0.7945\n",
      "Epoch 234/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7483 - val_loss: 0.5403 - val_accuracy: 0.8008\n",
      "Epoch 235/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.7469 - val_loss: 0.5409 - val_accuracy: 0.7841\n",
      "Epoch 236/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7538 - val_loss: 0.5415 - val_accuracy: 0.7987\n",
      "Epoch 237/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5366 - accuracy: 0.7552 - val_loss: 0.5411 - val_accuracy: 0.7966\n",
      "Epoch 238/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7594 - val_loss: 0.5454 - val_accuracy: 0.7966\n",
      "Epoch 239/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.7510 - val_loss: 0.5402 - val_accuracy: 0.7945\n",
      "Epoch 240/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7538 - val_loss: 0.5404 - val_accuracy: 0.7862\n",
      "Epoch 241/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7497 - val_loss: 0.5444 - val_accuracy: 0.7966\n",
      "Epoch 242/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7650 - val_loss: 0.5426 - val_accuracy: 0.7715\n",
      "Epoch 243/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7524 - val_loss: 0.5401 - val_accuracy: 0.7925\n",
      "Epoch 244/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.7538 - val_loss: 0.5489 - val_accuracy: 0.7966\n",
      "Epoch 245/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7622 - val_loss: 0.5787 - val_accuracy: 0.6667\n",
      "Epoch 246/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5424 - accuracy: 0.7497 - val_loss: 0.5406 - val_accuracy: 0.7841\n",
      "Epoch 247/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.7483 - val_loss: 0.5687 - val_accuracy: 0.6960\n",
      "Epoch 248/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7413 - val_loss: 0.5423 - val_accuracy: 0.7715\n",
      "Epoch 249/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7580 - val_loss: 0.5492 - val_accuracy: 0.7966\n",
      "Epoch 250/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7594 - val_loss: 0.5429 - val_accuracy: 0.7945\n",
      "Epoch 251/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7483 - val_loss: 0.5650 - val_accuracy: 0.7862\n",
      "Epoch 252/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.7580 - val_loss: 0.5411 - val_accuracy: 0.7987\n",
      "Epoch 253/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7524 - val_loss: 0.5440 - val_accuracy: 0.7736\n",
      "Epoch 254/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7538 - val_loss: 0.5423 - val_accuracy: 0.7715\n",
      "Epoch 255/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7580 - val_loss: 0.5815 - val_accuracy: 0.7526\n",
      "Epoch 256/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.7524 - val_loss: 0.5566 - val_accuracy: 0.7296\n",
      "Epoch 257/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5395 - accuracy: 0.7427 - val_loss: 0.5689 - val_accuracy: 0.6876\n",
      "Epoch 258/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7622 - val_loss: 0.5471 - val_accuracy: 0.7652\n",
      "Epoch 259/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7538 - val_loss: 0.5416 - val_accuracy: 0.7736\n",
      "Epoch 260/1000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.7538 - val_loss: 0.5397 - val_accuracy: 0.7966\n",
      "Epoch 261/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7538 - val_loss: 0.5443 - val_accuracy: 0.7945\n",
      "Epoch 262/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7497 - val_loss: 0.5444 - val_accuracy: 0.7715\n",
      "Epoch 263/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7455 - val_loss: 0.5394 - val_accuracy: 0.8008\n",
      "Epoch 264/1000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7497 - val_loss: 0.5393 - val_accuracy: 0.7883\n",
      "Epoch 265/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.7497 - val_loss: 0.5392 - val_accuracy: 0.7904\n",
      "Epoch 266/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7594 - val_loss: 0.5564 - val_accuracy: 0.7296\n",
      "Epoch 267/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7566 - val_loss: 0.6003 - val_accuracy: 0.6247\n",
      "Epoch 268/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7497 - val_loss: 0.5395 - val_accuracy: 0.7966\n",
      "Epoch 269/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7497 - val_loss: 0.5405 - val_accuracy: 0.7987\n",
      "Epoch 270/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7427 - val_loss: 0.5479 - val_accuracy: 0.7966\n",
      "Epoch 271/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7455 - val_loss: 0.5459 - val_accuracy: 0.7966\n",
      "Epoch 272/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7497 - val_loss: 0.5417 - val_accuracy: 0.7715\n",
      "Epoch 273/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7483 - val_loss: 0.5744 - val_accuracy: 0.7694\n",
      "Epoch 274/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5424 - accuracy: 0.7427 - val_loss: 0.5486 - val_accuracy: 0.7463\n",
      "Epoch 275/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.7427 - val_loss: 0.5549 - val_accuracy: 0.7317\n",
      "Epoch 276/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7552 - val_loss: 0.5799 - val_accuracy: 0.6583\n",
      "Epoch 277/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.7483 - val_loss: 0.5397 - val_accuracy: 0.7987\n",
      "Epoch 278/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7497 - val_loss: 0.5472 - val_accuracy: 0.7966\n",
      "Epoch 279/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.7538 - val_loss: 0.5566 - val_accuracy: 0.7945\n",
      "Epoch 280/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7538 - val_loss: 0.5388 - val_accuracy: 0.7883\n",
      "Epoch 281/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.7427 - val_loss: 0.5390 - val_accuracy: 0.7841\n",
      "Epoch 282/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7566 - val_loss: 0.5385 - val_accuracy: 0.7966\n",
      "Epoch 283/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.7538 - val_loss: 0.5407 - val_accuracy: 0.7736\n",
      "Epoch 284/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.7552 - val_loss: 0.5529 - val_accuracy: 0.7379\n",
      "Epoch 285/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5438 - accuracy: 0.7580 - val_loss: 0.5748 - val_accuracy: 0.7631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.7469 - val_loss: 0.5518 - val_accuracy: 0.7966\n",
      "Epoch 287/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7552 - val_loss: 0.5449 - val_accuracy: 0.7945\n",
      "Epoch 288/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7538 - val_loss: 0.5384 - val_accuracy: 0.7966\n",
      "Epoch 289/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.7469 - val_loss: 0.5383 - val_accuracy: 0.7925\n",
      "Epoch 290/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7636 - val_loss: 0.5767 - val_accuracy: 0.6625\n",
      "Epoch 291/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5498 - accuracy: 0.7427 - val_loss: 0.5384 - val_accuracy: 0.7904\n",
      "Epoch 292/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.7538 - val_loss: 0.5385 - val_accuracy: 0.7966\n",
      "Epoch 293/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7966\n",
      "Epoch 294/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7510 - val_loss: 0.5412 - val_accuracy: 0.7966\n",
      "Epoch 295/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7510 - val_loss: 0.5382 - val_accuracy: 0.7966\n",
      "Epoch 296/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7427 - val_loss: 0.5386 - val_accuracy: 0.7987\n",
      "Epoch 297/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5395 - accuracy: 0.7566 - val_loss: 0.5961 - val_accuracy: 0.6247\n",
      "Epoch 298/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7441 - val_loss: 0.6193 - val_accuracy: 0.6017\n",
      "Epoch 299/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7385 - val_loss: 0.5405 - val_accuracy: 0.7966\n",
      "Epoch 300/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7441 - val_loss: 0.5689 - val_accuracy: 0.6855\n",
      "Epoch 301/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7399 - val_loss: 0.5820 - val_accuracy: 0.7589\n",
      "Epoch 302/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.7469 - val_loss: 0.6250 - val_accuracy: 0.6960\n",
      "Epoch 303/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5438 - accuracy: 0.7455 - val_loss: 0.5504 - val_accuracy: 0.7463\n",
      "Epoch 304/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5438 - accuracy: 0.7538 - val_loss: 0.5380 - val_accuracy: 0.7925\n",
      "Epoch 305/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.7678 - val_loss: 0.5438 - val_accuracy: 0.7694\n",
      "Epoch 306/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7455 - val_loss: 0.5572 - val_accuracy: 0.7212\n",
      "Epoch 307/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7413 - val_loss: 0.5537 - val_accuracy: 0.7358\n",
      "Epoch 308/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7483 - val_loss: 0.5612 - val_accuracy: 0.7925\n",
      "Epoch 309/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.7497 - val_loss: 0.5405 - val_accuracy: 0.7966\n",
      "Epoch 310/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7497 - val_loss: 0.5719 - val_accuracy: 0.6751\n",
      "Epoch 311/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.7441 - val_loss: 0.5697 - val_accuracy: 0.7841\n",
      "Epoch 312/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7552 - val_loss: 0.6075 - val_accuracy: 0.6184\n",
      "Epoch 313/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7427 - val_loss: 0.5616 - val_accuracy: 0.7044\n",
      "Epoch 314/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7441 - val_loss: 0.5390 - val_accuracy: 0.7987\n",
      "Epoch 315/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7483 - val_loss: 0.5813 - val_accuracy: 0.6520\n",
      "Epoch 316/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7455 - val_loss: 0.5669 - val_accuracy: 0.6981\n",
      "Epoch 317/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7566 - val_loss: 0.5956 - val_accuracy: 0.6289\n",
      "Epoch 318/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5496 - accuracy: 0.7510 - val_loss: 0.5953 - val_accuracy: 0.7275\n",
      "Epoch 319/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.7566 - val_loss: 0.5388 - val_accuracy: 0.7736\n",
      "Epoch 320/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7594 - val_loss: 0.6208 - val_accuracy: 0.5996\n",
      "Epoch 321/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5333 - accuracy: 0.7483 - val_loss: 0.5414 - val_accuracy: 0.7966\n",
      "Epoch 322/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7622 - val_loss: 0.5393 - val_accuracy: 0.7987\n",
      "Epoch 323/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7524 - val_loss: 0.5383 - val_accuracy: 0.7841\n",
      "Epoch 324/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7566 - val_loss: 0.5403 - val_accuracy: 0.7966\n",
      "Epoch 325/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7510 - val_loss: 0.5376 - val_accuracy: 0.7883\n",
      "Epoch 326/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.7664 - val_loss: 0.5387 - val_accuracy: 0.7987\n",
      "Epoch 327/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7608 - val_loss: 0.5389 - val_accuracy: 0.7736\n",
      "Epoch 328/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7497 - val_loss: 0.5515 - val_accuracy: 0.7966\n",
      "Epoch 329/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7608 - val_loss: 0.6083 - val_accuracy: 0.6205\n",
      "Epoch 330/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7455 - val_loss: 0.5429 - val_accuracy: 0.7945\n",
      "Epoch 331/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7566 - val_loss: 0.5424 - val_accuracy: 0.7778\n",
      "Epoch 332/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7552 - val_loss: 0.5403 - val_accuracy: 0.7966\n",
      "Epoch 333/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7594 - val_loss: 0.5697 - val_accuracy: 0.7841\n",
      "Epoch 334/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7580 - val_loss: 0.5839 - val_accuracy: 0.7589\n",
      "Epoch 335/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7427 - val_loss: 0.5369 - val_accuracy: 0.7987\n",
      "Epoch 336/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7636 - val_loss: 0.5465 - val_accuracy: 0.7589\n",
      "Epoch 337/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7538 - val_loss: 0.5835 - val_accuracy: 0.7610\n",
      "Epoch 338/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.7636 - val_loss: 0.5742 - val_accuracy: 0.6688\n",
      "Epoch 339/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7385 - val_loss: 0.5366 - val_accuracy: 0.7966\n",
      "Epoch 340/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7469 - val_loss: 0.5993 - val_accuracy: 0.6226\n",
      "Epoch 341/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.7413 - val_loss: 0.5433 - val_accuracy: 0.7694\n",
      "Epoch 342/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7552 - val_loss: 0.5376 - val_accuracy: 0.7820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7622 - val_loss: 0.5490 - val_accuracy: 0.7463\n",
      "Epoch 344/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7608 - val_loss: 0.5388 - val_accuracy: 0.7757\n",
      "Epoch 345/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7580 - val_loss: 0.5460 - val_accuracy: 0.7945\n",
      "Epoch 346/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7608 - val_loss: 0.5364 - val_accuracy: 0.7925\n",
      "Epoch 347/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7441 - val_loss: 0.5520 - val_accuracy: 0.7966\n",
      "Epoch 348/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7510 - val_loss: 0.5551 - val_accuracy: 0.7296\n",
      "Epoch 349/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7510 - val_loss: 0.5577 - val_accuracy: 0.7170\n",
      "Epoch 350/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7483 - val_loss: 0.5364 - val_accuracy: 0.7925\n",
      "Epoch 351/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7497 - val_loss: 0.5620 - val_accuracy: 0.7023\n",
      "Epoch 352/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7510 - val_loss: 0.5398 - val_accuracy: 0.7757\n",
      "Epoch 353/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7497 - val_loss: 0.5364 - val_accuracy: 0.7945\n",
      "Epoch 354/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7580 - val_loss: 0.5388 - val_accuracy: 0.7757\n",
      "Epoch 355/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7524 - val_loss: 0.5545 - val_accuracy: 0.7296\n",
      "Epoch 356/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7497 - val_loss: 0.5362 - val_accuracy: 0.7945\n",
      "Epoch 357/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7538 - val_loss: 0.5498 - val_accuracy: 0.7966\n",
      "Epoch 358/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7524 - val_loss: 0.6089 - val_accuracy: 0.7191\n",
      "Epoch 359/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7510 - val_loss: 0.5392 - val_accuracy: 0.7966\n",
      "Epoch 360/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7413 - val_loss: 0.5492 - val_accuracy: 0.7966\n",
      "Epoch 361/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7580 - val_loss: 0.5409 - val_accuracy: 0.7778\n",
      "Epoch 362/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7510 - val_loss: 0.6139 - val_accuracy: 0.6164\n",
      "Epoch 363/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.7203 - val_loss: 0.5511 - val_accuracy: 0.7421\n",
      "Epoch 364/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7497 - val_loss: 0.5382 - val_accuracy: 0.7966\n",
      "Epoch 365/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7552 - val_loss: 0.5359 - val_accuracy: 0.7945\n",
      "Epoch 366/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7497 - val_loss: 0.5367 - val_accuracy: 0.7945\n",
      "Epoch 367/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7510 - val_loss: 0.5571 - val_accuracy: 0.7966\n",
      "Epoch 368/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7580 - val_loss: 0.5618 - val_accuracy: 0.7065\n",
      "Epoch 369/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7371 - val_loss: 0.5359 - val_accuracy: 0.7945\n",
      "Epoch 370/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7594 - val_loss: 0.5357 - val_accuracy: 0.7987\n",
      "Epoch 371/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7552 - val_loss: 0.5359 - val_accuracy: 0.7945\n",
      "Epoch 372/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.7497 - val_loss: 0.5423 - val_accuracy: 0.7945\n",
      "Epoch 373/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7636 - val_loss: 0.5464 - val_accuracy: 0.7925\n",
      "Epoch 374/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7552 - val_loss: 0.5552 - val_accuracy: 0.7275\n",
      "Epoch 375/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7538 - val_loss: 0.5574 - val_accuracy: 0.7191\n",
      "Epoch 376/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7455 - val_loss: 0.5451 - val_accuracy: 0.7925\n",
      "Epoch 377/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7510 - val_loss: 0.5363 - val_accuracy: 0.7945\n",
      "Epoch 378/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7552 - val_loss: 0.5520 - val_accuracy: 0.7966\n",
      "Epoch 379/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7566 - val_loss: 0.5406 - val_accuracy: 0.7757\n",
      "Epoch 380/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5375 - accuracy: 0.7483 - val_loss: 0.5506 - val_accuracy: 0.7966\n",
      "Epoch 381/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7483 - val_loss: 0.5369 - val_accuracy: 0.7945\n",
      "Epoch 382/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7483 - val_loss: 0.5369 - val_accuracy: 0.7757\n",
      "Epoch 383/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7510 - val_loss: 0.6103 - val_accuracy: 0.7170\n",
      "Epoch 384/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.7608 - val_loss: 0.5391 - val_accuracy: 0.7757\n",
      "Epoch 385/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.7524 - val_loss: 0.5368 - val_accuracy: 0.7945\n",
      "Epoch 386/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7566 - val_loss: 0.5383 - val_accuracy: 0.7778\n",
      "Epoch 387/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7497 - val_loss: 0.5624 - val_accuracy: 0.7904\n",
      "Epoch 388/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.7469 - val_loss: 0.5490 - val_accuracy: 0.7463\n",
      "Epoch 389/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7622 - val_loss: 0.5574 - val_accuracy: 0.7191\n",
      "Epoch 390/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7455 - val_loss: 0.5376 - val_accuracy: 0.7757\n",
      "Epoch 391/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7538 - val_loss: 0.5364 - val_accuracy: 0.7945\n",
      "Epoch 392/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7510 - val_loss: 0.5359 - val_accuracy: 0.7945\n",
      "Epoch 393/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7510 - val_loss: 0.5349 - val_accuracy: 0.7966\n",
      "Epoch 394/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7622 - val_loss: 0.5523 - val_accuracy: 0.7966\n",
      "Epoch 395/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7622 - val_loss: 0.5355 - val_accuracy: 0.7945\n",
      "Epoch 396/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7510 - val_loss: 0.5351 - val_accuracy: 0.7966\n",
      "Epoch 397/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7594 - val_loss: 0.5376 - val_accuracy: 0.7945\n",
      "Epoch 398/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7678 - val_loss: 0.5508 - val_accuracy: 0.7421\n",
      "Epoch 399/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7524 - val_loss: 0.5380 - val_accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7538 - val_loss: 0.5350 - val_accuracy: 0.7966\n",
      "Epoch 401/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7566 - val_loss: 0.5402 - val_accuracy: 0.7945\n",
      "Epoch 402/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7650 - val_loss: 0.5460 - val_accuracy: 0.7925\n",
      "Epoch 403/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7622 - val_loss: 0.5360 - val_accuracy: 0.7904\n",
      "Epoch 404/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7566 - val_loss: 0.5354 - val_accuracy: 0.7945\n",
      "Epoch 405/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7566 - val_loss: 0.5353 - val_accuracy: 0.7925\n",
      "Epoch 406/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7524 - val_loss: 0.5348 - val_accuracy: 0.7987\n",
      "Epoch 407/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5335 - accuracy: 0.7566 - val_loss: 0.5357 - val_accuracy: 0.7904\n",
      "Epoch 408/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7469 - val_loss: 0.5397 - val_accuracy: 0.7757\n",
      "Epoch 409/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7566 - val_loss: 0.5364 - val_accuracy: 0.7925\n",
      "Epoch 410/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7524 - val_loss: 0.5349 - val_accuracy: 0.7966\n",
      "Epoch 411/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7552 - val_loss: 0.5363 - val_accuracy: 0.7820\n",
      "Epoch 412/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7510 - val_loss: 0.5513 - val_accuracy: 0.7421\n",
      "Epoch 413/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7483 - val_loss: 0.5381 - val_accuracy: 0.7925\n",
      "Epoch 414/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7552 - val_loss: 0.5374 - val_accuracy: 0.7736\n",
      "Epoch 415/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.7622 - val_loss: 0.5362 - val_accuracy: 0.7778\n",
      "Epoch 416/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7413 - val_loss: 0.5346 - val_accuracy: 0.7966\n",
      "Epoch 417/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7552 - val_loss: 0.5352 - val_accuracy: 0.7945\n",
      "Epoch 418/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7594 - val_loss: 0.5352 - val_accuracy: 0.7945\n",
      "Epoch 419/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7566 - val_loss: 0.5367 - val_accuracy: 0.7925\n",
      "Epoch 420/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7566 - val_loss: 0.5347 - val_accuracy: 0.7945\n",
      "Epoch 421/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7357 - val_loss: 0.5362 - val_accuracy: 0.7820\n",
      "Epoch 422/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7566 - val_loss: 0.5351 - val_accuracy: 0.7945\n",
      "Epoch 423/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.7524 - val_loss: 0.5351 - val_accuracy: 0.7945\n",
      "Epoch 424/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7622 - val_loss: 0.5432 - val_accuracy: 0.7945\n",
      "Epoch 425/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7608 - val_loss: 0.5359 - val_accuracy: 0.7945\n",
      "Epoch 426/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7497 - val_loss: 0.5360 - val_accuracy: 0.7778\n",
      "Epoch 427/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7497 - val_loss: 0.5450 - val_accuracy: 0.7945\n",
      "Epoch 428/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.7580 - val_loss: 0.5358 - val_accuracy: 0.7778\n",
      "Epoch 429/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7650 - val_loss: 0.5342 - val_accuracy: 0.7966\n",
      "Epoch 430/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7594 - val_loss: 0.5457 - val_accuracy: 0.7484\n",
      "Epoch 431/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7524 - val_loss: 0.5349 - val_accuracy: 0.7945\n",
      "Epoch 432/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.7538 - val_loss: 0.5439 - val_accuracy: 0.7589\n",
      "Epoch 433/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7580 - val_loss: 0.5352 - val_accuracy: 0.7925\n",
      "Epoch 434/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7678 - val_loss: 0.5391 - val_accuracy: 0.7925\n",
      "Epoch 435/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7552 - val_loss: 0.5511 - val_accuracy: 0.7966\n",
      "Epoch 436/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7692 - val_loss: 0.5372 - val_accuracy: 0.7925\n",
      "Epoch 437/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7497 - val_loss: 0.5888 - val_accuracy: 0.6394\n",
      "Epoch 438/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.7608 - val_loss: 0.5343 - val_accuracy: 0.7966\n",
      "Epoch 439/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7594 - val_loss: 0.5657 - val_accuracy: 0.6939\n",
      "Epoch 440/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7594 - val_loss: 0.5506 - val_accuracy: 0.7966\n",
      "Epoch 441/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7580 - val_loss: 0.5345 - val_accuracy: 0.7966\n",
      "Epoch 442/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7580 - val_loss: 0.5401 - val_accuracy: 0.7757\n",
      "Epoch 443/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7552 - val_loss: 0.5858 - val_accuracy: 0.7652\n",
      "Epoch 444/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7510 - val_loss: 0.5382 - val_accuracy: 0.7904\n",
      "Epoch 445/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.7497 - val_loss: 0.5382 - val_accuracy: 0.7736\n",
      "Epoch 446/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7664 - val_loss: 0.5729 - val_accuracy: 0.6730\n",
      "Epoch 447/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7385 - val_loss: 0.5388 - val_accuracy: 0.7904\n",
      "Epoch 448/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7580 - val_loss: 0.5352 - val_accuracy: 0.7925\n",
      "Epoch 449/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7566 - val_loss: 0.5431 - val_accuracy: 0.7945\n",
      "Epoch 450/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7622 - val_loss: 0.5392 - val_accuracy: 0.7925\n",
      "Epoch 451/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7594 - val_loss: 0.5498 - val_accuracy: 0.7463\n",
      "Epoch 452/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7510 - val_loss: 0.5415 - val_accuracy: 0.7694\n",
      "Epoch 453/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7580 - val_loss: 0.5341 - val_accuracy: 0.7945\n",
      "Epoch 454/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7608 - val_loss: 0.5494 - val_accuracy: 0.7925\n",
      "Epoch 455/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7524 - val_loss: 0.5389 - val_accuracy: 0.7904\n",
      "Epoch 456/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7524 - val_loss: 0.5403 - val_accuracy: 0.7945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7497 - val_loss: 0.5363 - val_accuracy: 0.7925\n",
      "Epoch 458/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7497 - val_loss: 0.5500 - val_accuracy: 0.7925\n",
      "Epoch 459/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7580 - val_loss: 0.5739 - val_accuracy: 0.6646\n",
      "Epoch 460/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7469 - val_loss: 0.5418 - val_accuracy: 0.7694\n",
      "Epoch 461/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.7538 - val_loss: 0.5804 - val_accuracy: 0.6499\n",
      "Epoch 462/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7538 - val_loss: 0.5526 - val_accuracy: 0.7421\n",
      "Epoch 463/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.7469 - val_loss: 0.5623 - val_accuracy: 0.6981\n",
      "Epoch 464/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7469 - val_loss: 0.5335 - val_accuracy: 0.7966\n",
      "Epoch 465/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.7497 - val_loss: 0.5474 - val_accuracy: 0.7925\n",
      "Epoch 466/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7552 - val_loss: 0.5425 - val_accuracy: 0.7652\n",
      "Epoch 467/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7594 - val_loss: 0.5662 - val_accuracy: 0.7841\n",
      "Epoch 468/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7441 - val_loss: 0.5340 - val_accuracy: 0.7966\n",
      "Epoch 469/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7524 - val_loss: 0.5426 - val_accuracy: 0.7945\n",
      "Epoch 470/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7636 - val_loss: 0.5449 - val_accuracy: 0.7945\n",
      "Epoch 471/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7580 - val_loss: 0.5534 - val_accuracy: 0.7966\n",
      "Epoch 472/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7594 - val_loss: 0.5958 - val_accuracy: 0.6247\n",
      "Epoch 473/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7538 - val_loss: 0.5336 - val_accuracy: 0.7945\n",
      "Epoch 474/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7413 - val_loss: 0.5336 - val_accuracy: 0.7945\n",
      "Epoch 475/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5287 - accuracy: 0.7552 - val_loss: 0.5365 - val_accuracy: 0.7736\n",
      "Epoch 476/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7524 - val_loss: 0.5484 - val_accuracy: 0.7925\n",
      "Epoch 477/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7608 - val_loss: 0.5365 - val_accuracy: 0.7736\n",
      "Epoch 478/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.7566 - val_loss: 0.5348 - val_accuracy: 0.7841\n",
      "Epoch 479/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7594 - val_loss: 0.5334 - val_accuracy: 0.7966\n",
      "Epoch 480/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7552 - val_loss: 0.5335 - val_accuracy: 0.7966\n",
      "Epoch 481/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7594 - val_loss: 0.7163 - val_accuracy: 0.5472\n",
      "Epoch 482/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.7469 - val_loss: 0.5558 - val_accuracy: 0.7945\n",
      "Epoch 483/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7566 - val_loss: 0.5540 - val_accuracy: 0.7254\n",
      "Epoch 484/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7622 - val_loss: 0.5522 - val_accuracy: 0.7338\n",
      "Epoch 485/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7566 - val_loss: 0.5389 - val_accuracy: 0.7904\n",
      "Epoch 486/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7580 - val_loss: 0.5615 - val_accuracy: 0.7862\n",
      "Epoch 487/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7664 - val_loss: 0.5443 - val_accuracy: 0.7589\n",
      "Epoch 488/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7594 - val_loss: 0.5521 - val_accuracy: 0.7966\n",
      "Epoch 489/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7413 - val_loss: 0.5335 - val_accuracy: 0.7966\n",
      "Epoch 490/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7566 - val_loss: 0.5605 - val_accuracy: 0.7862\n",
      "Epoch 491/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.7636 - val_loss: 0.5480 - val_accuracy: 0.7505\n",
      "Epoch 492/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7469 - val_loss: 0.5774 - val_accuracy: 0.7673\n",
      "Epoch 493/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7580 - val_loss: 0.5466 - val_accuracy: 0.7463\n",
      "Epoch 494/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7483 - val_loss: 0.5390 - val_accuracy: 0.7904\n",
      "Epoch 495/1000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7692 - val_loss: 0.5368 - val_accuracy: 0.7904\n",
      "Epoch 496/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.7566 - val_loss: 0.5337 - val_accuracy: 0.7904\n",
      "Epoch 497/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7552 - val_loss: 0.5377 - val_accuracy: 0.7904\n",
      "Epoch 498/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7594 - val_loss: 0.5771 - val_accuracy: 0.6583\n",
      "Epoch 499/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.7622 - val_loss: 0.5328 - val_accuracy: 0.7966\n",
      "Epoch 500/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7510 - val_loss: 0.5369 - val_accuracy: 0.7904\n",
      "Epoch 501/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.7622 - val_loss: 0.5335 - val_accuracy: 0.7945\n",
      "Epoch 502/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7552 - val_loss: 0.5488 - val_accuracy: 0.7505\n",
      "Epoch 503/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.7524 - val_loss: 0.5349 - val_accuracy: 0.7841\n",
      "Epoch 504/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7524 - val_loss: 0.5328 - val_accuracy: 0.7987\n",
      "Epoch 505/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.7636 - val_loss: 0.5373 - val_accuracy: 0.7736\n",
      "Epoch 506/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.7552 - val_loss: 0.5342 - val_accuracy: 0.7925\n",
      "Epoch 507/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7636 - val_loss: 0.5517 - val_accuracy: 0.7317\n",
      "Epoch 508/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7524 - val_loss: 0.5330 - val_accuracy: 0.7966\n",
      "Epoch 509/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5335 - accuracy: 0.7622 - val_loss: 0.5327 - val_accuracy: 0.7987\n",
      "Epoch 510/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7594 - val_loss: 0.5410 - val_accuracy: 0.7925\n",
      "Epoch 511/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7552 - val_loss: 0.5907 - val_accuracy: 0.6373\n",
      "Epoch 512/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7524 - val_loss: 0.5668 - val_accuracy: 0.7841\n",
      "Epoch 513/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7552 - val_loss: 0.5345 - val_accuracy: 0.7862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7580 - val_loss: 0.5334 - val_accuracy: 0.7966\n",
      "Epoch 515/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7538 - val_loss: 0.5364 - val_accuracy: 0.7736\n",
      "Epoch 516/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7566 - val_loss: 0.5365 - val_accuracy: 0.7715\n",
      "Epoch 517/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7497 - val_loss: 0.5335 - val_accuracy: 0.7966\n",
      "Epoch 518/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7552 - val_loss: 0.5498 - val_accuracy: 0.7925\n",
      "Epoch 519/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7622 - val_loss: 0.5366 - val_accuracy: 0.7694\n",
      "Epoch 520/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7566 - val_loss: 0.5329 - val_accuracy: 0.7966\n",
      "Epoch 521/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.7622 - val_loss: 0.5423 - val_accuracy: 0.7945\n",
      "Epoch 522/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.7524 - val_loss: 0.5350 - val_accuracy: 0.7799\n",
      "Epoch 523/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7622 - val_loss: 0.5324 - val_accuracy: 0.8008\n",
      "Epoch 524/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7552 - val_loss: 0.5323 - val_accuracy: 0.7987\n",
      "Epoch 525/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7524 - val_loss: 0.5755 - val_accuracy: 0.7694\n",
      "Epoch 526/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.7538 - val_loss: 0.5442 - val_accuracy: 0.7945\n",
      "Epoch 527/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7734 - val_loss: 0.5641 - val_accuracy: 0.6960\n",
      "Epoch 528/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7524 - val_loss: 0.6032 - val_accuracy: 0.6226\n",
      "Epoch 529/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7371 - val_loss: 0.5449 - val_accuracy: 0.7945\n",
      "Epoch 530/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7594 - val_loss: 0.5710 - val_accuracy: 0.6730\n",
      "Epoch 531/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7497 - val_loss: 0.5621 - val_accuracy: 0.7862\n",
      "Epoch 532/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7594 - val_loss: 0.5320 - val_accuracy: 0.7987\n",
      "Epoch 533/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7566 - val_loss: 0.5628 - val_accuracy: 0.7862\n",
      "Epoch 534/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7594 - val_loss: 0.5338 - val_accuracy: 0.7904\n",
      "Epoch 535/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7524 - val_loss: 0.5324 - val_accuracy: 0.7966\n",
      "Epoch 536/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7524 - val_loss: 0.5429 - val_accuracy: 0.7945\n",
      "Epoch 537/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.7497 - val_loss: 0.5508 - val_accuracy: 0.7904\n",
      "Epoch 538/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7566 - val_loss: 0.5933 - val_accuracy: 0.6331\n",
      "Epoch 539/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7538 - val_loss: 0.5357 - val_accuracy: 0.7904\n",
      "Epoch 540/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7636 - val_loss: 0.5839 - val_accuracy: 0.7673\n",
      "Epoch 541/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7524 - val_loss: 0.5555 - val_accuracy: 0.7862\n",
      "Epoch 542/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7469 - val_loss: 0.5379 - val_accuracy: 0.7904\n",
      "Epoch 543/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7552 - val_loss: 0.5460 - val_accuracy: 0.7945\n",
      "Epoch 544/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7510 - val_loss: 0.5355 - val_accuracy: 0.7904\n",
      "Epoch 545/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7580 - val_loss: 0.5503 - val_accuracy: 0.7400\n",
      "Epoch 546/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7622 - val_loss: 0.5323 - val_accuracy: 0.7966\n",
      "Epoch 547/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7580 - val_loss: 0.5316 - val_accuracy: 0.7987\n",
      "Epoch 548/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.7706 - val_loss: 0.5499 - val_accuracy: 0.7925\n",
      "Epoch 549/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7664 - val_loss: 0.5494 - val_accuracy: 0.7421\n",
      "Epoch 550/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7469 - val_loss: 0.5338 - val_accuracy: 0.7925\n",
      "Epoch 551/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.7608 - val_loss: 0.5755 - val_accuracy: 0.6625\n",
      "Epoch 552/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7636 - val_loss: 0.6067 - val_accuracy: 0.6205\n",
      "Epoch 553/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7469 - val_loss: 0.5568 - val_accuracy: 0.7862\n",
      "Epoch 554/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7552 - val_loss: 0.5332 - val_accuracy: 0.7925\n",
      "Epoch 555/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7636 - val_loss: 0.5375 - val_accuracy: 0.7904\n",
      "Epoch 556/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7538 - val_loss: 0.5323 - val_accuracy: 0.7966\n",
      "Epoch 557/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7650 - val_loss: 0.5505 - val_accuracy: 0.7421\n",
      "Epoch 558/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7483 - val_loss: 0.5328 - val_accuracy: 0.7966\n",
      "Epoch 559/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7441 - val_loss: 0.5433 - val_accuracy: 0.7925\n",
      "Epoch 560/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.7594 - val_loss: 0.5354 - val_accuracy: 0.7757\n",
      "Epoch 561/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7524 - val_loss: 0.5482 - val_accuracy: 0.7925\n",
      "Epoch 562/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7594 - val_loss: 0.5385 - val_accuracy: 0.7715\n",
      "Epoch 563/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.7566 - val_loss: 0.5326 - val_accuracy: 0.7945\n",
      "Epoch 564/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7524 - val_loss: 0.5730 - val_accuracy: 0.6625\n",
      "Epoch 565/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7608 - val_loss: 0.5435 - val_accuracy: 0.7589\n",
      "Epoch 566/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7580 - val_loss: 0.6026 - val_accuracy: 0.7484\n",
      "Epoch 567/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7636 - val_loss: 0.5642 - val_accuracy: 0.6960\n",
      "Epoch 568/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7552 - val_loss: 0.5322 - val_accuracy: 0.7966\n",
      "Epoch 569/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7510 - val_loss: 0.5322 - val_accuracy: 0.7966\n",
      "Epoch 570/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7580 - val_loss: 0.5687 - val_accuracy: 0.6792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7455 - val_loss: 0.5406 - val_accuracy: 0.7904\n",
      "Epoch 572/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7622 - val_loss: 0.5557 - val_accuracy: 0.7841\n",
      "Epoch 573/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7664 - val_loss: 0.5339 - val_accuracy: 0.7925\n",
      "Epoch 574/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7650 - val_loss: 0.6563 - val_accuracy: 0.5891\n",
      "Epoch 575/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5335 - accuracy: 0.7497 - val_loss: 0.5355 - val_accuracy: 0.7904\n",
      "Epoch 576/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7678 - val_loss: 0.5326 - val_accuracy: 0.7966\n",
      "Epoch 577/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7650 - val_loss: 0.5445 - val_accuracy: 0.7925\n",
      "Epoch 578/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7510 - val_loss: 0.5317 - val_accuracy: 0.7966\n",
      "Epoch 579/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7580 - val_loss: 0.5432 - val_accuracy: 0.7925\n",
      "Epoch 580/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7594 - val_loss: 0.5352 - val_accuracy: 0.7715\n",
      "Epoch 581/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7622 - val_loss: 0.5643 - val_accuracy: 0.6960\n",
      "Epoch 582/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7552 - val_loss: 0.5330 - val_accuracy: 0.7883\n",
      "Epoch 583/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5287 - accuracy: 0.7622 - val_loss: 0.5723 - val_accuracy: 0.6646\n",
      "Epoch 584/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7650 - val_loss: 0.5374 - val_accuracy: 0.7694\n",
      "Epoch 585/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7552 - val_loss: 0.5320 - val_accuracy: 0.7966\n",
      "Epoch 586/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7580 - val_loss: 0.5362 - val_accuracy: 0.7715\n",
      "Epoch 587/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7678 - val_loss: 0.5475 - val_accuracy: 0.7945\n",
      "Epoch 588/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7552 - val_loss: 0.5349 - val_accuracy: 0.7757\n",
      "Epoch 589/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7608 - val_loss: 0.5314 - val_accuracy: 0.7987\n",
      "Epoch 590/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7636 - val_loss: 0.5535 - val_accuracy: 0.7904\n",
      "Epoch 591/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7566 - val_loss: 0.5635 - val_accuracy: 0.6981\n",
      "Epoch 592/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7510 - val_loss: 0.5459 - val_accuracy: 0.7421\n",
      "Epoch 593/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7594 - val_loss: 0.5578 - val_accuracy: 0.7841\n",
      "Epoch 594/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7594 - val_loss: 0.5345 - val_accuracy: 0.7778\n",
      "Epoch 595/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7455 - val_loss: 0.5398 - val_accuracy: 0.7652\n",
      "Epoch 596/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7469 - val_loss: 0.5429 - val_accuracy: 0.7589\n",
      "Epoch 597/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.7608 - val_loss: 0.5330 - val_accuracy: 0.7925\n",
      "Epoch 598/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7594 - val_loss: 0.5469 - val_accuracy: 0.7945\n",
      "Epoch 599/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7692 - val_loss: 0.5437 - val_accuracy: 0.7547\n",
      "Epoch 600/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7608 - val_loss: 0.5336 - val_accuracy: 0.7862\n",
      "Epoch 601/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7594 - val_loss: 0.5376 - val_accuracy: 0.7904\n",
      "Epoch 602/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7664 - val_loss: 0.5659 - val_accuracy: 0.7778\n",
      "Epoch 603/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.7566 - val_loss: 0.5310 - val_accuracy: 0.7966\n",
      "Epoch 604/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7455 - val_loss: 0.5369 - val_accuracy: 0.7904\n",
      "Epoch 605/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.7678 - val_loss: 0.5340 - val_accuracy: 0.7820\n",
      "Epoch 606/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7552 - val_loss: 0.6088 - val_accuracy: 0.6101\n",
      "Epoch 607/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7483 - val_loss: 0.5737 - val_accuracy: 0.6625\n",
      "Epoch 608/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.7636 - val_loss: 0.5311 - val_accuracy: 0.7987\n",
      "Epoch 609/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7566 - val_loss: 0.5848 - val_accuracy: 0.6457\n",
      "Epoch 610/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7566 - val_loss: 0.5420 - val_accuracy: 0.7589\n",
      "Epoch 611/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7552 - val_loss: 0.5761 - val_accuracy: 0.7757\n",
      "Epoch 612/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7580 - val_loss: 0.5314 - val_accuracy: 0.7966\n",
      "Epoch 613/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7552 - val_loss: 0.5338 - val_accuracy: 0.7904\n",
      "Epoch 614/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7594 - val_loss: 0.5677 - val_accuracy: 0.7778\n",
      "Epoch 615/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7594 - val_loss: 0.5309 - val_accuracy: 0.7966\n",
      "Epoch 616/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7594 - val_loss: 0.5368 - val_accuracy: 0.7904\n",
      "Epoch 617/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7664 - val_loss: 0.5450 - val_accuracy: 0.7925\n",
      "Epoch 618/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7636 - val_loss: 0.5671 - val_accuracy: 0.7778\n",
      "Epoch 619/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7580 - val_loss: 0.5682 - val_accuracy: 0.7778\n",
      "Epoch 620/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7510 - val_loss: 0.5523 - val_accuracy: 0.7254\n",
      "Epoch 621/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7608 - val_loss: 0.5355 - val_accuracy: 0.7904\n",
      "Epoch 622/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.7441 - val_loss: 0.5643 - val_accuracy: 0.7778\n",
      "Epoch 623/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7664 - val_loss: 0.5720 - val_accuracy: 0.6709\n",
      "Epoch 624/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7538 - val_loss: 0.5581 - val_accuracy: 0.7086\n",
      "Epoch 625/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7720 - val_loss: 0.5305 - val_accuracy: 0.7987\n",
      "Epoch 626/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7580 - val_loss: 0.5309 - val_accuracy: 0.7966\n",
      "Epoch 627/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7594 - val_loss: 0.5740 - val_accuracy: 0.6625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5249 - accuracy: 0.7594 - val_loss: 0.5322 - val_accuracy: 0.7966\n",
      "Epoch 629/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7538 - val_loss: 0.5420 - val_accuracy: 0.7904\n",
      "Epoch 630/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7594 - val_loss: 0.5351 - val_accuracy: 0.7715\n",
      "Epoch 631/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7594 - val_loss: 0.5333 - val_accuracy: 0.7883\n",
      "Epoch 632/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7580 - val_loss: 0.5307 - val_accuracy: 0.7987\n",
      "Epoch 633/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7664 - val_loss: 0.5434 - val_accuracy: 0.7904\n",
      "Epoch 634/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7566 - val_loss: 0.5455 - val_accuracy: 0.7421\n",
      "Epoch 635/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.7538 - val_loss: 0.5563 - val_accuracy: 0.7170\n",
      "Epoch 636/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5345 - accuracy: 0.7538 - val_loss: 0.5308 - val_accuracy: 0.7966\n",
      "Epoch 637/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7552 - val_loss: 0.5449 - val_accuracy: 0.7904\n",
      "Epoch 638/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7552 - val_loss: 0.5306 - val_accuracy: 0.7966\n",
      "Epoch 639/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7510 - val_loss: 0.5730 - val_accuracy: 0.7799\n",
      "Epoch 640/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.7636 - val_loss: 0.5393 - val_accuracy: 0.7904\n",
      "Epoch 641/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7664 - val_loss: 0.5328 - val_accuracy: 0.7904\n",
      "Epoch 642/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7580 - val_loss: 0.5429 - val_accuracy: 0.7904\n",
      "Epoch 643/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7580 - val_loss: 0.5305 - val_accuracy: 0.7966\n",
      "Epoch 644/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7608 - val_loss: 0.5477 - val_accuracy: 0.7421\n",
      "Epoch 645/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7580 - val_loss: 0.5911 - val_accuracy: 0.7694\n",
      "Epoch 646/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7594 - val_loss: 0.5299 - val_accuracy: 0.7987\n",
      "Epoch 647/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7636 - val_loss: 0.5435 - val_accuracy: 0.7505\n",
      "Epoch 648/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7566 - val_loss: 0.5415 - val_accuracy: 0.7904\n",
      "Epoch 649/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7664 - val_loss: 0.5388 - val_accuracy: 0.7673\n",
      "Epoch 650/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7622 - val_loss: 0.5392 - val_accuracy: 0.7589\n",
      "Epoch 651/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7594 - val_loss: 0.5481 - val_accuracy: 0.7904\n",
      "Epoch 652/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7538 - val_loss: 0.5349 - val_accuracy: 0.7736\n",
      "Epoch 653/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5294 - accuracy: 0.7524 - val_loss: 0.5330 - val_accuracy: 0.7904\n",
      "Epoch 654/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7692 - val_loss: 0.5372 - val_accuracy: 0.7673\n",
      "Epoch 655/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7524 - val_loss: 0.5418 - val_accuracy: 0.7568\n",
      "Epoch 656/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7678 - val_loss: 0.5401 - val_accuracy: 0.7904\n",
      "Epoch 657/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7510 - val_loss: 0.5675 - val_accuracy: 0.7778\n",
      "Epoch 658/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7664 - val_loss: 0.5316 - val_accuracy: 0.7945\n",
      "Epoch 659/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7580 - val_loss: 0.5302 - val_accuracy: 0.7987\n",
      "Epoch 660/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7566 - val_loss: 0.5303 - val_accuracy: 0.7987\n",
      "Epoch 661/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7608 - val_loss: 0.5302 - val_accuracy: 0.8008\n",
      "Epoch 662/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7664 - val_loss: 0.5302 - val_accuracy: 0.8008\n",
      "Epoch 663/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7524 - val_loss: 0.5407 - val_accuracy: 0.7589\n",
      "Epoch 664/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7497 - val_loss: 0.5338 - val_accuracy: 0.7841\n",
      "Epoch 665/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7762 - val_loss: 0.5552 - val_accuracy: 0.7191\n",
      "Epoch 666/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7566 - val_loss: 0.5325 - val_accuracy: 0.7883\n",
      "Epoch 667/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7678 - val_loss: 0.5631 - val_accuracy: 0.6981\n",
      "Epoch 668/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7622 - val_loss: 0.6671 - val_accuracy: 0.5786\n",
      "Epoch 669/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7497 - val_loss: 0.5308 - val_accuracy: 0.7945\n",
      "Epoch 670/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7636 - val_loss: 0.5347 - val_accuracy: 0.7757\n",
      "Epoch 671/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7566 - val_loss: 0.5303 - val_accuracy: 0.7966\n",
      "Epoch 672/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7622 - val_loss: 0.5320 - val_accuracy: 0.7904\n",
      "Epoch 673/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7580 - val_loss: 0.5320 - val_accuracy: 0.7925\n",
      "Epoch 674/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7566 - val_loss: 0.5525 - val_accuracy: 0.7317\n",
      "Epoch 675/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7427 - val_loss: 0.5503 - val_accuracy: 0.7841\n",
      "Epoch 676/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.7510 - val_loss: 0.5315 - val_accuracy: 0.7925\n",
      "Epoch 677/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7510 - val_loss: 0.5413 - val_accuracy: 0.7883\n",
      "Epoch 678/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.7692 - val_loss: 0.5572 - val_accuracy: 0.7191\n",
      "Epoch 679/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7594 - val_loss: 0.5294 - val_accuracy: 0.7987\n",
      "Epoch 680/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7580 - val_loss: 0.5309 - val_accuracy: 0.7966\n",
      "Epoch 681/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7538 - val_loss: 0.5468 - val_accuracy: 0.7904\n",
      "Epoch 682/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7636 - val_loss: 0.5335 - val_accuracy: 0.7841\n",
      "Epoch 683/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7622 - val_loss: 0.5400 - val_accuracy: 0.7610\n",
      "Epoch 684/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7497 - val_loss: 0.5428 - val_accuracy: 0.7526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7580 - val_loss: 0.5297 - val_accuracy: 0.7987\n",
      "Epoch 686/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7580 - val_loss: 0.5344 - val_accuracy: 0.7904\n",
      "Epoch 687/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7650 - val_loss: 0.5427 - val_accuracy: 0.7883\n",
      "Epoch 688/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7538 - val_loss: 0.5472 - val_accuracy: 0.7820\n",
      "Epoch 689/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7538 - val_loss: 0.5387 - val_accuracy: 0.7652\n",
      "Epoch 690/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7622 - val_loss: 0.5325 - val_accuracy: 0.7925\n",
      "Epoch 691/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7580 - val_loss: 0.5297 - val_accuracy: 0.7966\n",
      "Epoch 692/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7608 - val_loss: 0.5295 - val_accuracy: 0.7987\n",
      "Epoch 693/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7650 - val_loss: 0.5394 - val_accuracy: 0.7904\n",
      "Epoch 694/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7566 - val_loss: 0.5406 - val_accuracy: 0.7904\n",
      "Epoch 695/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7650 - val_loss: 0.5582 - val_accuracy: 0.7757\n",
      "Epoch 696/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7552 - val_loss: 0.5880 - val_accuracy: 0.6478\n",
      "Epoch 697/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7608 - val_loss: 0.5954 - val_accuracy: 0.6310\n",
      "Epoch 698/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7538 - val_loss: 0.5292 - val_accuracy: 0.7987\n",
      "Epoch 699/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7510 - val_loss: 0.5305 - val_accuracy: 0.7945\n",
      "Epoch 700/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7636 - val_loss: 0.5388 - val_accuracy: 0.7673\n",
      "Epoch 701/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.7497 - val_loss: 0.5663 - val_accuracy: 0.6855\n",
      "Epoch 702/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7594 - val_loss: 0.5301 - val_accuracy: 0.7966\n",
      "Epoch 703/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7608 - val_loss: 0.5510 - val_accuracy: 0.7317\n",
      "Epoch 704/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7580 - val_loss: 0.5670 - val_accuracy: 0.6834\n",
      "Epoch 705/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7608 - val_loss: 0.5971 - val_accuracy: 0.6289\n",
      "Epoch 706/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7497 - val_loss: 0.5354 - val_accuracy: 0.7694\n",
      "Epoch 707/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7650 - val_loss: 0.5293 - val_accuracy: 0.7966\n",
      "Epoch 708/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7580 - val_loss: 0.5318 - val_accuracy: 0.7904\n",
      "Epoch 709/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7580 - val_loss: 0.5296 - val_accuracy: 0.8008\n",
      "Epoch 710/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.7636 - val_loss: 0.5317 - val_accuracy: 0.7904\n",
      "Epoch 711/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.7566 - val_loss: 0.5321 - val_accuracy: 0.7904\n",
      "Epoch 712/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7650 - val_loss: 0.5400 - val_accuracy: 0.7610\n",
      "Epoch 713/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7608 - val_loss: 0.5321 - val_accuracy: 0.7904\n",
      "Epoch 714/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7580 - val_loss: 0.5555 - val_accuracy: 0.7191\n",
      "Epoch 715/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7510 - val_loss: 0.5290 - val_accuracy: 0.7966\n",
      "Epoch 716/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7650 - val_loss: 0.5637 - val_accuracy: 0.6897\n",
      "Epoch 717/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7552 - val_loss: 0.5289 - val_accuracy: 0.7987\n",
      "Epoch 718/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7636 - val_loss: 0.5469 - val_accuracy: 0.7820\n",
      "Epoch 719/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7538 - val_loss: 0.5302 - val_accuracy: 0.7945\n",
      "Epoch 720/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7622 - val_loss: 0.5294 - val_accuracy: 0.7966\n",
      "Epoch 721/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7594 - val_loss: 0.5352 - val_accuracy: 0.7904\n",
      "Epoch 722/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7734 - val_loss: 0.5297 - val_accuracy: 0.7966\n",
      "Epoch 723/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7706 - val_loss: 0.5292 - val_accuracy: 0.8008\n",
      "Epoch 724/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7636 - val_loss: 0.5292 - val_accuracy: 0.8008\n",
      "Epoch 725/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.7608 - val_loss: 0.5374 - val_accuracy: 0.7652\n",
      "Epoch 726/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7552 - val_loss: 0.5398 - val_accuracy: 0.7883\n",
      "Epoch 727/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7483 - val_loss: 0.5599 - val_accuracy: 0.7736\n",
      "Epoch 728/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.7538 - val_loss: 0.5435 - val_accuracy: 0.7547\n",
      "Epoch 729/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.7538 - val_loss: 0.5457 - val_accuracy: 0.7799\n",
      "Epoch 730/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7580 - val_loss: 0.5486 - val_accuracy: 0.7400\n",
      "Epoch 731/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7678 - val_loss: 0.5810 - val_accuracy: 0.6583\n",
      "Epoch 732/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7469 - val_loss: 0.5286 - val_accuracy: 0.8008\n",
      "Epoch 733/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7636 - val_loss: 0.5311 - val_accuracy: 0.7904\n",
      "Epoch 734/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7552 - val_loss: 0.5446 - val_accuracy: 0.7484\n",
      "Epoch 735/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7622 - val_loss: 0.5289 - val_accuracy: 0.7966\n",
      "Epoch 736/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7510 - val_loss: 0.5333 - val_accuracy: 0.7862\n",
      "Epoch 737/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7413 - val_loss: 0.5351 - val_accuracy: 0.7673\n",
      "Epoch 738/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7608 - val_loss: 0.5492 - val_accuracy: 0.7820\n",
      "Epoch 739/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7552 - val_loss: 0.5493 - val_accuracy: 0.7820\n",
      "Epoch 740/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7650 - val_loss: 0.5356 - val_accuracy: 0.7904\n",
      "Epoch 741/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7524 - val_loss: 0.5295 - val_accuracy: 0.7966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5294 - accuracy: 0.7524 - val_loss: 0.5340 - val_accuracy: 0.7757\n",
      "Epoch 743/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7538 - val_loss: 0.5360 - val_accuracy: 0.7631\n",
      "Epoch 744/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7622 - val_loss: 0.5354 - val_accuracy: 0.7904\n",
      "Epoch 745/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7650 - val_loss: 0.5287 - val_accuracy: 0.8008\n",
      "Epoch 746/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7636 - val_loss: 0.5289 - val_accuracy: 0.7966\n",
      "Epoch 747/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7524 - val_loss: 0.5287 - val_accuracy: 0.8008\n",
      "Epoch 748/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.7524 - val_loss: 0.5296 - val_accuracy: 0.7945\n",
      "Epoch 749/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7552 - val_loss: 0.5317 - val_accuracy: 0.7925\n",
      "Epoch 750/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7552 - val_loss: 0.5366 - val_accuracy: 0.7904\n",
      "Epoch 751/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7636 - val_loss: 0.5317 - val_accuracy: 0.7925\n",
      "Epoch 752/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5287 - accuracy: 0.7566 - val_loss: 0.5574 - val_accuracy: 0.7736\n",
      "Epoch 753/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7510 - val_loss: 0.5827 - val_accuracy: 0.6520\n",
      "Epoch 754/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7608 - val_loss: 0.5426 - val_accuracy: 0.7883\n",
      "Epoch 755/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7678 - val_loss: 0.5758 - val_accuracy: 0.7799\n",
      "Epoch 756/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7650 - val_loss: 0.5322 - val_accuracy: 0.7925\n",
      "Epoch 757/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7608 - val_loss: 0.5594 - val_accuracy: 0.7107\n",
      "Epoch 758/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7497 - val_loss: 0.5309 - val_accuracy: 0.7904\n",
      "Epoch 759/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7622 - val_loss: 0.5376 - val_accuracy: 0.7652\n",
      "Epoch 760/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7594 - val_loss: 0.5291 - val_accuracy: 0.7945\n",
      "Epoch 761/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7622 - val_loss: 0.5287 - val_accuracy: 0.7966\n",
      "Epoch 762/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5202 - accuracy: 0.7608 - val_loss: 0.5607 - val_accuracy: 0.7757\n",
      "Epoch 763/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7566 - val_loss: 0.5538 - val_accuracy: 0.7233\n",
      "Epoch 764/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7706 - val_loss: 0.5282 - val_accuracy: 0.7966\n",
      "Epoch 765/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7510 - val_loss: 0.5511 - val_accuracy: 0.7820\n",
      "Epoch 766/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7608 - val_loss: 0.5531 - val_accuracy: 0.7799\n",
      "Epoch 767/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7692 - val_loss: 0.5431 - val_accuracy: 0.7883\n",
      "Epoch 768/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7608 - val_loss: 0.5280 - val_accuracy: 0.7966\n",
      "Epoch 769/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7664 - val_loss: 0.6227 - val_accuracy: 0.6017\n",
      "Epoch 770/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7552 - val_loss: 0.5373 - val_accuracy: 0.7904\n",
      "Epoch 771/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7608 - val_loss: 0.5589 - val_accuracy: 0.7086\n",
      "Epoch 772/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7720 - val_loss: 0.5801 - val_accuracy: 0.7757\n",
      "Epoch 773/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7580 - val_loss: 0.5303 - val_accuracy: 0.7966\n",
      "Epoch 774/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7636 - val_loss: 0.5279 - val_accuracy: 0.7987\n",
      "Epoch 775/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7580 - val_loss: 0.5446 - val_accuracy: 0.7505\n",
      "Epoch 776/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7510 - val_loss: 0.5306 - val_accuracy: 0.7925\n",
      "Epoch 777/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7678 - val_loss: 0.5930 - val_accuracy: 0.6373\n",
      "Epoch 778/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7580 - val_loss: 0.5433 - val_accuracy: 0.7526\n",
      "Epoch 779/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7483 - val_loss: 0.5555 - val_accuracy: 0.7170\n",
      "Epoch 780/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7636 - val_loss: 0.5350 - val_accuracy: 0.7610\n",
      "Epoch 781/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7622 - val_loss: 0.5318 - val_accuracy: 0.7925\n",
      "Epoch 782/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7594 - val_loss: 0.6888 - val_accuracy: 0.5681\n",
      "Epoch 783/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7566 - val_loss: 0.5283 - val_accuracy: 0.7987\n",
      "Epoch 784/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7413 - val_loss: 0.5382 - val_accuracy: 0.7883\n",
      "Epoch 785/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5287 - accuracy: 0.7608 - val_loss: 0.5279 - val_accuracy: 0.7987\n",
      "Epoch 786/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7552 - val_loss: 0.5286 - val_accuracy: 0.7987\n",
      "Epoch 787/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.7608 - val_loss: 0.5301 - val_accuracy: 0.7966\n",
      "Epoch 788/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7664 - val_loss: 0.5296 - val_accuracy: 0.7966\n",
      "Epoch 789/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7580 - val_loss: 0.5576 - val_accuracy: 0.7736\n",
      "Epoch 790/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7692 - val_loss: 0.5302 - val_accuracy: 0.7925\n",
      "Epoch 791/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.7650 - val_loss: 0.5291 - val_accuracy: 0.7966\n",
      "Epoch 792/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7524 - val_loss: 0.5303 - val_accuracy: 0.7925\n",
      "Epoch 793/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7636 - val_loss: 0.5281 - val_accuracy: 0.8008\n",
      "Epoch 794/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7622 - val_loss: 0.5565 - val_accuracy: 0.7170\n",
      "Epoch 795/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7594 - val_loss: 0.5283 - val_accuracy: 0.7966\n",
      "Epoch 796/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.7594 - val_loss: 0.5572 - val_accuracy: 0.7191\n",
      "Epoch 797/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7455 - val_loss: 0.5416 - val_accuracy: 0.7883\n",
      "Epoch 798/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7594 - val_loss: 0.5350 - val_accuracy: 0.7904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7636 - val_loss: 0.5357 - val_accuracy: 0.7589\n",
      "Epoch 800/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7636 - val_loss: 0.5297 - val_accuracy: 0.7925\n",
      "Epoch 801/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7678 - val_loss: 0.5281 - val_accuracy: 0.8008\n",
      "Epoch 802/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7580 - val_loss: 0.5588 - val_accuracy: 0.7736\n",
      "Epoch 803/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7622 - val_loss: 0.5410 - val_accuracy: 0.7883\n",
      "Epoch 804/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7650 - val_loss: 0.5298 - val_accuracy: 0.7925\n",
      "Epoch 805/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5287 - accuracy: 0.7594 - val_loss: 0.5337 - val_accuracy: 0.7757\n",
      "Epoch 806/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5299 - accuracy: 0.7538 - val_loss: 0.5293 - val_accuracy: 0.7966\n",
      "Epoch 807/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7650 - val_loss: 0.5281 - val_accuracy: 0.7966\n",
      "Epoch 808/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7664 - val_loss: 0.5301 - val_accuracy: 0.7966\n",
      "Epoch 809/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7636 - val_loss: 0.6172 - val_accuracy: 0.7421\n",
      "Epoch 810/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.7636 - val_loss: 0.5324 - val_accuracy: 0.7862\n",
      "Epoch 811/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7650 - val_loss: 0.5358 - val_accuracy: 0.7904\n",
      "Epoch 812/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.7650 - val_loss: 0.5277 - val_accuracy: 0.8008\n",
      "Epoch 813/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7608 - val_loss: 0.5340 - val_accuracy: 0.7736\n",
      "Epoch 814/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7594 - val_loss: 0.5405 - val_accuracy: 0.7883\n",
      "Epoch 815/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7678 - val_loss: 0.5663 - val_accuracy: 0.6876\n",
      "Epoch 816/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7580 - val_loss: 0.5405 - val_accuracy: 0.7883\n",
      "Epoch 817/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7608 - val_loss: 0.5297 - val_accuracy: 0.7925\n",
      "Epoch 818/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7524 - val_loss: 0.5316 - val_accuracy: 0.7883\n",
      "Epoch 819/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7692 - val_loss: 0.5328 - val_accuracy: 0.7925\n",
      "Epoch 820/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7580 - val_loss: 0.5498 - val_accuracy: 0.7778\n",
      "Epoch 821/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7636 - val_loss: 0.5317 - val_accuracy: 0.7925\n",
      "Epoch 822/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.7552 - val_loss: 0.5489 - val_accuracy: 0.7799\n",
      "Epoch 823/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7664 - val_loss: 0.5507 - val_accuracy: 0.7296\n",
      "Epoch 824/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7538 - val_loss: 0.5297 - val_accuracy: 0.7925\n",
      "Epoch 825/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7497 - val_loss: 0.5321 - val_accuracy: 0.7862\n",
      "Epoch 826/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7622 - val_loss: 0.5556 - val_accuracy: 0.7170\n",
      "Epoch 827/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7497 - val_loss: 0.5290 - val_accuracy: 0.7966\n",
      "Epoch 828/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5234 - accuracy: 0.7622 - val_loss: 0.5302 - val_accuracy: 0.7925\n",
      "Epoch 829/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7483 - val_loss: 0.5272 - val_accuracy: 0.8008\n",
      "Epoch 830/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7622 - val_loss: 0.5349 - val_accuracy: 0.7568\n",
      "Epoch 831/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7566 - val_loss: 0.5274 - val_accuracy: 0.7987\n",
      "Epoch 832/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7692 - val_loss: 0.5370 - val_accuracy: 0.7883\n",
      "Epoch 833/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7650 - val_loss: 0.5737 - val_accuracy: 0.6709\n",
      "Epoch 834/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7413 - val_loss: 0.5396 - val_accuracy: 0.7883\n",
      "Epoch 835/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7636 - val_loss: 0.5478 - val_accuracy: 0.7379\n",
      "Epoch 836/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7622 - val_loss: 0.5348 - val_accuracy: 0.7589\n",
      "Epoch 837/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.7594 - val_loss: 0.5278 - val_accuracy: 0.7966\n",
      "Epoch 838/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7594 - val_loss: 0.5275 - val_accuracy: 0.7966\n",
      "Epoch 839/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7622 - val_loss: 0.5337 - val_accuracy: 0.7736\n",
      "Epoch 840/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7566 - val_loss: 0.5278 - val_accuracy: 0.7966\n",
      "Epoch 841/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7552 - val_loss: 0.5295 - val_accuracy: 0.7925\n",
      "Epoch 842/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7524 - val_loss: 0.5391 - val_accuracy: 0.7568\n",
      "Epoch 843/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7566 - val_loss: 0.5836 - val_accuracy: 0.6520\n",
      "Epoch 844/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7497 - val_loss: 0.5409 - val_accuracy: 0.7484\n",
      "Epoch 845/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7497 - val_loss: 0.5281 - val_accuracy: 0.7987\n",
      "Epoch 846/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7734 - val_loss: 0.5289 - val_accuracy: 0.7945\n",
      "Epoch 847/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7608 - val_loss: 0.5313 - val_accuracy: 0.7925\n",
      "Epoch 848/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5299 - accuracy: 0.7594 - val_loss: 0.5365 - val_accuracy: 0.7883\n",
      "Epoch 849/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.7552 - val_loss: 0.5677 - val_accuracy: 0.7778\n",
      "Epoch 850/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7720 - val_loss: 0.5275 - val_accuracy: 0.7987\n",
      "Epoch 851/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7664 - val_loss: 0.5275 - val_accuracy: 0.8008\n",
      "Epoch 852/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7566 - val_loss: 0.5337 - val_accuracy: 0.7925\n",
      "Epoch 853/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7594 - val_loss: 0.5352 - val_accuracy: 0.7883\n",
      "Epoch 854/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7580 - val_loss: 0.5271 - val_accuracy: 0.8008\n",
      "Epoch 855/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7608 - val_loss: 0.5405 - val_accuracy: 0.7883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7636 - val_loss: 0.5323 - val_accuracy: 0.7925\n",
      "Epoch 857/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7636 - val_loss: 0.5343 - val_accuracy: 0.7925\n",
      "Epoch 858/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7636 - val_loss: 0.5356 - val_accuracy: 0.7883\n",
      "Epoch 859/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7580 - val_loss: 0.5531 - val_accuracy: 0.7275\n",
      "Epoch 860/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5234 - accuracy: 0.7524 - val_loss: 0.5554 - val_accuracy: 0.7212\n",
      "Epoch 861/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7594 - val_loss: 0.5331 - val_accuracy: 0.7925\n",
      "Epoch 862/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7622 - val_loss: 0.5285 - val_accuracy: 0.7966\n",
      "Epoch 863/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7678 - val_loss: 0.5610 - val_accuracy: 0.7086\n",
      "Epoch 864/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7636 - val_loss: 0.5272 - val_accuracy: 0.8008\n",
      "Epoch 865/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7594 - val_loss: 0.5286 - val_accuracy: 0.7925\n",
      "Epoch 866/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7622 - val_loss: 0.5271 - val_accuracy: 0.7987\n",
      "Epoch 867/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7594 - val_loss: 0.5329 - val_accuracy: 0.7757\n",
      "Epoch 868/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7566 - val_loss: 0.5272 - val_accuracy: 0.7987\n",
      "Epoch 869/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7678 - val_loss: 0.5847 - val_accuracy: 0.7757\n",
      "Epoch 870/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7678 - val_loss: 0.5276 - val_accuracy: 0.7966\n",
      "Epoch 871/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.7552 - val_loss: 0.5275 - val_accuracy: 0.7966\n",
      "Epoch 872/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7566 - val_loss: 0.5296 - val_accuracy: 0.7925\n",
      "Epoch 873/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7580 - val_loss: 0.5389 - val_accuracy: 0.7883\n",
      "Epoch 874/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7594 - val_loss: 0.5829 - val_accuracy: 0.7757\n",
      "Epoch 875/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7622 - val_loss: 0.5335 - val_accuracy: 0.7925\n",
      "Epoch 876/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7720 - val_loss: 0.5269 - val_accuracy: 0.7987\n",
      "Epoch 877/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7650 - val_loss: 0.5277 - val_accuracy: 0.7966\n",
      "Epoch 878/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.7538 - val_loss: 0.5266 - val_accuracy: 0.8008\n",
      "Epoch 879/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7552 - val_loss: 0.5679 - val_accuracy: 0.6876\n",
      "Epoch 880/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7664 - val_loss: 0.5630 - val_accuracy: 0.6960\n",
      "Epoch 881/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7510 - val_loss: 0.5269 - val_accuracy: 0.7987\n",
      "Epoch 882/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7608 - val_loss: 0.5270 - val_accuracy: 0.7966\n",
      "Epoch 883/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7706 - val_loss: 0.5402 - val_accuracy: 0.7883\n",
      "Epoch 884/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7664 - val_loss: 0.5275 - val_accuracy: 0.7945\n",
      "Epoch 885/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7636 - val_loss: 0.5383 - val_accuracy: 0.7610\n",
      "Epoch 886/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7538 - val_loss: 0.5283 - val_accuracy: 0.7925\n",
      "Epoch 887/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7580 - val_loss: 0.5275 - val_accuracy: 0.7945\n",
      "Epoch 888/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7608 - val_loss: 0.5540 - val_accuracy: 0.7233\n",
      "Epoch 889/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7552 - val_loss: 0.5411 - val_accuracy: 0.7799\n",
      "Epoch 890/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7636 - val_loss: 0.5998 - val_accuracy: 0.6268\n",
      "Epoch 891/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7524 - val_loss: 0.5284 - val_accuracy: 0.7945\n",
      "Epoch 892/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7636 - val_loss: 0.5438 - val_accuracy: 0.7568\n",
      "Epoch 893/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7622 - val_loss: 0.5301 - val_accuracy: 0.7925\n",
      "Epoch 894/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.7664 - val_loss: 0.5420 - val_accuracy: 0.7526\n",
      "Epoch 895/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.7678 - val_loss: 0.5744 - val_accuracy: 0.7778\n",
      "Epoch 896/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7636 - val_loss: 0.5306 - val_accuracy: 0.7904\n",
      "Epoch 897/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7566 - val_loss: 0.5533 - val_accuracy: 0.7254\n",
      "Epoch 898/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7622 - val_loss: 0.5636 - val_accuracy: 0.7799\n",
      "Epoch 899/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5202 - accuracy: 0.7608 - val_loss: 0.5641 - val_accuracy: 0.7778\n",
      "Epoch 900/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7594 - val_loss: 0.5268 - val_accuracy: 0.7987\n",
      "Epoch 901/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.7608 - val_loss: 0.5266 - val_accuracy: 0.7966\n",
      "Epoch 902/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7594 - val_loss: 0.5391 - val_accuracy: 0.7883\n",
      "Epoch 903/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7636 - val_loss: 0.5483 - val_accuracy: 0.7778\n",
      "Epoch 904/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7678 - val_loss: 0.5402 - val_accuracy: 0.7883\n",
      "Epoch 905/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7552 - val_loss: 0.5397 - val_accuracy: 0.7883\n",
      "Epoch 906/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7622 - val_loss: 0.5627 - val_accuracy: 0.7044\n",
      "Epoch 907/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7650 - val_loss: 0.5622 - val_accuracy: 0.7044\n",
      "Epoch 908/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.7664 - val_loss: 0.5735 - val_accuracy: 0.6709\n",
      "Epoch 909/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7608 - val_loss: 0.5271 - val_accuracy: 0.7966\n",
      "Epoch 910/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7580 - val_loss: 0.5844 - val_accuracy: 0.7757\n",
      "Epoch 911/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7524 - val_loss: 0.5266 - val_accuracy: 0.8008\n",
      "Epoch 912/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7650 - val_loss: 0.5265 - val_accuracy: 0.8008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7622 - val_loss: 0.5735 - val_accuracy: 0.6709\n",
      "Epoch 914/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7538 - val_loss: 0.5582 - val_accuracy: 0.7170\n",
      "Epoch 915/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7580 - val_loss: 0.5435 - val_accuracy: 0.7547\n",
      "Epoch 916/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7608 - val_loss: 0.5378 - val_accuracy: 0.7883\n",
      "Epoch 917/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7580 - val_loss: 0.5266 - val_accuracy: 0.7987\n",
      "Epoch 918/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7622 - val_loss: 0.5265 - val_accuracy: 0.7966\n",
      "Epoch 919/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.7594 - val_loss: 0.5276 - val_accuracy: 0.7945\n",
      "Epoch 920/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7580 - val_loss: 0.5268 - val_accuracy: 0.7966\n",
      "Epoch 921/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7636 - val_loss: 0.6075 - val_accuracy: 0.6143\n",
      "Epoch 922/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7636 - val_loss: 0.5259 - val_accuracy: 0.8008\n",
      "Epoch 923/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7622 - val_loss: 0.5337 - val_accuracy: 0.7904\n",
      "Epoch 924/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7580 - val_loss: 0.5433 - val_accuracy: 0.7799\n",
      "Epoch 925/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7664 - val_loss: 0.5558 - val_accuracy: 0.7212\n",
      "Epoch 926/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.7622 - val_loss: 0.5309 - val_accuracy: 0.7925\n",
      "Epoch 927/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7594 - val_loss: 0.5387 - val_accuracy: 0.7610\n",
      "Epoch 928/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7552 - val_loss: 0.5413 - val_accuracy: 0.7883\n",
      "Epoch 929/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7622 - val_loss: 0.5282 - val_accuracy: 0.7925\n",
      "Epoch 930/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.7594 - val_loss: 0.5265 - val_accuracy: 0.7966\n",
      "Epoch 931/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7594 - val_loss: 0.5342 - val_accuracy: 0.7610\n",
      "Epoch 932/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7608 - val_loss: 0.5312 - val_accuracy: 0.7925\n",
      "Epoch 933/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7524 - val_loss: 0.5257 - val_accuracy: 0.8008\n",
      "Epoch 934/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7664 - val_loss: 0.5794 - val_accuracy: 0.6604\n",
      "Epoch 935/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7538 - val_loss: 0.5292 - val_accuracy: 0.7925\n",
      "Epoch 936/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7566 - val_loss: 0.5269 - val_accuracy: 0.7945\n",
      "Epoch 937/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7636 - val_loss: 0.5257 - val_accuracy: 0.7987\n",
      "Epoch 938/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7580 - val_loss: 0.5271 - val_accuracy: 0.7945\n",
      "Epoch 939/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7469 - val_loss: 0.5628 - val_accuracy: 0.7757\n",
      "Epoch 940/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7552 - val_loss: 0.5600 - val_accuracy: 0.7757\n",
      "Epoch 941/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.7720 - val_loss: 0.5276 - val_accuracy: 0.7925\n",
      "Epoch 942/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7650 - val_loss: 0.5268 - val_accuracy: 0.7945\n",
      "Epoch 943/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.7580 - val_loss: 0.5314 - val_accuracy: 0.7862\n",
      "Epoch 944/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7664 - val_loss: 0.5451 - val_accuracy: 0.7799\n",
      "Epoch 945/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7636 - val_loss: 0.5286 - val_accuracy: 0.7945\n",
      "Epoch 946/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7594 - val_loss: 0.5313 - val_accuracy: 0.7925\n",
      "Epoch 947/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.7706 - val_loss: 0.5374 - val_accuracy: 0.7589\n",
      "Epoch 948/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7650 - val_loss: 0.5321 - val_accuracy: 0.7925\n",
      "Epoch 949/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7580 - val_loss: 0.5259 - val_accuracy: 0.8008\n",
      "Epoch 950/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.7566 - val_loss: 0.5259 - val_accuracy: 0.7987\n",
      "Epoch 951/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7622 - val_loss: 0.5785 - val_accuracy: 0.7757\n",
      "Epoch 952/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7594 - val_loss: 0.5252 - val_accuracy: 0.8008\n",
      "Epoch 953/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7650 - val_loss: 0.5254 - val_accuracy: 0.7987\n",
      "Epoch 954/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7594 - val_loss: 0.5255 - val_accuracy: 0.7987\n",
      "Epoch 955/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7552 - val_loss: 0.5658 - val_accuracy: 0.6897\n",
      "Epoch 956/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7706 - val_loss: 0.5634 - val_accuracy: 0.6981\n",
      "Epoch 957/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7608 - val_loss: 0.5280 - val_accuracy: 0.7925\n",
      "Epoch 958/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7692 - val_loss: 0.5399 - val_accuracy: 0.7799\n",
      "Epoch 959/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7594 - val_loss: 0.5275 - val_accuracy: 0.7925\n",
      "Epoch 960/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7664 - val_loss: 0.5272 - val_accuracy: 0.7945\n",
      "Epoch 961/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.7664 - val_loss: 0.5268 - val_accuracy: 0.7966\n",
      "Epoch 962/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7678 - val_loss: 0.5358 - val_accuracy: 0.7883\n",
      "Epoch 963/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7580 - val_loss: 0.5392 - val_accuracy: 0.7526\n",
      "Epoch 964/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7594 - val_loss: 0.5488 - val_accuracy: 0.7358\n",
      "Epoch 965/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7510 - val_loss: 0.5471 - val_accuracy: 0.7778\n",
      "Epoch 966/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7566 - val_loss: 0.5454 - val_accuracy: 0.7799\n",
      "Epoch 967/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.7608 - val_loss: 0.5265 - val_accuracy: 0.7966\n",
      "Epoch 968/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7622 - val_loss: 0.5445 - val_accuracy: 0.7799\n",
      "Epoch 969/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7622 - val_loss: 0.5586 - val_accuracy: 0.7757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7580 - val_loss: 0.5262 - val_accuracy: 0.7966\n",
      "Epoch 971/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7608 - val_loss: 0.5464 - val_accuracy: 0.7400\n",
      "Epoch 972/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7538 - val_loss: 0.5346 - val_accuracy: 0.7904\n",
      "Epoch 973/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.7636 - val_loss: 0.5323 - val_accuracy: 0.7673\n",
      "Epoch 974/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7636 - val_loss: 0.5251 - val_accuracy: 0.7987\n",
      "Epoch 975/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7594 - val_loss: 0.5329 - val_accuracy: 0.7904\n",
      "Epoch 976/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7678 - val_loss: 0.5907 - val_accuracy: 0.6373\n",
      "Epoch 977/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7538 - val_loss: 0.5257 - val_accuracy: 0.7966\n",
      "Epoch 978/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7608 - val_loss: 0.5251 - val_accuracy: 0.8008\n",
      "Epoch 979/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7594 - val_loss: 0.5419 - val_accuracy: 0.7526\n",
      "Epoch 980/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7580 - val_loss: 0.5283 - val_accuracy: 0.7945\n",
      "Epoch 981/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7636 - val_loss: 0.5411 - val_accuracy: 0.7799\n",
      "Epoch 982/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7636 - val_loss: 0.5349 - val_accuracy: 0.7589\n",
      "Epoch 983/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7594 - val_loss: 0.5440 - val_accuracy: 0.7547\n",
      "Epoch 984/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7538 - val_loss: 0.5655 - val_accuracy: 0.7778\n",
      "Epoch 985/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7622 - val_loss: 0.5267 - val_accuracy: 0.7925\n",
      "Epoch 986/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7734 - val_loss: 0.5258 - val_accuracy: 0.7925\n",
      "Epoch 987/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5202 - accuracy: 0.7566 - val_loss: 0.5372 - val_accuracy: 0.7589\n",
      "Epoch 988/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7538 - val_loss: 0.5339 - val_accuracy: 0.7904\n",
      "Epoch 989/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7692 - val_loss: 0.5288 - val_accuracy: 0.7904\n",
      "Epoch 990/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7636 - val_loss: 0.5342 - val_accuracy: 0.7904\n",
      "Epoch 991/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7650 - val_loss: 0.5753 - val_accuracy: 0.7757\n",
      "Epoch 992/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.7706 - val_loss: 0.5300 - val_accuracy: 0.7883\n",
      "Epoch 993/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7664 - val_loss: 0.5257 - val_accuracy: 0.7966\n",
      "Epoch 994/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7594 - val_loss: 0.5256 - val_accuracy: 0.8008\n",
      "Epoch 995/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7566 - val_loss: 0.5316 - val_accuracy: 0.7820\n",
      "Epoch 996/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7580 - val_loss: 0.5321 - val_accuracy: 0.7904\n",
      "Epoch 997/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7673\n",
      "Epoch 998/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7678 - val_loss: 0.5416 - val_accuracy: 0.7799\n",
      "Epoch 999/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7664 - val_loss: 0.5478 - val_accuracy: 0.7694\n",
      "Epoch 1000/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7594 - val_loss: 0.5276 - val_accuracy: 0.7925\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, validation_data=(X_valid, y_valid), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f754adb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'ro', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179a534c",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae8130e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5178384184837341, 'accuracy': 0.7678321599960327}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81e9985d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5276165008544922, 'accuracy': 0.7924528121948242}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ce35d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5325643420219421, 'accuracy': 0.7761006355285645}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d1e718d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 971us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = np.round(model.predict(X_test),0)\n",
    "test_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52b2262b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "795"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_labels = y_test\n",
    "len(predict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "695bcca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6289308176100629"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = predict_labels != test_predictions\n",
    "np.sum(errors[1])/len(errors)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371a8ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
