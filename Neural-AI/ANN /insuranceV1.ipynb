{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10daae06",
   "metadata": {},
   "source": [
    "# Travel insurance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78df287",
   "metadata": {},
   "source": [
    "# Setting up Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "309d637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e748c8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data ingestion\n",
    "\n",
    "Source: [Travel insurance predictions](https://www.kaggle.com/datasets/tejashvi14/travel-insurance-prediction-data)\n",
    "\n",
    "Upload and clean dataset. It was checked from the source the data was clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cd39363",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Employment Type</th>\n",
       "      <th>GraduateOrNot</th>\n",
       "      <th>AnnualIncome</th>\n",
       "      <th>FamilyMembers</th>\n",
       "      <th>ChronicDiseases</th>\n",
       "      <th>FrequentFlyer</th>\n",
       "      <th>EverTravelledAbroad</th>\n",
       "      <th>TravelInsurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>Government Sector</td>\n",
       "      <td>Yes</td>\n",
       "      <td>400000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>Private Sector/Self Employed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1250000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>Private Sector/Self Employed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>Private Sector/Self Employed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>700000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>Private Sector/Self Employed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>700000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Age               Employment Type GraduateOrNot  AnnualIncome  \\\n",
       "0           0   31             Government Sector           Yes        400000   \n",
       "1           1   31  Private Sector/Self Employed           Yes       1250000   \n",
       "2           2   34  Private Sector/Self Employed           Yes        500000   \n",
       "3           3   28  Private Sector/Self Employed           Yes        700000   \n",
       "4           4   28  Private Sector/Self Employed           Yes        700000   \n",
       "\n",
       "   FamilyMembers  ChronicDiseases FrequentFlyer EverTravelledAbroad  \\\n",
       "0              6                1            No                  No   \n",
       "1              7                0            No                  No   \n",
       "2              4                1            No                  No   \n",
       "3              3                1            No                  No   \n",
       "4              8                1           Yes                  No   \n",
       "\n",
       "   TravelInsurance  \n",
       "0                0  \n",
       "1                0  \n",
       "2                1  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"TravelInsurancePrediction.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33d20fe5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Age', 'Employment Type', 'GraduateOrNot', 'AnnualIncome',\n",
       "       'FamilyMembers', 'ChronicDiseases', 'FrequentFlyer',\n",
       "       'EverTravelledAbroad', 'TravelInsurance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "258ab3d2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1987, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74875037",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5af4e7e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Employment Type</th>\n",
       "      <th>GraduateOrNot</th>\n",
       "      <th>AnnualIncome</th>\n",
       "      <th>FamilyMembers</th>\n",
       "      <th>ChronicDiseases</th>\n",
       "      <th>FrequentFlyer</th>\n",
       "      <th>EverTravelledAbroad</th>\n",
       "      <th>TravelInsurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>Government Sector</td>\n",
       "      <td>Yes</td>\n",
       "      <td>400000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>Private Sector/Self Employed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1250000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>Private Sector/Self Employed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Private Sector/Self Employed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>700000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private Sector/Self Employed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>700000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age               Employment Type GraduateOrNot  AnnualIncome  \\\n",
       "0   31             Government Sector           Yes        400000   \n",
       "1   31  Private Sector/Self Employed           Yes       1250000   \n",
       "2   34  Private Sector/Self Employed           Yes        500000   \n",
       "3   28  Private Sector/Self Employed           Yes        700000   \n",
       "4   28  Private Sector/Self Employed           Yes        700000   \n",
       "\n",
       "   FamilyMembers  ChronicDiseases FrequentFlyer EverTravelledAbroad  \\\n",
       "0              6                1            No                  No   \n",
       "1              7                0            No                  No   \n",
       "2              4                1            No                  No   \n",
       "3              3                1            No                  No   \n",
       "4              8                1           Yes                  No   \n",
       "\n",
       "   TravelInsurance  \n",
       "0                0  \n",
       "1                0  \n",
       "2                1  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop([\"Unnamed: 0\"], axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33f22b49",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'GraduateOrNot', 'AnnualIncome', 'FamilyMembers',\n",
       "       'ChronicDiseases', 'FrequentFlyer', 'EverTravelledAbroad',\n",
       "       'TravelInsurance', 'emp_type_1', 'emp_type_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Employment Type'] = data['Employment Type'].map({'Government Sector': 2, \n",
    "                                                        'Private Sector/Self Employed': 1})\n",
    "transformed_data = pd.get_dummies(data['Employment Type'], prefix='emp_type')\n",
    "data = pd.concat([data,transformed_data],axis=1)\n",
    "data = data.drop(['Employment Type'], axis = 1)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24f67425",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'AnnualIncome', 'FamilyMembers', 'ChronicDiseases',\n",
       "       'FrequentFlyer', 'EverTravelledAbroad', 'TravelInsurance', 'emp_type_1',\n",
       "       'emp_type_2', 'grad_status_0', 'grad_status_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['GraduateOrNot'] = data['GraduateOrNot'].map({'Yes': 1, \n",
    "                                                   'No': 0})\n",
    "transformed_data = pd.get_dummies(data['GraduateOrNot'], prefix='grad_status')\n",
    "data = pd.concat([data,transformed_data],axis=1)\n",
    "data = data.drop(['GraduateOrNot'], axis = 1)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "428a8a70",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'AnnualIncome', 'FamilyMembers', 'ChronicDiseases',\n",
       "       'EverTravelledAbroad', 'TravelInsurance', 'emp_type_1', 'emp_type_2',\n",
       "       'grad_status_0', 'grad_status_1', 'freq_flyer_0', 'freq_flyer_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['FrequentFlyer'] = data['FrequentFlyer'].map({'Yes': 1, \n",
    "                                                   'No': 0})\n",
    "transformed_data = pd.get_dummies(data['FrequentFlyer'], prefix='freq_flyer')\n",
    "data = pd.concat([data,transformed_data],axis=1)\n",
    "data = data.drop(['FrequentFlyer'], axis = 1)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eae6f347",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'AnnualIncome', 'FamilyMembers', 'ChronicDiseases',\n",
       "       'TravelInsurance', 'emp_type_1', 'emp_type_2', 'grad_status_0',\n",
       "       'grad_status_1', 'freq_flyer_0', 'freq_flyer_1', 'trav_abroad_0',\n",
       "       'trav_abroad_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['EverTravelledAbroad'] = data['EverTravelledAbroad'].map({'Yes': 1, \n",
    "                                                   'No': 0})\n",
    "transformed_data = pd.get_dummies(data['EverTravelledAbroad'], prefix='trav_abroad')\n",
    "data = pd.concat([data,transformed_data],axis=1)\n",
    "data = data.drop(['EverTravelledAbroad'], axis = 1)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc35499",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Reduce complexity of annual income using a z-score normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00c09329",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mu  = np.mean(data['AnnualIncome'])\n",
    "std = np.std(data['AnnualIncome'])\n",
    "data['AnnualIncome'] =(data['AnnualIncome'] - mu)/std\n",
    "                                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7730dc56",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Prepare the data for analysis. Split the datasets into training, valid and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3272d98",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TravelInsurance_0</th>\n",
       "      <th>TravelInsurance_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TravelInsurance_0  TravelInsurance_1\n",
       "0                  1                  0\n",
       "1                  1                  0\n",
       "2                  0                  1\n",
       "3                  1                  0\n",
       "4                  1                  0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aa192a5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = data.TravelInsurance.values\n",
    "X = data.drop([\"TravelInsurance\"], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.40, \n",
    "                                                    random_state = 42)\n",
    "\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, \n",
    "                                                    test_size = 0.50, \n",
    "                                                    random_state = 42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85e98d34",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'AnnualIncome', 'FamilyMembers', 'ChronicDiseases', 'emp_type_1',\n",
       "       'emp_type_2', 'grad_status_0', 'grad_status_1', 'freq_flyer_0',\n",
       "       'freq_flyer_1', 'trav_abroad_0', 'trav_abroad_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82ec6641",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1192, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0889d0ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'AnnualIncome', 'FamilyMembers', 'ChronicDiseases', 'emp_type_1',\n",
       "       'emp_type_2', 'grad_status_0', 'grad_status_1', 'freq_flyer_0',\n",
       "       'freq_flyer_1', 'trav_abroad_0', 'trav_abroad_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5272af8",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db2c8dcb",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'AnnualIncome', 'FamilyMembers', 'ChronicDiseases', 'emp_type_1',\n",
       "       'emp_type_2', 'grad_status_0', 'grad_status_1', 'freq_flyer_0',\n",
       "       'freq_flyer_1', 'trav_abroad_0', 'trav_abroad_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f25797f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b573ab8a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TravelInsurance_0', 'TravelInsurance_1'], dtype='object')\n",
      "(1192, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_train = pd.get_dummies(y_train, prefix='TravelInsurance')\n",
    "y.head()\n",
    "print(y_train.columns)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d5f37b1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TravelInsurance_0', 'TravelInsurance_1'], dtype='object')\n",
      "(398, 2)\n"
     ]
    }
   ],
   "source": [
    "y_valid = pd.get_dummies(y_valid, prefix='TravelInsurance')\n",
    "print(y_valid.columns)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1cf1819",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TravelInsurance_0', 'TravelInsurance_1'], dtype='object')\n",
      "(397, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.columns)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158eb86",
   "metadata": {},
   "source": [
    "# Create, compile, and train a model\n",
    "\n",
    "X_train has 12 columns -> 12 neurons for input\n",
    "y_train has 2 columns -> 2 neurons for output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0a7c71",
   "metadata": {},
   "source": [
    "## Model one\n",
    "\n",
    "[SGD](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)\n",
    "\n",
    "[Binary Cross entropy](https://www.analyticsvidhya.com/blog/2021/03/binary-cross-entropy-log-loss-for-binary-classification/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa5163c0",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               3328      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,842\n",
      "Trainable params: 3,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(12,)),\n",
    "    tf.keras.layers.Dense(256, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "])\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d5b342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(optimizer='SGD', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c86e9441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "38/38 [==============================] - 1s 6ms/step - loss: 0.6567 - accuracy: 0.6242 - val_loss: 0.6622 - val_accuracy: 0.6256\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.6518 - val_loss: 0.6559 - val_accuracy: 0.6256\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.6518 - val_loss: 0.6536 - val_accuracy: 0.6256\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.6518 - val_loss: 0.6560 - val_accuracy: 0.6256\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.6518 - val_loss: 0.6679 - val_accuracy: 0.6256\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.6518 - val_loss: 0.6541 - val_accuracy: 0.6256\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.6518 - val_loss: 0.6486 - val_accuracy: 0.6256\n",
      "Epoch 8/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.6518 - val_loss: 0.6476 - val_accuracy: 0.6256\n",
      "Epoch 9/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.6518 - val_loss: 0.6517 - val_accuracy: 0.6256\n",
      "Epoch 10/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.6518 - val_loss: 0.6492 - val_accuracy: 0.6256\n",
      "Epoch 11/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6518 - val_loss: 0.6438 - val_accuracy: 0.6256\n",
      "Epoch 12/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.6518 - val_loss: 0.6510 - val_accuracy: 0.6256\n",
      "Epoch 13/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6299 - accuracy: 0.6518 - val_loss: 0.6615 - val_accuracy: 0.6256\n",
      "Epoch 14/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.6518 - val_loss: 0.6414 - val_accuracy: 0.6256\n",
      "Epoch 15/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6284 - accuracy: 0.6518 - val_loss: 0.6391 - val_accuracy: 0.6256\n",
      "Epoch 16/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.6518 - val_loss: 0.6377 - val_accuracy: 0.6256\n",
      "Epoch 17/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.6518 - val_loss: 0.6368 - val_accuracy: 0.6256\n",
      "Epoch 18/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.6518 - val_loss: 0.6377 - val_accuracy: 0.6256\n",
      "Epoch 19/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.6518 - val_loss: 0.6529 - val_accuracy: 0.6256\n",
      "Epoch 20/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6228 - accuracy: 0.6518 - val_loss: 0.6370 - val_accuracy: 0.6256\n",
      "Epoch 21/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.6518 - val_loss: 0.6370 - val_accuracy: 0.6482\n",
      "Epoch 22/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.6527 - val_loss: 0.6376 - val_accuracy: 0.6256\n",
      "Epoch 23/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.6518 - val_loss: 0.6295 - val_accuracy: 0.6256\n",
      "Epoch 24/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.6518 - val_loss: 0.6312 - val_accuracy: 0.6256\n",
      "Epoch 25/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.6518 - val_loss: 0.6272 - val_accuracy: 0.6256\n",
      "Epoch 26/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.6518 - val_loss: 0.6322 - val_accuracy: 0.6256\n",
      "Epoch 27/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6142 - accuracy: 0.6518 - val_loss: 0.6295 - val_accuracy: 0.6683\n",
      "Epoch 28/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.6535 - val_loss: 0.6286 - val_accuracy: 0.6256\n",
      "Epoch 29/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.6518 - val_loss: 0.6226 - val_accuracy: 0.6256\n",
      "Epoch 30/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.6527 - val_loss: 0.6210 - val_accuracy: 0.6256\n",
      "Epoch 31/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.6518 - val_loss: 0.6203 - val_accuracy: 0.6256\n",
      "Epoch 32/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6527 - val_loss: 0.6250 - val_accuracy: 0.6256\n",
      "Epoch 33/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.6527 - val_loss: 0.6179 - val_accuracy: 0.6256\n",
      "Epoch 34/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.6518 - val_loss: 0.6206 - val_accuracy: 0.6256\n",
      "Epoch 35/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.6527 - val_loss: 0.6155 - val_accuracy: 0.6256\n",
      "Epoch 36/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6033 - accuracy: 0.6569 - val_loss: 0.6251 - val_accuracy: 0.6256\n",
      "Epoch 37/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.6535 - val_loss: 0.6234 - val_accuracy: 0.6256\n",
      "Epoch 38/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.6544 - val_loss: 0.6113 - val_accuracy: 0.6482\n",
      "Epoch 39/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6005 - accuracy: 0.6577 - val_loss: 0.6133 - val_accuracy: 0.7236\n",
      "Epoch 40/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.6628 - val_loss: 0.6250 - val_accuracy: 0.6256\n",
      "Epoch 41/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.6552 - val_loss: 0.6079 - val_accuracy: 0.6834\n",
      "Epoch 42/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.6728 - val_loss: 0.6311 - val_accuracy: 0.6256\n",
      "Epoch 43/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.6569 - val_loss: 0.6157 - val_accuracy: 0.6256\n",
      "Epoch 44/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.6669 - val_loss: 0.6045 - val_accuracy: 0.7010\n",
      "Epoch 45/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.6846 - val_loss: 0.6117 - val_accuracy: 0.6256\n",
      "Epoch 46/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.6703 - val_loss: 0.6176 - val_accuracy: 0.6256\n",
      "Epoch 47/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.6669 - val_loss: 0.6030 - val_accuracy: 0.7663\n",
      "Epoch 48/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.6896 - val_loss: 0.5999 - val_accuracy: 0.7261\n",
      "Epoch 49/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.6871 - val_loss: 0.6007 - val_accuracy: 0.6558\n",
      "Epoch 50/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.6862 - val_loss: 0.5973 - val_accuracy: 0.6985\n",
      "Epoch 51/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.6846 - val_loss: 0.5960 - val_accuracy: 0.7161\n",
      "Epoch 52/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.6971 - val_loss: 0.5961 - val_accuracy: 0.7688\n",
      "Epoch 53/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.7030 - val_loss: 0.5947 - val_accuracy: 0.6859\n",
      "Epoch 54/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7039 - val_loss: 0.5928 - val_accuracy: 0.7111\n",
      "Epoch 55/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7223 - val_loss: 0.6053 - val_accuracy: 0.6231\n",
      "Epoch 56/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.7064 - val_loss: 0.5937 - val_accuracy: 0.6784\n",
      "Epoch 57/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.7097 - val_loss: 0.6085 - val_accuracy: 0.6231\n",
      "Epoch 58/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.6980 - val_loss: 0.5898 - val_accuracy: 0.7688\n",
      "Epoch 59/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7265 - val_loss: 0.5883 - val_accuracy: 0.7136\n",
      "Epoch 60/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.7273 - val_loss: 0.5861 - val_accuracy: 0.7739\n",
      "Epoch 61/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5766 - accuracy: 0.7332 - val_loss: 0.5870 - val_accuracy: 0.7136\n",
      "Epoch 62/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.7307 - val_loss: 0.5921 - val_accuracy: 0.7487\n",
      "Epoch 63/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.7332 - val_loss: 0.5856 - val_accuracy: 0.7161\n",
      "Epoch 64/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7383 - val_loss: 0.5822 - val_accuracy: 0.7538\n",
      "Epoch 65/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.7416 - val_loss: 0.5822 - val_accuracy: 0.7638\n",
      "Epoch 66/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7458 - val_loss: 0.5806 - val_accuracy: 0.7538\n",
      "Epoch 67/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5693 - accuracy: 0.7416 - val_loss: 0.5823 - val_accuracy: 0.7663\n",
      "Epoch 68/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.7534 - val_loss: 0.5782 - val_accuracy: 0.7739\n",
      "Epoch 69/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7550 - val_loss: 0.5797 - val_accuracy: 0.7312\n",
      "Epoch 70/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.7542 - val_loss: 0.5858 - val_accuracy: 0.6960\n",
      "Epoch 71/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7433 - val_loss: 0.5766 - val_accuracy: 0.7663\n",
      "Epoch 72/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5667 - accuracy: 0.7567 - val_loss: 0.6112 - val_accuracy: 0.6357\n",
      "Epoch 73/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7534 - val_loss: 0.5776 - val_accuracy: 0.7362\n",
      "Epoch 74/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7693 - val_loss: 0.5871 - val_accuracy: 0.6935\n",
      "Epoch 75/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.7634 - val_loss: 0.5845 - val_accuracy: 0.7035\n",
      "Epoch 76/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7626 - val_loss: 0.5804 - val_accuracy: 0.7261\n",
      "Epoch 77/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.7659 - val_loss: 0.5819 - val_accuracy: 0.7186\n",
      "Epoch 78/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7576 - val_loss: 0.5745 - val_accuracy: 0.7487\n",
      "Epoch 79/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7676 - val_loss: 0.5973 - val_accuracy: 0.6734\n",
      "Epoch 80/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.7617 - val_loss: 0.5714 - val_accuracy: 0.7513\n",
      "Epoch 81/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.7710 - val_loss: 0.5676 - val_accuracy: 0.7663\n",
      "Epoch 82/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7735 - val_loss: 0.5793 - val_accuracy: 0.7286\n",
      "Epoch 83/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.7768 - val_loss: 0.5662 - val_accuracy: 0.7638\n",
      "Epoch 84/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.7768 - val_loss: 0.5671 - val_accuracy: 0.7638\n",
      "Epoch 85/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7777 - val_loss: 0.5661 - val_accuracy: 0.7688\n",
      "Epoch 86/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.7743 - val_loss: 0.5645 - val_accuracy: 0.7638\n",
      "Epoch 87/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7710 - val_loss: 0.5712 - val_accuracy: 0.7538\n",
      "Epoch 88/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7718 - val_loss: 0.5691 - val_accuracy: 0.7739\n",
      "Epoch 89/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7777 - val_loss: 0.5659 - val_accuracy: 0.7513\n",
      "Epoch 90/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5540 - accuracy: 0.7735 - val_loss: 0.5765 - val_accuracy: 0.7362\n",
      "Epoch 91/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7743 - val_loss: 0.5750 - val_accuracy: 0.7462\n",
      "Epoch 92/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.7727 - val_loss: 0.5654 - val_accuracy: 0.7538\n",
      "Epoch 93/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7743 - val_loss: 0.5661 - val_accuracy: 0.7538\n",
      "Epoch 94/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.7785 - val_loss: 0.5620 - val_accuracy: 0.7663\n",
      "Epoch 95/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7743 - val_loss: 0.5688 - val_accuracy: 0.7764\n",
      "Epoch 96/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7768 - val_loss: 0.5603 - val_accuracy: 0.7638\n",
      "Epoch 97/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.7836 - val_loss: 0.5603 - val_accuracy: 0.7663\n",
      "Epoch 98/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.7718 - val_loss: 0.5659 - val_accuracy: 0.7764\n",
      "Epoch 99/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7752 - val_loss: 0.5676 - val_accuracy: 0.7764\n",
      "Epoch 100/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7760 - val_loss: 0.5600 - val_accuracy: 0.7663\n",
      "Epoch 101/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5479 - accuracy: 0.7777 - val_loss: 0.5619 - val_accuracy: 0.7714\n",
      "Epoch 102/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.7676 - val_loss: 0.5711 - val_accuracy: 0.7688\n",
      "Epoch 103/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.7785 - val_loss: 0.6192 - val_accuracy: 0.6784\n",
      "Epoch 104/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7718 - val_loss: 0.5585 - val_accuracy: 0.7638\n",
      "Epoch 105/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7760 - val_loss: 0.5622 - val_accuracy: 0.7714\n",
      "Epoch 106/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7743 - val_loss: 0.5599 - val_accuracy: 0.7538\n",
      "Epoch 107/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7760 - val_loss: 0.5543 - val_accuracy: 0.7714\n",
      "Epoch 108/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7710 - val_loss: 0.5539 - val_accuracy: 0.7714\n",
      "Epoch 109/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.7810 - val_loss: 0.5536 - val_accuracy: 0.7688\n",
      "Epoch 110/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7752 - val_loss: 0.5533 - val_accuracy: 0.7663\n",
      "Epoch 111/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.7768 - val_loss: 0.5595 - val_accuracy: 0.7663\n",
      "Epoch 112/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7794 - val_loss: 0.5586 - val_accuracy: 0.7663\n",
      "Epoch 113/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7794 - val_loss: 0.5536 - val_accuracy: 0.7613\n",
      "Epoch 114/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.7794 - val_loss: 0.5521 - val_accuracy: 0.7688\n",
      "Epoch 115/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7710 - val_loss: 0.5708 - val_accuracy: 0.7739\n",
      "Epoch 116/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7794 - val_loss: 0.5557 - val_accuracy: 0.7638\n",
      "Epoch 117/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7777 - val_loss: 0.5529 - val_accuracy: 0.7538\n",
      "Epoch 118/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.7752 - val_loss: 0.5694 - val_accuracy: 0.7764\n",
      "Epoch 119/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7768 - val_loss: 0.5552 - val_accuracy: 0.7638\n",
      "Epoch 120/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7777 - val_loss: 0.5510 - val_accuracy: 0.7638\n",
      "Epoch 121/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7710 - val_loss: 0.5514 - val_accuracy: 0.7513\n",
      "Epoch 122/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7634 - val_loss: 0.5821 - val_accuracy: 0.7588\n",
      "Epoch 123/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7794 - val_loss: 0.5675 - val_accuracy: 0.7789\n",
      "Epoch 124/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7752 - val_loss: 0.5559 - val_accuracy: 0.7638\n",
      "Epoch 125/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7785 - val_loss: 0.5523 - val_accuracy: 0.7513\n",
      "Epoch 126/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7752 - val_loss: 0.5488 - val_accuracy: 0.7739\n",
      "Epoch 127/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7727 - val_loss: 0.5514 - val_accuracy: 0.7513\n",
      "Epoch 128/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7760 - val_loss: 0.5494 - val_accuracy: 0.7588\n",
      "Epoch 129/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7710 - val_loss: 0.5562 - val_accuracy: 0.7638\n",
      "Epoch 130/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7710 - val_loss: 0.5576 - val_accuracy: 0.7638\n",
      "Epoch 131/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7710 - val_loss: 0.5514 - val_accuracy: 0.7487\n",
      "Epoch 132/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7752 - val_loss: 0.5477 - val_accuracy: 0.7688\n",
      "Epoch 133/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7735 - val_loss: 0.5477 - val_accuracy: 0.7714\n",
      "Epoch 134/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7743 - val_loss: 0.5670 - val_accuracy: 0.7739\n",
      "Epoch 135/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7685 - val_loss: 0.5543 - val_accuracy: 0.7638\n",
      "Epoch 136/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7777 - val_loss: 0.5513 - val_accuracy: 0.7613\n",
      "Epoch 137/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7701 - val_loss: 0.5491 - val_accuracy: 0.7563\n",
      "Epoch 138/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7710 - val_loss: 0.5476 - val_accuracy: 0.7588\n",
      "Epoch 139/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7735 - val_loss: 0.5512 - val_accuracy: 0.7613\n",
      "Epoch 140/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7777 - val_loss: 0.5472 - val_accuracy: 0.7588\n",
      "Epoch 141/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7743 - val_loss: 0.5623 - val_accuracy: 0.7663\n",
      "Epoch 142/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7777 - val_loss: 0.5463 - val_accuracy: 0.7663\n",
      "Epoch 143/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5375 - accuracy: 0.7668 - val_loss: 0.5492 - val_accuracy: 0.7613\n",
      "Epoch 144/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5375 - accuracy: 0.7701 - val_loss: 0.5476 - val_accuracy: 0.7613\n",
      "Epoch 145/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7768 - val_loss: 0.5564 - val_accuracy: 0.7638\n",
      "Epoch 146/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7743 - val_loss: 0.5576 - val_accuracy: 0.7638\n",
      "Epoch 147/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7743 - val_loss: 0.5453 - val_accuracy: 0.7663\n",
      "Epoch 148/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7760 - val_loss: 0.5674 - val_accuracy: 0.6683\n",
      "Epoch 149/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7676 - val_loss: 0.5599 - val_accuracy: 0.7638\n",
      "Epoch 150/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.7768 - val_loss: 0.5488 - val_accuracy: 0.7513\n",
      "Epoch 151/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7651 - val_loss: 0.5533 - val_accuracy: 0.7638\n",
      "Epoch 152/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7727 - val_loss: 0.5453 - val_accuracy: 0.7714\n",
      "Epoch 153/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.7727 - val_loss: 0.5890 - val_accuracy: 0.7688\n",
      "Epoch 154/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7710 - val_loss: 0.5563 - val_accuracy: 0.7663\n",
      "Epoch 155/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7768 - val_loss: 0.5447 - val_accuracy: 0.7638\n",
      "Epoch 156/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7718 - val_loss: 0.5465 - val_accuracy: 0.7513\n",
      "Epoch 157/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7768 - val_loss: 0.5544 - val_accuracy: 0.7161\n",
      "Epoch 158/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7676 - val_loss: 0.5694 - val_accuracy: 0.7739\n",
      "Epoch 159/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.7735 - val_loss: 0.5466 - val_accuracy: 0.7613\n",
      "Epoch 160/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.7710 - val_loss: 0.5440 - val_accuracy: 0.7764\n",
      "Epoch 161/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7693 - val_loss: 0.5632 - val_accuracy: 0.7663\n",
      "Epoch 162/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7710 - val_loss: 0.5763 - val_accuracy: 0.7789\n",
      "Epoch 163/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7735 - val_loss: 0.5616 - val_accuracy: 0.7638\n",
      "Epoch 164/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7785 - val_loss: 0.5431 - val_accuracy: 0.7764\n",
      "Epoch 165/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7760 - val_loss: 0.5844 - val_accuracy: 0.7764\n",
      "Epoch 166/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7693 - val_loss: 0.5839 - val_accuracy: 0.7764\n",
      "Epoch 167/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7760 - val_loss: 0.5962 - val_accuracy: 0.7513\n",
      "Epoch 168/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7743 - val_loss: 0.5459 - val_accuracy: 0.7613\n",
      "Epoch 169/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7710 - val_loss: 0.5518 - val_accuracy: 0.7613\n",
      "Epoch 170/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7743 - val_loss: 0.5806 - val_accuracy: 0.7789\n",
      "Epoch 171/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7701 - val_loss: 0.5670 - val_accuracy: 0.7688\n",
      "Epoch 172/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7760 - val_loss: 0.5553 - val_accuracy: 0.7035\n",
      "Epoch 173/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7659 - val_loss: 0.5579 - val_accuracy: 0.6910\n",
      "Epoch 174/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7634 - val_loss: 0.5637 - val_accuracy: 0.7688\n",
      "Epoch 175/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7827 - val_loss: 0.5650 - val_accuracy: 0.6683\n",
      "Epoch 176/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7718 - val_loss: 0.5488 - val_accuracy: 0.7613\n",
      "Epoch 177/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7718 - val_loss: 0.5464 - val_accuracy: 0.7613\n",
      "Epoch 178/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7685 - val_loss: 0.5551 - val_accuracy: 0.7638\n",
      "Epoch 179/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.7777 - val_loss: 0.5550 - val_accuracy: 0.7060\n",
      "Epoch 180/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7743 - val_loss: 0.5458 - val_accuracy: 0.7613\n",
      "Epoch 181/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7735 - val_loss: 0.5482 - val_accuracy: 0.7613\n",
      "Epoch 182/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7735 - val_loss: 0.5428 - val_accuracy: 0.7663\n",
      "Epoch 183/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7743 - val_loss: 0.5447 - val_accuracy: 0.7513\n",
      "Epoch 184/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7777 - val_loss: 0.5455 - val_accuracy: 0.7513\n",
      "Epoch 185/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7743 - val_loss: 0.5579 - val_accuracy: 0.7663\n",
      "Epoch 186/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.7718 - val_loss: 0.5434 - val_accuracy: 0.7638\n",
      "Epoch 187/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7768 - val_loss: 0.5433 - val_accuracy: 0.7638\n",
      "Epoch 188/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7710 - val_loss: 0.5439 - val_accuracy: 0.7638\n",
      "Epoch 189/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7760 - val_loss: 0.5865 - val_accuracy: 0.6382\n",
      "Epoch 190/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7643 - val_loss: 0.5649 - val_accuracy: 0.6683\n",
      "Epoch 191/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.7718 - val_loss: 0.5894 - val_accuracy: 0.7739\n",
      "Epoch 192/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7752 - val_loss: 0.5409 - val_accuracy: 0.7789\n",
      "Epoch 193/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7743 - val_loss: 0.5633 - val_accuracy: 0.7663\n",
      "Epoch 194/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7794 - val_loss: 0.5422 - val_accuracy: 0.7638\n",
      "Epoch 195/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7735 - val_loss: 0.5412 - val_accuracy: 0.7638\n",
      "Epoch 196/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7794 - val_loss: 0.5407 - val_accuracy: 0.7663\n",
      "Epoch 197/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7718 - val_loss: 0.5402 - val_accuracy: 0.7764\n",
      "Epoch 198/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7727 - val_loss: 0.5408 - val_accuracy: 0.7789\n",
      "Epoch 199/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7752 - val_loss: 0.5439 - val_accuracy: 0.7487\n",
      "Epoch 200/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7752 - val_loss: 0.5706 - val_accuracy: 0.7688\n",
      "Epoch 201/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7718 - val_loss: 0.5545 - val_accuracy: 0.7638\n",
      "Epoch 202/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7777 - val_loss: 0.5403 - val_accuracy: 0.7688\n",
      "Epoch 203/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.7735 - val_loss: 0.5397 - val_accuracy: 0.7764\n",
      "Epoch 204/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.7693 - val_loss: 0.5626 - val_accuracy: 0.7663\n",
      "Epoch 205/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7727 - val_loss: 0.5395 - val_accuracy: 0.7814\n",
      "Epoch 206/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.7727 - val_loss: 0.5554 - val_accuracy: 0.7638\n",
      "Epoch 207/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.7785 - val_loss: 0.5443 - val_accuracy: 0.7638\n",
      "Epoch 208/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7735 - val_loss: 0.5606 - val_accuracy: 0.7688\n",
      "Epoch 209/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7802 - val_loss: 0.5515 - val_accuracy: 0.7613\n",
      "Epoch 210/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.7718 - val_loss: 0.5556 - val_accuracy: 0.7638\n",
      "Epoch 211/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7718 - val_loss: 0.5523 - val_accuracy: 0.7613\n",
      "Epoch 212/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7735 - val_loss: 0.5443 - val_accuracy: 0.7638\n",
      "Epoch 213/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7752 - val_loss: 0.5572 - val_accuracy: 0.6859\n",
      "Epoch 214/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.7718 - val_loss: 0.5413 - val_accuracy: 0.7663\n",
      "Epoch 215/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7743 - val_loss: 0.5810 - val_accuracy: 0.7739\n",
      "Epoch 216/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7760 - val_loss: 0.5403 - val_accuracy: 0.7688\n",
      "Epoch 217/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7743 - val_loss: 0.5392 - val_accuracy: 0.7638\n",
      "Epoch 218/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7727 - val_loss: 0.5406 - val_accuracy: 0.7663\n",
      "Epoch 219/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7743 - val_loss: 0.5386 - val_accuracy: 0.7839\n",
      "Epoch 220/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7768 - val_loss: 0.5388 - val_accuracy: 0.7688\n",
      "Epoch 221/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.7710 - val_loss: 0.5387 - val_accuracy: 0.7789\n",
      "Epoch 222/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7693 - val_loss: 0.5967 - val_accuracy: 0.7688\n",
      "Epoch 223/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7718 - val_loss: 0.5400 - val_accuracy: 0.7663\n",
      "Epoch 224/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7760 - val_loss: 0.5384 - val_accuracy: 0.7789\n",
      "Epoch 225/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7693 - val_loss: 0.5733 - val_accuracy: 0.7688\n",
      "Epoch 226/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7743 - val_loss: 0.5466 - val_accuracy: 0.7613\n",
      "Epoch 227/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7785 - val_loss: 0.5488 - val_accuracy: 0.7613\n",
      "Epoch 228/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7718 - val_loss: 0.5548 - val_accuracy: 0.7613\n",
      "Epoch 229/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7768 - val_loss: 0.5392 - val_accuracy: 0.7714\n",
      "Epoch 230/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7760 - val_loss: 0.5559 - val_accuracy: 0.7638\n",
      "Epoch 231/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7777 - val_loss: 0.5385 - val_accuracy: 0.7688\n",
      "Epoch 232/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7760 - val_loss: 0.5398 - val_accuracy: 0.7663\n",
      "Epoch 233/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7727 - val_loss: 0.5391 - val_accuracy: 0.7588\n",
      "Epoch 234/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7735 - val_loss: 0.5386 - val_accuracy: 0.7789\n",
      "Epoch 235/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7794 - val_loss: 0.5646 - val_accuracy: 0.6683\n",
      "Epoch 236/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7651 - val_loss: 0.5441 - val_accuracy: 0.7638\n",
      "Epoch 237/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7752 - val_loss: 0.5536 - val_accuracy: 0.7613\n",
      "Epoch 238/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7685 - val_loss: 0.5749 - val_accuracy: 0.7688\n",
      "Epoch 239/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7777 - val_loss: 0.5379 - val_accuracy: 0.7714\n",
      "Epoch 240/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7777 - val_loss: 0.5425 - val_accuracy: 0.7638\n",
      "Epoch 241/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7752 - val_loss: 0.5412 - val_accuracy: 0.7513\n",
      "Epoch 242/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7760 - val_loss: 0.5411 - val_accuracy: 0.7663\n",
      "Epoch 243/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7760 - val_loss: 0.5924 - val_accuracy: 0.7663\n",
      "Epoch 244/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.7836 - val_loss: 0.5373 - val_accuracy: 0.7714\n",
      "Epoch 245/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.7735 - val_loss: 0.5374 - val_accuracy: 0.7688\n",
      "Epoch 246/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7743 - val_loss: 0.5370 - val_accuracy: 0.7789\n",
      "Epoch 247/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7752 - val_loss: 0.5372 - val_accuracy: 0.7789\n",
      "Epoch 248/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7743 - val_loss: 0.5554 - val_accuracy: 0.7638\n",
      "Epoch 249/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7701 - val_loss: 0.5581 - val_accuracy: 0.7663\n",
      "Epoch 250/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7735 - val_loss: 0.5417 - val_accuracy: 0.7487\n",
      "Epoch 251/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7651 - val_loss: 0.5372 - val_accuracy: 0.7789\n",
      "Epoch 252/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7752 - val_loss: 0.5402 - val_accuracy: 0.7663\n",
      "Epoch 253/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7735 - val_loss: 0.5609 - val_accuracy: 0.7663\n",
      "Epoch 254/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7710 - val_loss: 0.5415 - val_accuracy: 0.7663\n",
      "Epoch 255/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7743 - val_loss: 0.5367 - val_accuracy: 0.7764\n",
      "Epoch 256/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7710 - val_loss: 0.5831 - val_accuracy: 0.6432\n",
      "Epoch 257/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7668 - val_loss: 0.5367 - val_accuracy: 0.7714\n",
      "Epoch 258/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7743 - val_loss: 0.5364 - val_accuracy: 0.7764\n",
      "Epoch 259/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7727 - val_loss: 0.5396 - val_accuracy: 0.7663\n",
      "Epoch 260/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7735 - val_loss: 0.5471 - val_accuracy: 0.7638\n",
      "Epoch 261/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7735 - val_loss: 0.5477 - val_accuracy: 0.7638\n",
      "Epoch 262/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7760 - val_loss: 0.5377 - val_accuracy: 0.7638\n",
      "Epoch 263/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7810 - val_loss: 0.5374 - val_accuracy: 0.7638\n",
      "Epoch 264/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.7743 - val_loss: 0.5522 - val_accuracy: 0.7136\n",
      "Epoch 265/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7693 - val_loss: 0.5612 - val_accuracy: 0.7688\n",
      "Epoch 266/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7785 - val_loss: 0.5464 - val_accuracy: 0.7638\n",
      "Epoch 267/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7743 - val_loss: 0.5409 - val_accuracy: 0.7538\n",
      "Epoch 268/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7693 - val_loss: 0.5523 - val_accuracy: 0.7613\n",
      "Epoch 269/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7760 - val_loss: 0.5407 - val_accuracy: 0.7663\n",
      "Epoch 270/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7752 - val_loss: 0.5695 - val_accuracy: 0.7663\n",
      "Epoch 271/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7777 - val_loss: 0.5532 - val_accuracy: 0.7638\n",
      "Epoch 272/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7752 - val_loss: 0.5381 - val_accuracy: 0.7688\n",
      "Epoch 273/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7777 - val_loss: 0.5456 - val_accuracy: 0.7638\n",
      "Epoch 274/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7752 - val_loss: 0.5365 - val_accuracy: 0.7714\n",
      "Epoch 275/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7802 - val_loss: 0.5533 - val_accuracy: 0.7111\n",
      "Epoch 276/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7651 - val_loss: 0.5416 - val_accuracy: 0.7663\n",
      "Epoch 277/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7743 - val_loss: 0.5454 - val_accuracy: 0.7638\n",
      "Epoch 278/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7827 - val_loss: 0.5598 - val_accuracy: 0.6709\n",
      "Epoch 279/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7710 - val_loss: 0.5354 - val_accuracy: 0.7764\n",
      "Epoch 280/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7743 - val_loss: 0.5378 - val_accuracy: 0.7563\n",
      "Epoch 281/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7794 - val_loss: 0.5365 - val_accuracy: 0.7688\n",
      "Epoch 282/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7768 - val_loss: 0.5442 - val_accuracy: 0.7638\n",
      "Epoch 283/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7760 - val_loss: 0.5546 - val_accuracy: 0.6985\n",
      "Epoch 284/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7701 - val_loss: 0.5582 - val_accuracy: 0.7638\n",
      "Epoch 285/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7785 - val_loss: 0.5371 - val_accuracy: 0.7688\n",
      "Epoch 286/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7802 - val_loss: 0.5352 - val_accuracy: 0.7764\n",
      "Epoch 287/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7752 - val_loss: 0.5484 - val_accuracy: 0.7286\n",
      "Epoch 288/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7735 - val_loss: 0.5579 - val_accuracy: 0.7638\n",
      "Epoch 289/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7785 - val_loss: 0.5385 - val_accuracy: 0.7663\n",
      "Epoch 290/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7785 - val_loss: 0.5355 - val_accuracy: 0.7764\n",
      "Epoch 291/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7777 - val_loss: 0.5510 - val_accuracy: 0.7638\n",
      "Epoch 292/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7727 - val_loss: 0.5818 - val_accuracy: 0.7638\n",
      "Epoch 293/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7768 - val_loss: 0.5467 - val_accuracy: 0.7638\n",
      "Epoch 294/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7752 - val_loss: 0.5760 - val_accuracy: 0.7638\n",
      "Epoch 295/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7802 - val_loss: 0.5359 - val_accuracy: 0.7663\n",
      "Epoch 296/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.7727 - val_loss: 0.5349 - val_accuracy: 0.7764\n",
      "Epoch 297/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7693 - val_loss: 0.5434 - val_accuracy: 0.7638\n",
      "Epoch 298/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7718 - val_loss: 0.5496 - val_accuracy: 0.7613\n",
      "Epoch 299/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7743 - val_loss: 0.5381 - val_accuracy: 0.7563\n",
      "Epoch 300/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7760 - val_loss: 0.5350 - val_accuracy: 0.7739\n",
      "Epoch 301/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7668 - val_loss: 0.5508 - val_accuracy: 0.7638\n",
      "Epoch 302/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7760 - val_loss: 0.5389 - val_accuracy: 0.7663\n",
      "Epoch 303/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7777 - val_loss: 0.5348 - val_accuracy: 0.7764\n",
      "Epoch 304/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7785 - val_loss: 0.5382 - val_accuracy: 0.7688\n",
      "Epoch 305/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.7735 - val_loss: 0.5364 - val_accuracy: 0.7638\n",
      "Epoch 306/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7760 - val_loss: 0.5544 - val_accuracy: 0.7638\n",
      "Epoch 307/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7785 - val_loss: 0.5485 - val_accuracy: 0.7638\n",
      "Epoch 308/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7785 - val_loss: 0.5742 - val_accuracy: 0.6608\n",
      "Epoch 309/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7659 - val_loss: 0.5344 - val_accuracy: 0.7764\n",
      "Epoch 310/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7735 - val_loss: 0.5413 - val_accuracy: 0.7663\n",
      "Epoch 311/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7735 - val_loss: 0.5343 - val_accuracy: 0.7739\n",
      "Epoch 312/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7802 - val_loss: 0.5395 - val_accuracy: 0.7538\n",
      "Epoch 313/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7752 - val_loss: 0.5366 - val_accuracy: 0.7613\n",
      "Epoch 314/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7785 - val_loss: 0.5357 - val_accuracy: 0.7663\n",
      "Epoch 315/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7718 - val_loss: 0.5706 - val_accuracy: 0.7638\n",
      "Epoch 316/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7760 - val_loss: 0.5702 - val_accuracy: 0.7638\n",
      "Epoch 317/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7794 - val_loss: 0.5339 - val_accuracy: 0.7764\n",
      "Epoch 318/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7785 - val_loss: 0.5626 - val_accuracy: 0.7688\n",
      "Epoch 319/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7752 - val_loss: 0.5369 - val_accuracy: 0.7563\n",
      "Epoch 320/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7760 - val_loss: 0.5344 - val_accuracy: 0.7688\n",
      "Epoch 321/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7735 - val_loss: 0.5363 - val_accuracy: 0.7688\n",
      "Epoch 322/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7785 - val_loss: 0.5378 - val_accuracy: 0.7688\n",
      "Epoch 323/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7760 - val_loss: 0.5365 - val_accuracy: 0.7688\n",
      "Epoch 324/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7752 - val_loss: 0.5342 - val_accuracy: 0.7688\n",
      "Epoch 325/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7735 - val_loss: 0.5437 - val_accuracy: 0.7638\n",
      "Epoch 326/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7785 - val_loss: 0.5474 - val_accuracy: 0.7638\n",
      "Epoch 327/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.7743 - val_loss: 0.5385 - val_accuracy: 0.7663\n",
      "Epoch 328/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7735 - val_loss: 0.5382 - val_accuracy: 0.7688\n",
      "Epoch 329/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.7668 - val_loss: 0.5478 - val_accuracy: 0.7638\n",
      "Epoch 330/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7743 - val_loss: 0.5337 - val_accuracy: 0.7739\n",
      "Epoch 331/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7735 - val_loss: 0.5340 - val_accuracy: 0.7764\n",
      "Epoch 332/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.7727 - val_loss: 0.5352 - val_accuracy: 0.7638\n",
      "Epoch 333/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7735 - val_loss: 0.5545 - val_accuracy: 0.7638\n",
      "Epoch 334/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7735 - val_loss: 0.5346 - val_accuracy: 0.7638\n",
      "Epoch 335/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7743 - val_loss: 0.5676 - val_accuracy: 0.7638\n",
      "Epoch 336/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7735 - val_loss: 0.5351 - val_accuracy: 0.7638\n",
      "Epoch 337/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7727 - val_loss: 0.5405 - val_accuracy: 0.7462\n",
      "Epoch 338/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7785 - val_loss: 0.5350 - val_accuracy: 0.7663\n",
      "Epoch 339/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7727 - val_loss: 0.5352 - val_accuracy: 0.7663\n",
      "Epoch 340/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7777 - val_loss: 0.5361 - val_accuracy: 0.7588\n",
      "Epoch 341/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7743 - val_loss: 0.5369 - val_accuracy: 0.7688\n",
      "Epoch 342/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7735 - val_loss: 0.5373 - val_accuracy: 0.7588\n",
      "Epoch 343/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7685 - val_loss: 0.5511 - val_accuracy: 0.7663\n",
      "Epoch 344/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7819 - val_loss: 0.5376 - val_accuracy: 0.7688\n",
      "Epoch 345/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7777 - val_loss: 0.5335 - val_accuracy: 0.7714\n",
      "Epoch 346/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7743 - val_loss: 0.5340 - val_accuracy: 0.7663\n",
      "Epoch 347/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7777 - val_loss: 0.5358 - val_accuracy: 0.7663\n",
      "Epoch 348/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7727 - val_loss: 0.5392 - val_accuracy: 0.7663\n",
      "Epoch 349/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7735 - val_loss: 0.5411 - val_accuracy: 0.7663\n",
      "Epoch 350/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.7727 - val_loss: 0.5501 - val_accuracy: 0.7663\n",
      "Epoch 351/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7819 - val_loss: 0.5333 - val_accuracy: 0.7714\n",
      "Epoch 352/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.7735 - val_loss: 0.5429 - val_accuracy: 0.7663\n",
      "Epoch 353/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7743 - val_loss: 0.5353 - val_accuracy: 0.7663\n",
      "Epoch 354/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7777 - val_loss: 0.5693 - val_accuracy: 0.7613\n",
      "Epoch 355/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7802 - val_loss: 0.5414 - val_accuracy: 0.7663\n",
      "Epoch 356/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7802 - val_loss: 0.5540 - val_accuracy: 0.7638\n",
      "Epoch 357/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7861 - val_loss: 0.5671 - val_accuracy: 0.7638\n",
      "Epoch 358/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7743 - val_loss: 0.5596 - val_accuracy: 0.7638\n",
      "Epoch 359/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7760 - val_loss: 0.5378 - val_accuracy: 0.7688\n",
      "Epoch 360/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7777 - val_loss: 0.5592 - val_accuracy: 0.6759\n",
      "Epoch 361/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7710 - val_loss: 0.5342 - val_accuracy: 0.7638\n",
      "Epoch 362/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7785 - val_loss: 0.5386 - val_accuracy: 0.7663\n",
      "Epoch 363/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7735 - val_loss: 0.5431 - val_accuracy: 0.7663\n",
      "Epoch 364/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7743 - val_loss: 0.5337 - val_accuracy: 0.7638\n",
      "Epoch 365/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7760 - val_loss: 0.5500 - val_accuracy: 0.7663\n",
      "Epoch 366/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7777 - val_loss: 0.5412 - val_accuracy: 0.7663\n",
      "Epoch 367/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7760 - val_loss: 0.5349 - val_accuracy: 0.7663\n",
      "Epoch 368/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7743 - val_loss: 0.5355 - val_accuracy: 0.7613\n",
      "Epoch 369/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7710 - val_loss: 0.5376 - val_accuracy: 0.7538\n",
      "Epoch 370/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7718 - val_loss: 0.5503 - val_accuracy: 0.7211\n",
      "Epoch 371/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7685 - val_loss: 0.5322 - val_accuracy: 0.7663\n",
      "Epoch 372/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7777 - val_loss: 0.5329 - val_accuracy: 0.7638\n",
      "Epoch 373/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7743 - val_loss: 0.5570 - val_accuracy: 0.7638\n",
      "Epoch 374/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7802 - val_loss: 0.5419 - val_accuracy: 0.7663\n",
      "Epoch 375/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7794 - val_loss: 0.5326 - val_accuracy: 0.7688\n",
      "Epoch 376/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7768 - val_loss: 0.5486 - val_accuracy: 0.7286\n",
      "Epoch 377/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7785 - val_loss: 0.5412 - val_accuracy: 0.7663\n",
      "Epoch 378/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7752 - val_loss: 0.5334 - val_accuracy: 0.7638\n",
      "Epoch 379/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7760 - val_loss: 0.5359 - val_accuracy: 0.7663\n",
      "Epoch 380/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7802 - val_loss: 0.5319 - val_accuracy: 0.7739\n",
      "Epoch 381/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7768 - val_loss: 0.5410 - val_accuracy: 0.7663\n",
      "Epoch 382/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7760 - val_loss: 0.5323 - val_accuracy: 0.7638\n",
      "Epoch 383/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7777 - val_loss: 0.5320 - val_accuracy: 0.7688\n",
      "Epoch 384/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7777 - val_loss: 0.5422 - val_accuracy: 0.7437\n",
      "Epoch 385/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7710 - val_loss: 0.5364 - val_accuracy: 0.7688\n",
      "Epoch 386/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7760 - val_loss: 0.5414 - val_accuracy: 0.7663\n",
      "Epoch 387/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7735 - val_loss: 0.5320 - val_accuracy: 0.7714\n",
      "Epoch 388/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7777 - val_loss: 0.5318 - val_accuracy: 0.7714\n",
      "Epoch 389/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7743 - val_loss: 0.5325 - val_accuracy: 0.7714\n",
      "Epoch 390/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7727 - val_loss: 0.5431 - val_accuracy: 0.7663\n",
      "Epoch 391/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7794 - val_loss: 0.5356 - val_accuracy: 0.7663\n",
      "Epoch 392/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7718 - val_loss: 0.5354 - val_accuracy: 0.7663\n",
      "Epoch 393/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7752 - val_loss: 0.5499 - val_accuracy: 0.7663\n",
      "Epoch 394/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7810 - val_loss: 0.5345 - val_accuracy: 0.7638\n",
      "Epoch 395/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7760 - val_loss: 0.5430 - val_accuracy: 0.7663\n",
      "Epoch 396/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7768 - val_loss: 0.5313 - val_accuracy: 0.7739\n",
      "Epoch 397/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7743 - val_loss: 0.5315 - val_accuracy: 0.7663\n",
      "Epoch 398/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7760 - val_loss: 0.5670 - val_accuracy: 0.7638\n",
      "Epoch 399/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7743 - val_loss: 0.5733 - val_accuracy: 0.7588\n",
      "Epoch 400/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7760 - val_loss: 0.5343 - val_accuracy: 0.7613\n",
      "Epoch 401/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7743 - val_loss: 0.5313 - val_accuracy: 0.7714\n",
      "Epoch 402/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7768 - val_loss: 0.5324 - val_accuracy: 0.7739\n",
      "Epoch 403/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7760 - val_loss: 0.5310 - val_accuracy: 0.7739\n",
      "Epoch 404/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7819 - val_loss: 0.5312 - val_accuracy: 0.7714\n",
      "Epoch 405/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7768 - val_loss: 0.5641 - val_accuracy: 0.7613\n",
      "Epoch 406/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7710 - val_loss: 0.5351 - val_accuracy: 0.7663\n",
      "Epoch 407/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7760 - val_loss: 0.5450 - val_accuracy: 0.7312\n",
      "Epoch 408/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7752 - val_loss: 0.5399 - val_accuracy: 0.7437\n",
      "Epoch 409/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7743 - val_loss: 0.5334 - val_accuracy: 0.7638\n",
      "Epoch 410/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7810 - val_loss: 0.5362 - val_accuracy: 0.7688\n",
      "Epoch 411/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7785 - val_loss: 0.5394 - val_accuracy: 0.7663\n",
      "Epoch 412/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7752 - val_loss: 0.5309 - val_accuracy: 0.7714\n",
      "Epoch 413/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7727 - val_loss: 0.5321 - val_accuracy: 0.7638\n",
      "Epoch 414/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7718 - val_loss: 0.5422 - val_accuracy: 0.7688\n",
      "Epoch 415/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7777 - val_loss: 0.5316 - val_accuracy: 0.7638\n",
      "Epoch 416/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7810 - val_loss: 0.5376 - val_accuracy: 0.7688\n",
      "Epoch 417/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7752 - val_loss: 0.5346 - val_accuracy: 0.7663\n",
      "Epoch 418/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7752 - val_loss: 0.5314 - val_accuracy: 0.7688\n",
      "Epoch 419/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7760 - val_loss: 0.5307 - val_accuracy: 0.7714\n",
      "Epoch 420/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7785 - val_loss: 0.5308 - val_accuracy: 0.7714\n",
      "Epoch 421/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7743 - val_loss: 0.5353 - val_accuracy: 0.7663\n",
      "Epoch 422/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7743 - val_loss: 0.5339 - val_accuracy: 0.7613\n",
      "Epoch 423/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7676 - val_loss: 0.5573 - val_accuracy: 0.7638\n",
      "Epoch 424/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7735 - val_loss: 0.5390 - val_accuracy: 0.7663\n",
      "Epoch 425/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7743 - val_loss: 0.5319 - val_accuracy: 0.7739\n",
      "Epoch 426/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7710 - val_loss: 0.5759 - val_accuracy: 0.7538\n",
      "Epoch 427/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7752 - val_loss: 0.5303 - val_accuracy: 0.7739\n",
      "Epoch 428/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7710 - val_loss: 0.5323 - val_accuracy: 0.7638\n",
      "Epoch 429/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7768 - val_loss: 0.5393 - val_accuracy: 0.7663\n",
      "Epoch 430/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7802 - val_loss: 0.5313 - val_accuracy: 0.7638\n",
      "Epoch 431/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7785 - val_loss: 0.5323 - val_accuracy: 0.7638\n",
      "Epoch 432/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7794 - val_loss: 0.5400 - val_accuracy: 0.7663\n",
      "Epoch 433/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7752 - val_loss: 0.5321 - val_accuracy: 0.7638\n",
      "Epoch 434/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7802 - val_loss: 0.5414 - val_accuracy: 0.7688\n",
      "Epoch 435/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7777 - val_loss: 0.5375 - val_accuracy: 0.7688\n",
      "Epoch 436/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7827 - val_loss: 0.5439 - val_accuracy: 0.7714\n",
      "Epoch 437/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7777 - val_loss: 0.5846 - val_accuracy: 0.7538\n",
      "Epoch 438/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7718 - val_loss: 0.5787 - val_accuracy: 0.7538\n",
      "Epoch 439/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7827 - val_loss: 0.5302 - val_accuracy: 0.7663\n",
      "Epoch 440/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7810 - val_loss: 0.5538 - val_accuracy: 0.7638\n",
      "Epoch 441/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7810 - val_loss: 0.5402 - val_accuracy: 0.7437\n",
      "Epoch 442/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7701 - val_loss: 0.5337 - val_accuracy: 0.7638\n",
      "Epoch 443/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7743 - val_loss: 0.5363 - val_accuracy: 0.7688\n",
      "Epoch 444/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7777 - val_loss: 0.5499 - val_accuracy: 0.7663\n",
      "Epoch 445/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7727 - val_loss: 0.5349 - val_accuracy: 0.7588\n",
      "Epoch 446/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7718 - val_loss: 0.5347 - val_accuracy: 0.7588\n",
      "Epoch 447/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7710 - val_loss: 0.5361 - val_accuracy: 0.7688\n",
      "Epoch 448/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7777 - val_loss: 0.5549 - val_accuracy: 0.7060\n",
      "Epoch 449/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7735 - val_loss: 0.5303 - val_accuracy: 0.7714\n",
      "Epoch 450/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7777 - val_loss: 0.5345 - val_accuracy: 0.7563\n",
      "Epoch 451/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7768 - val_loss: 0.5328 - val_accuracy: 0.7663\n",
      "Epoch 452/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7743 - val_loss: 0.5417 - val_accuracy: 0.7688\n",
      "Epoch 453/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7777 - val_loss: 0.5303 - val_accuracy: 0.7714\n",
      "Epoch 454/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7743 - val_loss: 0.5346 - val_accuracy: 0.7588\n",
      "Epoch 455/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7752 - val_loss: 0.5304 - val_accuracy: 0.7613\n",
      "Epoch 456/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7743 - val_loss: 0.5591 - val_accuracy: 0.7588\n",
      "Epoch 457/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7768 - val_loss: 0.5297 - val_accuracy: 0.7663\n",
      "Epoch 458/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7819 - val_loss: 0.5302 - val_accuracy: 0.7613\n",
      "Epoch 459/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7752 - val_loss: 0.5350 - val_accuracy: 0.7588\n",
      "Epoch 460/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7735 - val_loss: 0.5514 - val_accuracy: 0.7663\n",
      "Epoch 461/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7710 - val_loss: 0.5302 - val_accuracy: 0.7613\n",
      "Epoch 462/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7735 - val_loss: 0.5364 - val_accuracy: 0.7688\n",
      "Epoch 463/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7819 - val_loss: 0.5354 - val_accuracy: 0.7538\n",
      "Epoch 464/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7768 - val_loss: 0.5369 - val_accuracy: 0.7513\n",
      "Epoch 465/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7777 - val_loss: 0.5517 - val_accuracy: 0.7663\n",
      "Epoch 466/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7735 - val_loss: 0.5460 - val_accuracy: 0.7663\n",
      "Epoch 467/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7768 - val_loss: 0.5313 - val_accuracy: 0.7638\n",
      "Epoch 468/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7718 - val_loss: 0.5666 - val_accuracy: 0.6734\n",
      "Epoch 469/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7718 - val_loss: 0.5491 - val_accuracy: 0.7663\n",
      "Epoch 470/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7777 - val_loss: 0.5308 - val_accuracy: 0.7739\n",
      "Epoch 471/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7768 - val_loss: 0.5293 - val_accuracy: 0.7714\n",
      "Epoch 472/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7777 - val_loss: 0.5313 - val_accuracy: 0.7764\n",
      "Epoch 473/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7752 - val_loss: 0.5414 - val_accuracy: 0.7437\n",
      "Epoch 474/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7727 - val_loss: 0.5354 - val_accuracy: 0.7688\n",
      "Epoch 475/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7727 - val_loss: 0.5384 - val_accuracy: 0.7663\n",
      "Epoch 476/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7777 - val_loss: 0.5899 - val_accuracy: 0.7563\n",
      "Epoch 477/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7785 - val_loss: 0.5372 - val_accuracy: 0.7688\n",
      "Epoch 478/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7777 - val_loss: 0.5291 - val_accuracy: 0.7663\n",
      "Epoch 479/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7794 - val_loss: 0.5293 - val_accuracy: 0.7613\n",
      "Epoch 480/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7794 - val_loss: 0.5313 - val_accuracy: 0.7638\n",
      "Epoch 481/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7785 - val_loss: 0.5311 - val_accuracy: 0.7764\n",
      "Epoch 482/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7768 - val_loss: 0.5289 - val_accuracy: 0.7714\n",
      "Epoch 483/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7827 - val_loss: 0.5331 - val_accuracy: 0.7638\n",
      "Epoch 484/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7743 - val_loss: 0.5332 - val_accuracy: 0.7638\n",
      "Epoch 485/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7760 - val_loss: 0.5303 - val_accuracy: 0.7638\n",
      "Epoch 486/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7785 - val_loss: 0.5682 - val_accuracy: 0.7588\n",
      "Epoch 487/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7802 - val_loss: 0.5304 - val_accuracy: 0.7714\n",
      "Epoch 488/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7701 - val_loss: 0.5326 - val_accuracy: 0.7638\n",
      "Epoch 489/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7735 - val_loss: 0.5462 - val_accuracy: 0.7663\n",
      "Epoch 490/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7785 - val_loss: 0.5539 - val_accuracy: 0.7663\n",
      "Epoch 491/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7760 - val_loss: 0.5401 - val_accuracy: 0.7688\n",
      "Epoch 492/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7794 - val_loss: 0.5303 - val_accuracy: 0.7638\n",
      "Epoch 493/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7768 - val_loss: 0.5286 - val_accuracy: 0.7714\n",
      "Epoch 494/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7777 - val_loss: 0.5327 - val_accuracy: 0.7638\n",
      "Epoch 495/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7743 - val_loss: 0.5640 - val_accuracy: 0.7563\n",
      "Epoch 496/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7768 - val_loss: 0.5300 - val_accuracy: 0.7638\n",
      "Epoch 497/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7777 - val_loss: 0.5301 - val_accuracy: 0.7638\n",
      "Epoch 498/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7768 - val_loss: 0.5719 - val_accuracy: 0.7538\n",
      "Epoch 499/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7743 - val_loss: 0.5300 - val_accuracy: 0.7663\n",
      "Epoch 500/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7768 - val_loss: 0.5297 - val_accuracy: 0.7638\n",
      "Epoch 501/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7718 - val_loss: 0.5285 - val_accuracy: 0.7714\n",
      "Epoch 502/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7718 - val_loss: 0.5288 - val_accuracy: 0.7714\n",
      "Epoch 503/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7760 - val_loss: 0.5308 - val_accuracy: 0.7739\n",
      "Epoch 504/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7752 - val_loss: 0.5283 - val_accuracy: 0.7739\n",
      "Epoch 505/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7760 - val_loss: 0.5645 - val_accuracy: 0.7588\n",
      "Epoch 506/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7752 - val_loss: 0.5289 - val_accuracy: 0.7714\n",
      "Epoch 507/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7785 - val_loss: 0.5504 - val_accuracy: 0.7186\n",
      "Epoch 508/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7760 - val_loss: 0.5345 - val_accuracy: 0.7663\n",
      "Epoch 509/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7802 - val_loss: 0.5403 - val_accuracy: 0.7714\n",
      "Epoch 510/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7735 - val_loss: 0.5495 - val_accuracy: 0.7663\n",
      "Epoch 511/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7785 - val_loss: 0.5287 - val_accuracy: 0.7714\n",
      "Epoch 512/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7735 - val_loss: 0.5583 - val_accuracy: 0.7588\n",
      "Epoch 513/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7752 - val_loss: 0.5299 - val_accuracy: 0.7638\n",
      "Epoch 514/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7718 - val_loss: 0.5280 - val_accuracy: 0.7663\n",
      "Epoch 515/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7810 - val_loss: 0.5286 - val_accuracy: 0.7714\n",
      "Epoch 516/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7752 - val_loss: 0.5281 - val_accuracy: 0.7714\n",
      "Epoch 517/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7743 - val_loss: 0.5337 - val_accuracy: 0.7588\n",
      "Epoch 518/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7735 - val_loss: 0.5332 - val_accuracy: 0.7613\n",
      "Epoch 519/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7743 - val_loss: 0.5392 - val_accuracy: 0.7462\n",
      "Epoch 520/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7743 - val_loss: 0.5283 - val_accuracy: 0.7613\n",
      "Epoch 521/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7760 - val_loss: 0.5290 - val_accuracy: 0.7638\n",
      "Epoch 522/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7760 - val_loss: 0.5473 - val_accuracy: 0.7362\n",
      "Epoch 523/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7768 - val_loss: 0.5403 - val_accuracy: 0.7688\n",
      "Epoch 524/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7802 - val_loss: 0.5280 - val_accuracy: 0.7638\n",
      "Epoch 525/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7777 - val_loss: 0.5567 - val_accuracy: 0.7588\n",
      "Epoch 526/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7743 - val_loss: 0.5277 - val_accuracy: 0.7714\n",
      "Epoch 527/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7768 - val_loss: 0.5293 - val_accuracy: 0.7663\n",
      "Epoch 528/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7794 - val_loss: 0.5288 - val_accuracy: 0.7663\n",
      "Epoch 529/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7810 - val_loss: 0.5285 - val_accuracy: 0.7613\n",
      "Epoch 530/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7777 - val_loss: 0.5293 - val_accuracy: 0.7638\n",
      "Epoch 531/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7794 - val_loss: 0.5492 - val_accuracy: 0.7663\n",
      "Epoch 532/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7785 - val_loss: 0.5280 - val_accuracy: 0.7613\n",
      "Epoch 533/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7777 - val_loss: 0.5412 - val_accuracy: 0.7688\n",
      "Epoch 534/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7752 - val_loss: 0.5289 - val_accuracy: 0.7613\n",
      "Epoch 535/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7735 - val_loss: 0.5351 - val_accuracy: 0.7714\n",
      "Epoch 536/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7785 - val_loss: 0.5339 - val_accuracy: 0.7688\n",
      "Epoch 537/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7794 - val_loss: 0.5273 - val_accuracy: 0.7714\n",
      "Epoch 538/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7768 - val_loss: 0.5273 - val_accuracy: 0.7714\n",
      "Epoch 539/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7785 - val_loss: 0.5351 - val_accuracy: 0.7714\n",
      "Epoch 540/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7768 - val_loss: 0.5295 - val_accuracy: 0.7688\n",
      "Epoch 541/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7802 - val_loss: 0.5303 - val_accuracy: 0.7638\n",
      "Epoch 542/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7785 - val_loss: 0.5286 - val_accuracy: 0.7663\n",
      "Epoch 543/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7743 - val_loss: 0.5468 - val_accuracy: 0.7663\n",
      "Epoch 544/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7777 - val_loss: 0.5299 - val_accuracy: 0.7739\n",
      "Epoch 545/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7760 - val_loss: 0.5382 - val_accuracy: 0.7714\n",
      "Epoch 546/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7777 - val_loss: 0.5312 - val_accuracy: 0.7638\n",
      "Epoch 547/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7735 - val_loss: 0.5400 - val_accuracy: 0.7714\n",
      "Epoch 548/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7752 - val_loss: 0.5529 - val_accuracy: 0.7663\n",
      "Epoch 549/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7743 - val_loss: 0.5517 - val_accuracy: 0.7663\n",
      "Epoch 550/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7735 - val_loss: 0.5281 - val_accuracy: 0.7714\n",
      "Epoch 551/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7760 - val_loss: 0.5270 - val_accuracy: 0.7714\n",
      "Epoch 552/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7760 - val_loss: 0.5349 - val_accuracy: 0.7714\n",
      "Epoch 553/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7752 - val_loss: 0.5524 - val_accuracy: 0.7663\n",
      "Epoch 554/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7743 - val_loss: 0.5299 - val_accuracy: 0.7638\n",
      "Epoch 555/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7760 - val_loss: 0.5272 - val_accuracy: 0.7714\n",
      "Epoch 556/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7752 - val_loss: 0.5270 - val_accuracy: 0.7663\n",
      "Epoch 557/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7768 - val_loss: 0.5496 - val_accuracy: 0.7663\n",
      "Epoch 558/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7810 - val_loss: 0.5369 - val_accuracy: 0.7714\n",
      "Epoch 559/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7785 - val_loss: 0.5336 - val_accuracy: 0.7663\n",
      "Epoch 560/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7760 - val_loss: 0.5588 - val_accuracy: 0.7563\n",
      "Epoch 561/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7777 - val_loss: 0.5274 - val_accuracy: 0.7714\n",
      "Epoch 562/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7752 - val_loss: 0.5348 - val_accuracy: 0.7513\n",
      "Epoch 563/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7752 - val_loss: 0.5319 - val_accuracy: 0.7638\n",
      "Epoch 564/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7718 - val_loss: 0.5392 - val_accuracy: 0.7688\n",
      "Epoch 565/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7735 - val_loss: 0.5600 - val_accuracy: 0.7563\n",
      "Epoch 566/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7752 - val_loss: 0.5268 - val_accuracy: 0.7638\n",
      "Epoch 567/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7743 - val_loss: 0.5303 - val_accuracy: 0.7638\n",
      "Epoch 568/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7768 - val_loss: 0.5288 - val_accuracy: 0.7638\n",
      "Epoch 569/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7727 - val_loss: 0.5376 - val_accuracy: 0.7714\n",
      "Epoch 570/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7794 - val_loss: 0.5400 - val_accuracy: 0.7688\n",
      "Epoch 571/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7727 - val_loss: 0.5275 - val_accuracy: 0.7613\n",
      "Epoch 572/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7760 - val_loss: 0.5282 - val_accuracy: 0.7613\n",
      "Epoch 573/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7777 - val_loss: 0.5289 - val_accuracy: 0.7638\n",
      "Epoch 574/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7794 - val_loss: 0.5292 - val_accuracy: 0.7638\n",
      "Epoch 575/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7727 - val_loss: 0.5733 - val_accuracy: 0.7538\n",
      "Epoch 576/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7794 - val_loss: 0.5266 - val_accuracy: 0.7714\n",
      "Epoch 577/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7777 - val_loss: 0.5283 - val_accuracy: 0.7613\n",
      "Epoch 578/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7727 - val_loss: 0.5349 - val_accuracy: 0.7714\n",
      "Epoch 579/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7768 - val_loss: 0.5383 - val_accuracy: 0.7714\n",
      "Epoch 580/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7777 - val_loss: 0.5455 - val_accuracy: 0.7688\n",
      "Epoch 581/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7794 - val_loss: 0.5327 - val_accuracy: 0.7588\n",
      "Epoch 582/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7752 - val_loss: 0.5269 - val_accuracy: 0.7714\n",
      "Epoch 583/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7760 - val_loss: 0.5467 - val_accuracy: 0.7663\n",
      "Epoch 584/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7794 - val_loss: 0.5428 - val_accuracy: 0.7688\n",
      "Epoch 585/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7794 - val_loss: 0.5270 - val_accuracy: 0.7714\n",
      "Epoch 586/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7810 - val_loss: 0.5268 - val_accuracy: 0.7638\n",
      "Epoch 587/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7768 - val_loss: 0.5295 - val_accuracy: 0.7638\n",
      "Epoch 588/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7760 - val_loss: 0.5540 - val_accuracy: 0.7613\n",
      "Epoch 589/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7785 - val_loss: 0.5268 - val_accuracy: 0.7613\n",
      "Epoch 590/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7768 - val_loss: 0.5284 - val_accuracy: 0.7638\n",
      "Epoch 591/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7768 - val_loss: 0.5310 - val_accuracy: 0.7663\n",
      "Epoch 592/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7752 - val_loss: 0.5261 - val_accuracy: 0.7638\n",
      "Epoch 593/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7752 - val_loss: 0.5274 - val_accuracy: 0.7613\n",
      "Epoch 594/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7727 - val_loss: 0.5264 - val_accuracy: 0.7714\n",
      "Epoch 595/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7768 - val_loss: 0.5403 - val_accuracy: 0.7688\n",
      "Epoch 596/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7794 - val_loss: 0.5298 - val_accuracy: 0.7739\n",
      "Epoch 597/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7735 - val_loss: 0.5265 - val_accuracy: 0.7714\n",
      "Epoch 598/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7743 - val_loss: 0.5264 - val_accuracy: 0.7613\n",
      "Epoch 599/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7810 - val_loss: 0.5327 - val_accuracy: 0.7688\n",
      "Epoch 600/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7768 - val_loss: 0.5262 - val_accuracy: 0.7613\n",
      "Epoch 601/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7785 - val_loss: 0.5370 - val_accuracy: 0.7739\n",
      "Epoch 602/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7777 - val_loss: 0.5477 - val_accuracy: 0.7663\n",
      "Epoch 603/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7785 - val_loss: 0.5361 - val_accuracy: 0.7462\n",
      "Epoch 604/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7752 - val_loss: 0.5395 - val_accuracy: 0.7688\n",
      "Epoch 605/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7777 - val_loss: 0.5290 - val_accuracy: 0.7688\n",
      "Epoch 606/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7777 - val_loss: 0.5262 - val_accuracy: 0.7714\n",
      "Epoch 607/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7777 - val_loss: 0.5277 - val_accuracy: 0.7638\n",
      "Epoch 608/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7735 - val_loss: 0.5263 - val_accuracy: 0.7714\n",
      "Epoch 609/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7743 - val_loss: 0.5287 - val_accuracy: 0.7638\n",
      "Epoch 610/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7743 - val_loss: 0.5282 - val_accuracy: 0.7638\n",
      "Epoch 611/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7810 - val_loss: 0.5364 - val_accuracy: 0.7739\n",
      "Epoch 612/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7777 - val_loss: 0.5467 - val_accuracy: 0.7663\n",
      "Epoch 613/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7768 - val_loss: 0.5264 - val_accuracy: 0.7714\n",
      "Epoch 614/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7802 - val_loss: 0.5364 - val_accuracy: 0.7462\n",
      "Epoch 615/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7743 - val_loss: 0.5259 - val_accuracy: 0.7638\n",
      "Epoch 616/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7735 - val_loss: 0.5268 - val_accuracy: 0.7613\n",
      "Epoch 617/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7760 - val_loss: 0.5397 - val_accuracy: 0.7688\n",
      "Epoch 618/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7743 - val_loss: 0.5279 - val_accuracy: 0.7638\n",
      "Epoch 619/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7802 - val_loss: 0.5268 - val_accuracy: 0.7613\n",
      "Epoch 620/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7777 - val_loss: 0.5261 - val_accuracy: 0.7613\n",
      "Epoch 621/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7810 - val_loss: 0.5267 - val_accuracy: 0.7688\n",
      "Epoch 622/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7810 - val_loss: 0.5370 - val_accuracy: 0.7714\n",
      "Epoch 623/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7785 - val_loss: 0.5256 - val_accuracy: 0.7613\n",
      "Epoch 624/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7752 - val_loss: 0.5341 - val_accuracy: 0.7538\n",
      "Epoch 625/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7785 - val_loss: 0.5258 - val_accuracy: 0.7714\n",
      "Epoch 626/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7718 - val_loss: 0.5253 - val_accuracy: 0.7714\n",
      "Epoch 627/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7743 - val_loss: 0.5537 - val_accuracy: 0.7060\n",
      "Epoch 628/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7743 - val_loss: 0.5267 - val_accuracy: 0.7638\n",
      "Epoch 629/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7760 - val_loss: 0.5269 - val_accuracy: 0.7638\n",
      "Epoch 630/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7735 - val_loss: 0.5282 - val_accuracy: 0.7638\n",
      "Epoch 631/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7752 - val_loss: 0.5296 - val_accuracy: 0.7638\n",
      "Epoch 632/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7760 - val_loss: 0.5276 - val_accuracy: 0.7638\n",
      "Epoch 633/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7768 - val_loss: 0.5265 - val_accuracy: 0.7613\n",
      "Epoch 634/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7743 - val_loss: 0.5284 - val_accuracy: 0.7638\n",
      "Epoch 635/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7743 - val_loss: 0.5281 - val_accuracy: 0.7688\n",
      "Epoch 636/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7752 - val_loss: 0.5257 - val_accuracy: 0.7714\n",
      "Epoch 637/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7819 - val_loss: 0.5266 - val_accuracy: 0.7688\n",
      "Epoch 638/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7743 - val_loss: 0.5584 - val_accuracy: 0.7563\n",
      "Epoch 639/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7768 - val_loss: 0.5465 - val_accuracy: 0.7663\n",
      "Epoch 640/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7735 - val_loss: 0.5658 - val_accuracy: 0.7513\n",
      "Epoch 641/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7768 - val_loss: 0.5306 - val_accuracy: 0.7688\n",
      "Epoch 642/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7760 - val_loss: 0.5393 - val_accuracy: 0.7462\n",
      "Epoch 643/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7760 - val_loss: 0.5267 - val_accuracy: 0.7613\n",
      "Epoch 644/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7752 - val_loss: 0.5266 - val_accuracy: 0.7638\n",
      "Epoch 645/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7794 - val_loss: 0.5330 - val_accuracy: 0.7714\n",
      "Epoch 646/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7727 - val_loss: 0.5311 - val_accuracy: 0.7663\n",
      "Epoch 647/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7777 - val_loss: 0.5257 - val_accuracy: 0.7613\n",
      "Epoch 648/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7785 - val_loss: 0.5254 - val_accuracy: 0.7613\n",
      "Epoch 649/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7785 - val_loss: 0.5252 - val_accuracy: 0.7638\n",
      "Epoch 650/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7785 - val_loss: 0.5262 - val_accuracy: 0.7714\n",
      "Epoch 651/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7785 - val_loss: 0.5257 - val_accuracy: 0.7714\n",
      "Epoch 652/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7760 - val_loss: 0.5301 - val_accuracy: 0.7688\n",
      "Epoch 653/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7760 - val_loss: 0.5292 - val_accuracy: 0.7739\n",
      "Epoch 654/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7777 - val_loss: 0.5282 - val_accuracy: 0.7638\n",
      "Epoch 655/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7777 - val_loss: 0.5258 - val_accuracy: 0.7714\n",
      "Epoch 656/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7727 - val_loss: 0.5411 - val_accuracy: 0.7688\n",
      "Epoch 657/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7760 - val_loss: 0.5295 - val_accuracy: 0.7638\n",
      "Epoch 658/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7777 - val_loss: 0.5271 - val_accuracy: 0.7638\n",
      "Epoch 659/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7785 - val_loss: 0.5266 - val_accuracy: 0.7638\n",
      "Epoch 660/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7768 - val_loss: 0.5346 - val_accuracy: 0.7739\n",
      "Epoch 661/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7768 - val_loss: 0.5246 - val_accuracy: 0.7638\n",
      "Epoch 662/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7777 - val_loss: 0.5262 - val_accuracy: 0.7613\n",
      "Epoch 663/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7785 - val_loss: 0.5253 - val_accuracy: 0.7613\n",
      "Epoch 664/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7794 - val_loss: 0.5270 - val_accuracy: 0.7638\n",
      "Epoch 665/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7810 - val_loss: 0.5270 - val_accuracy: 0.7638\n",
      "Epoch 666/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7760 - val_loss: 0.5273 - val_accuracy: 0.7638\n",
      "Epoch 667/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7785 - val_loss: 0.5267 - val_accuracy: 0.7638\n",
      "Epoch 668/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7810 - val_loss: 0.5252 - val_accuracy: 0.7714\n",
      "Epoch 669/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7810 - val_loss: 0.5254 - val_accuracy: 0.7714\n",
      "Epoch 670/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7785 - val_loss: 0.5386 - val_accuracy: 0.7688\n",
      "Epoch 671/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7735 - val_loss: 0.5527 - val_accuracy: 0.7563\n",
      "Epoch 672/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7752 - val_loss: 0.5248 - val_accuracy: 0.7613\n",
      "Epoch 673/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7777 - val_loss: 0.5254 - val_accuracy: 0.7714\n",
      "Epoch 674/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7777 - val_loss: 0.5640 - val_accuracy: 0.7513\n",
      "Epoch 675/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7810 - val_loss: 0.5247 - val_accuracy: 0.7613\n",
      "Epoch 676/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7743 - val_loss: 0.5255 - val_accuracy: 0.7613\n",
      "Epoch 677/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7760 - val_loss: 0.5261 - val_accuracy: 0.7688\n",
      "Epoch 678/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7760 - val_loss: 0.5278 - val_accuracy: 0.7638\n",
      "Epoch 679/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7777 - val_loss: 0.5281 - val_accuracy: 0.7638\n",
      "Epoch 680/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7819 - val_loss: 0.5464 - val_accuracy: 0.7663\n",
      "Epoch 681/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7802 - val_loss: 0.5356 - val_accuracy: 0.7688\n",
      "Epoch 682/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7785 - val_loss: 0.5250 - val_accuracy: 0.7714\n",
      "Epoch 683/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7752 - val_loss: 0.5419 - val_accuracy: 0.7688\n",
      "Epoch 684/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7794 - val_loss: 0.5243 - val_accuracy: 0.7714\n",
      "Epoch 685/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7777 - val_loss: 0.5255 - val_accuracy: 0.7714\n",
      "Epoch 686/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7752 - val_loss: 0.5413 - val_accuracy: 0.7688\n",
      "Epoch 687/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7819 - val_loss: 0.5279 - val_accuracy: 0.7663\n",
      "Epoch 688/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7794 - val_loss: 0.5338 - val_accuracy: 0.7613\n",
      "Epoch 689/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7743 - val_loss: 0.5241 - val_accuracy: 0.7638\n",
      "Epoch 690/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7810 - val_loss: 0.5281 - val_accuracy: 0.7638\n",
      "Epoch 691/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7760 - val_loss: 0.5303 - val_accuracy: 0.7688\n",
      "Epoch 692/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7777 - val_loss: 0.5251 - val_accuracy: 0.7613\n",
      "Epoch 693/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7752 - val_loss: 0.5240 - val_accuracy: 0.7638\n",
      "Epoch 694/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7819 - val_loss: 0.5601 - val_accuracy: 0.7513\n",
      "Epoch 695/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7777 - val_loss: 0.5362 - val_accuracy: 0.7688\n",
      "Epoch 696/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7785 - val_loss: 0.5244 - val_accuracy: 0.7613\n",
      "Epoch 697/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7794 - val_loss: 0.5367 - val_accuracy: 0.7688\n",
      "Epoch 698/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7760 - val_loss: 0.5312 - val_accuracy: 0.7714\n",
      "Epoch 699/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7777 - val_loss: 0.5534 - val_accuracy: 0.7563\n",
      "Epoch 700/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7760 - val_loss: 0.5279 - val_accuracy: 0.7663\n",
      "Epoch 701/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7638\n",
      "Epoch 702/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7768 - val_loss: 0.5274 - val_accuracy: 0.7638\n",
      "Epoch 703/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7785 - val_loss: 0.5445 - val_accuracy: 0.7688\n",
      "Epoch 704/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7777 - val_loss: 0.5246 - val_accuracy: 0.7613\n",
      "Epoch 705/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7752 - val_loss: 0.5410 - val_accuracy: 0.7688\n",
      "Epoch 706/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7768 - val_loss: 0.5256 - val_accuracy: 0.7638\n",
      "Epoch 707/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7802 - val_loss: 0.5398 - val_accuracy: 0.7688\n",
      "Epoch 708/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7768 - val_loss: 0.5240 - val_accuracy: 0.7613\n",
      "Epoch 709/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7794 - val_loss: 0.5258 - val_accuracy: 0.7638\n",
      "Epoch 710/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7760 - val_loss: 0.5251 - val_accuracy: 0.7613\n",
      "Epoch 711/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7794 - val_loss: 0.5241 - val_accuracy: 0.7613\n",
      "Epoch 712/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7777 - val_loss: 0.5282 - val_accuracy: 0.7638\n",
      "Epoch 713/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7777 - val_loss: 0.5312 - val_accuracy: 0.7688\n",
      "Epoch 714/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7768 - val_loss: 0.5245 - val_accuracy: 0.7714\n",
      "Epoch 715/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7768 - val_loss: 0.5279 - val_accuracy: 0.7638\n",
      "Epoch 716/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7743 - val_loss: 0.5237 - val_accuracy: 0.7714\n",
      "Epoch 717/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7777 - val_loss: 0.5414 - val_accuracy: 0.7688\n",
      "Epoch 718/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7785 - val_loss: 0.5237 - val_accuracy: 0.7688\n",
      "Epoch 719/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7777 - val_loss: 0.5237 - val_accuracy: 0.7714\n",
      "Epoch 720/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7743 - val_loss: 0.5358 - val_accuracy: 0.7688\n",
      "Epoch 721/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7727 - val_loss: 0.5256 - val_accuracy: 0.7638\n",
      "Epoch 722/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7827 - val_loss: 0.5287 - val_accuracy: 0.7688\n",
      "Epoch 723/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7802 - val_loss: 0.5233 - val_accuracy: 0.7688\n",
      "Epoch 724/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7819 - val_loss: 0.5232 - val_accuracy: 0.7638\n",
      "Epoch 725/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7752 - val_loss: 0.5234 - val_accuracy: 0.7714\n",
      "Epoch 726/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7752 - val_loss: 0.5268 - val_accuracy: 0.7638\n",
      "Epoch 727/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7777 - val_loss: 0.5282 - val_accuracy: 0.7663\n",
      "Epoch 728/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7727 - val_loss: 0.5282 - val_accuracy: 0.7663\n",
      "Epoch 729/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7760 - val_loss: 0.5234 - val_accuracy: 0.7714\n",
      "Epoch 730/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7819 - val_loss: 0.5286 - val_accuracy: 0.7688\n",
      "Epoch 731/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7768 - val_loss: 0.5233 - val_accuracy: 0.7613\n",
      "Epoch 732/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7752 - val_loss: 0.5257 - val_accuracy: 0.7638\n",
      "Epoch 733/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7760 - val_loss: 0.5233 - val_accuracy: 0.7638\n",
      "Epoch 734/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7768 - val_loss: 0.5233 - val_accuracy: 0.7638\n",
      "Epoch 735/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7794 - val_loss: 0.5277 - val_accuracy: 0.7688\n",
      "Epoch 736/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7760 - val_loss: 0.5260 - val_accuracy: 0.7638\n",
      "Epoch 737/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7819 - val_loss: 0.5286 - val_accuracy: 0.7688\n",
      "Epoch 738/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7768 - val_loss: 0.5452 - val_accuracy: 0.7663\n",
      "Epoch 739/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7777 - val_loss: 0.5233 - val_accuracy: 0.7714\n",
      "Epoch 740/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7810 - val_loss: 0.5243 - val_accuracy: 0.7613\n",
      "Epoch 741/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7810 - val_loss: 0.5444 - val_accuracy: 0.7412\n",
      "Epoch 742/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7760 - val_loss: 0.5233 - val_accuracy: 0.7638\n",
      "Epoch 743/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7760 - val_loss: 0.5245 - val_accuracy: 0.7613\n",
      "Epoch 744/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7743 - val_loss: 0.5231 - val_accuracy: 0.7714\n",
      "Epoch 745/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7785 - val_loss: 0.5382 - val_accuracy: 0.7688\n",
      "Epoch 746/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7760 - val_loss: 0.5236 - val_accuracy: 0.7613\n",
      "Epoch 747/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7785 - val_loss: 0.5233 - val_accuracy: 0.7613\n",
      "Epoch 748/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7727 - val_loss: 0.5230 - val_accuracy: 0.7613\n",
      "Epoch 749/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7768 - val_loss: 0.5308 - val_accuracy: 0.7714\n",
      "Epoch 750/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7794 - val_loss: 0.5231 - val_accuracy: 0.7714\n",
      "Epoch 751/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7802 - val_loss: 0.5265 - val_accuracy: 0.7663\n",
      "Epoch 752/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7768 - val_loss: 0.5230 - val_accuracy: 0.7638\n",
      "Epoch 753/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7752 - val_loss: 0.5289 - val_accuracy: 0.7688\n",
      "Epoch 754/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7794 - val_loss: 0.5329 - val_accuracy: 0.7714\n",
      "Epoch 755/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7785 - val_loss: 0.5250 - val_accuracy: 0.7638\n",
      "Epoch 756/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7727 - val_loss: 0.5386 - val_accuracy: 0.7688\n",
      "Epoch 757/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7777 - val_loss: 0.5274 - val_accuracy: 0.7663\n",
      "Epoch 758/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7760 - val_loss: 0.5234 - val_accuracy: 0.7714\n",
      "Epoch 759/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7743 - val_loss: 0.5269 - val_accuracy: 0.7638\n",
      "Epoch 760/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7802 - val_loss: 0.5376 - val_accuracy: 0.7688\n",
      "Epoch 761/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7802 - val_loss: 0.5227 - val_accuracy: 0.7613\n",
      "Epoch 762/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7743 - val_loss: 0.5261 - val_accuracy: 0.7663\n",
      "Epoch 763/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7718 - val_loss: 0.5322 - val_accuracy: 0.7714\n",
      "Epoch 764/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7785 - val_loss: 0.5247 - val_accuracy: 0.7638\n",
      "Epoch 765/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7760 - val_loss: 0.5232 - val_accuracy: 0.7714\n",
      "Epoch 766/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7777 - val_loss: 0.5305 - val_accuracy: 0.7714\n",
      "Epoch 767/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7777 - val_loss: 0.5240 - val_accuracy: 0.7613\n",
      "Epoch 768/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7777 - val_loss: 0.5232 - val_accuracy: 0.7613\n",
      "Epoch 769/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7743 - val_loss: 0.5406 - val_accuracy: 0.7688\n",
      "Epoch 770/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7768 - val_loss: 0.5224 - val_accuracy: 0.7638\n",
      "Epoch 771/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7810 - val_loss: 0.5346 - val_accuracy: 0.7688\n",
      "Epoch 772/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7794 - val_loss: 0.5549 - val_accuracy: 0.7111\n",
      "Epoch 773/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7768 - val_loss: 0.5365 - val_accuracy: 0.7688\n",
      "Epoch 774/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7802 - val_loss: 0.5259 - val_accuracy: 0.7663\n",
      "Epoch 775/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7777 - val_loss: 0.5225 - val_accuracy: 0.7714\n",
      "Epoch 776/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7785 - val_loss: 0.5290 - val_accuracy: 0.7688\n",
      "Epoch 777/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7777 - val_loss: 0.5242 - val_accuracy: 0.7663\n",
      "Epoch 778/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7810 - val_loss: 0.5241 - val_accuracy: 0.7663\n",
      "Epoch 779/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7768 - val_loss: 0.5265 - val_accuracy: 0.7663\n",
      "Epoch 780/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7785 - val_loss: 0.5229 - val_accuracy: 0.7613\n",
      "Epoch 781/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7810 - val_loss: 0.5292 - val_accuracy: 0.7688\n",
      "Epoch 782/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7794 - val_loss: 0.5416 - val_accuracy: 0.7688\n",
      "Epoch 783/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7768 - val_loss: 0.5225 - val_accuracy: 0.7613\n",
      "Epoch 784/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7768 - val_loss: 0.5307 - val_accuracy: 0.7714\n",
      "Epoch 785/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7718 - val_loss: 0.5349 - val_accuracy: 0.7688\n",
      "Epoch 786/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7760 - val_loss: 0.5362 - val_accuracy: 0.7688\n",
      "Epoch 787/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7785 - val_loss: 0.5500 - val_accuracy: 0.7563\n",
      "Epoch 788/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7777 - val_loss: 0.5221 - val_accuracy: 0.7714\n",
      "Epoch 789/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7794 - val_loss: 0.5223 - val_accuracy: 0.7613\n",
      "Epoch 790/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7802 - val_loss: 0.5223 - val_accuracy: 0.7714\n",
      "Epoch 791/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7777 - val_loss: 0.5272 - val_accuracy: 0.7688\n",
      "Epoch 792/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7819 - val_loss: 0.5245 - val_accuracy: 0.7638\n",
      "Epoch 793/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7760 - val_loss: 0.5486 - val_accuracy: 0.7638\n",
      "Epoch 794/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7768 - val_loss: 0.5234 - val_accuracy: 0.7714\n",
      "Epoch 795/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7718 - val_loss: 0.5221 - val_accuracy: 0.7714\n",
      "Epoch 796/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7785 - val_loss: 0.5222 - val_accuracy: 0.7688\n",
      "Epoch 797/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7777 - val_loss: 0.5224 - val_accuracy: 0.7714\n",
      "Epoch 798/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7785 - val_loss: 0.5240 - val_accuracy: 0.7638\n",
      "Epoch 799/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7794 - val_loss: 0.5218 - val_accuracy: 0.7613\n",
      "Epoch 800/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7794 - val_loss: 0.5456 - val_accuracy: 0.7638\n",
      "Epoch 801/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7794 - val_loss: 0.5250 - val_accuracy: 0.7663\n",
      "Epoch 802/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7802 - val_loss: 0.5229 - val_accuracy: 0.7613\n",
      "Epoch 803/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7810 - val_loss: 0.5229 - val_accuracy: 0.7613\n",
      "Epoch 804/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7743 - val_loss: 0.5236 - val_accuracy: 0.7638\n",
      "Epoch 805/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7819 - val_loss: 0.5239 - val_accuracy: 0.7638\n",
      "Epoch 806/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7768 - val_loss: 0.5230 - val_accuracy: 0.7638\n",
      "Epoch 807/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7768 - val_loss: 0.5278 - val_accuracy: 0.7688\n",
      "Epoch 808/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7810 - val_loss: 0.5252 - val_accuracy: 0.7663\n",
      "Epoch 809/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7768 - val_loss: 0.5403 - val_accuracy: 0.7688\n",
      "Epoch 810/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7802 - val_loss: 0.5226 - val_accuracy: 0.7714\n",
      "Epoch 811/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7752 - val_loss: 0.5531 - val_accuracy: 0.7563\n",
      "Epoch 812/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7760 - val_loss: 0.5298 - val_accuracy: 0.7714\n",
      "Epoch 813/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7810 - val_loss: 0.5242 - val_accuracy: 0.7638\n",
      "Epoch 814/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7768 - val_loss: 0.5321 - val_accuracy: 0.7714\n",
      "Epoch 815/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7743 - val_loss: 0.5304 - val_accuracy: 0.7714\n",
      "Epoch 816/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7777 - val_loss: 0.5320 - val_accuracy: 0.7714\n",
      "Epoch 817/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7777 - val_loss: 0.5384 - val_accuracy: 0.7688\n",
      "Epoch 818/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7802 - val_loss: 0.5249 - val_accuracy: 0.7638\n",
      "Epoch 819/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7760 - val_loss: 0.5368 - val_accuracy: 0.7688\n",
      "Epoch 820/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7794 - val_loss: 0.5218 - val_accuracy: 0.7613\n",
      "Epoch 821/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7819 - val_loss: 0.5237 - val_accuracy: 0.7663\n",
      "Epoch 822/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7743 - val_loss: 0.5288 - val_accuracy: 0.7714\n",
      "Epoch 823/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7785 - val_loss: 0.5235 - val_accuracy: 0.7638\n",
      "Epoch 824/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7777 - val_loss: 0.5245 - val_accuracy: 0.7663\n",
      "Epoch 825/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7785 - val_loss: 0.5305 - val_accuracy: 0.7714\n",
      "Epoch 826/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7802 - val_loss: 0.5214 - val_accuracy: 0.7638\n",
      "Epoch 827/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7810 - val_loss: 0.5495 - val_accuracy: 0.7337\n",
      "Epoch 828/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7735 - val_loss: 0.5253 - val_accuracy: 0.7688\n",
      "Epoch 829/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7768 - val_loss: 0.5252 - val_accuracy: 0.7663\n",
      "Epoch 830/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7768 - val_loss: 0.5218 - val_accuracy: 0.7613\n",
      "Epoch 831/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7752 - val_loss: 0.5278 - val_accuracy: 0.7688\n",
      "Epoch 832/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7710 - val_loss: 0.5215 - val_accuracy: 0.7714\n",
      "Epoch 833/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7752 - val_loss: 0.5218 - val_accuracy: 0.7613\n",
      "Epoch 834/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7752 - val_loss: 0.5247 - val_accuracy: 0.7663\n",
      "Epoch 835/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7777 - val_loss: 0.5638 - val_accuracy: 0.7513\n",
      "Epoch 836/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7794 - val_loss: 0.5266 - val_accuracy: 0.7688\n",
      "Epoch 837/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7794 - val_loss: 0.5367 - val_accuracy: 0.7688\n",
      "Epoch 838/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7785 - val_loss: 0.5320 - val_accuracy: 0.7714\n",
      "Epoch 839/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7777 - val_loss: 0.5303 - val_accuracy: 0.7714\n",
      "Epoch 840/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7768 - val_loss: 0.5218 - val_accuracy: 0.7613\n",
      "Epoch 841/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7743 - val_loss: 0.5380 - val_accuracy: 0.7688\n",
      "Epoch 842/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7794 - val_loss: 0.5222 - val_accuracy: 0.7714\n",
      "Epoch 843/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7794 - val_loss: 0.5228 - val_accuracy: 0.7714\n",
      "Epoch 844/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7777 - val_loss: 0.5221 - val_accuracy: 0.7613\n",
      "Epoch 845/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7768 - val_loss: 0.5373 - val_accuracy: 0.7688\n",
      "Epoch 846/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7794 - val_loss: 0.5273 - val_accuracy: 0.7688\n",
      "Epoch 847/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7768 - val_loss: 0.5211 - val_accuracy: 0.7613\n",
      "Epoch 848/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7768 - val_loss: 0.5350 - val_accuracy: 0.7688\n",
      "Epoch 849/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7810 - val_loss: 0.5298 - val_accuracy: 0.7714\n",
      "Epoch 850/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7760 - val_loss: 0.5439 - val_accuracy: 0.7638\n",
      "Epoch 851/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7777 - val_loss: 0.5249 - val_accuracy: 0.7688\n",
      "Epoch 852/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7760 - val_loss: 0.5223 - val_accuracy: 0.7638\n",
      "Epoch 853/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7760 - val_loss: 0.5210 - val_accuracy: 0.7714\n",
      "Epoch 854/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7768 - val_loss: 0.5208 - val_accuracy: 0.7688\n",
      "Epoch 855/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7802 - val_loss: 0.5208 - val_accuracy: 0.7613\n",
      "Epoch 856/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7802 - val_loss: 0.5377 - val_accuracy: 0.7688\n",
      "Epoch 857/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7777 - val_loss: 0.5390 - val_accuracy: 0.7688\n",
      "Epoch 858/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7768 - val_loss: 0.5218 - val_accuracy: 0.7638\n",
      "Epoch 859/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7743 - val_loss: 0.5208 - val_accuracy: 0.7613\n",
      "Epoch 860/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7802 - val_loss: 0.5209 - val_accuracy: 0.7613\n",
      "Epoch 861/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7768 - val_loss: 0.5501 - val_accuracy: 0.7563\n",
      "Epoch 862/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7777 - val_loss: 0.5210 - val_accuracy: 0.7714\n",
      "Epoch 863/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7794 - val_loss: 0.5244 - val_accuracy: 0.7663\n",
      "Epoch 864/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7768 - val_loss: 0.5283 - val_accuracy: 0.7714\n",
      "Epoch 865/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7785 - val_loss: 0.5260 - val_accuracy: 0.7714\n",
      "Epoch 866/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7802 - val_loss: 0.5206 - val_accuracy: 0.7613\n",
      "Epoch 867/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7752 - val_loss: 0.5220 - val_accuracy: 0.7714\n",
      "Epoch 868/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7802 - val_loss: 0.5209 - val_accuracy: 0.7714\n",
      "Epoch 869/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7819 - val_loss: 0.5221 - val_accuracy: 0.7638\n",
      "Epoch 870/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7777 - val_loss: 0.5275 - val_accuracy: 0.7714\n",
      "Epoch 871/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7768 - val_loss: 0.5239 - val_accuracy: 0.7663\n",
      "Epoch 872/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7768 - val_loss: 0.5234 - val_accuracy: 0.7663\n",
      "Epoch 873/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7777 - val_loss: 0.5224 - val_accuracy: 0.7663\n",
      "Epoch 874/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7777 - val_loss: 0.5210 - val_accuracy: 0.7613\n",
      "Epoch 875/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7777 - val_loss: 0.5316 - val_accuracy: 0.7714\n",
      "Epoch 876/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7785 - val_loss: 0.5225 - val_accuracy: 0.7663\n",
      "Epoch 877/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7794 - val_loss: 0.5206 - val_accuracy: 0.7714\n",
      "Epoch 878/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7760 - val_loss: 0.5297 - val_accuracy: 0.7714\n",
      "Epoch 879/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7802 - val_loss: 0.5374 - val_accuracy: 0.7688\n",
      "Epoch 880/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7802 - val_loss: 0.5220 - val_accuracy: 0.7663\n",
      "Epoch 881/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7794 - val_loss: 0.5384 - val_accuracy: 0.7688\n",
      "Epoch 882/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7794 - val_loss: 0.5329 - val_accuracy: 0.7688\n",
      "Epoch 883/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7768 - val_loss: 0.5202 - val_accuracy: 0.7638\n",
      "Epoch 884/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7810 - val_loss: 0.5324 - val_accuracy: 0.7688\n",
      "Epoch 885/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7794 - val_loss: 0.5227 - val_accuracy: 0.7663\n",
      "Epoch 886/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7794 - val_loss: 0.5230 - val_accuracy: 0.7638\n",
      "Epoch 887/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7827 - val_loss: 0.5423 - val_accuracy: 0.7638\n",
      "Epoch 888/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7794 - val_loss: 0.5236 - val_accuracy: 0.7663\n",
      "Epoch 889/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7810 - val_loss: 0.5215 - val_accuracy: 0.7714\n",
      "Epoch 890/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7785 - val_loss: 0.5313 - val_accuracy: 0.7688\n",
      "Epoch 891/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7827 - val_loss: 0.5207 - val_accuracy: 0.7714\n",
      "Epoch 892/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7785 - val_loss: 0.5549 - val_accuracy: 0.7538\n",
      "Epoch 893/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7785 - val_loss: 0.5201 - val_accuracy: 0.7638\n",
      "Epoch 894/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7777 - val_loss: 0.5452 - val_accuracy: 0.7638\n",
      "Epoch 895/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7777 - val_loss: 0.5312 - val_accuracy: 0.7714\n",
      "Epoch 896/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7777 - val_loss: 0.5288 - val_accuracy: 0.7714\n",
      "Epoch 897/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7752 - val_loss: 0.5250 - val_accuracy: 0.7688\n",
      "Epoch 898/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7802 - val_loss: 0.5263 - val_accuracy: 0.7714\n",
      "Epoch 899/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7785 - val_loss: 0.5253 - val_accuracy: 0.7688\n",
      "Epoch 900/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7760 - val_loss: 0.5457 - val_accuracy: 0.7613\n",
      "Epoch 901/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7827 - val_loss: 0.5344 - val_accuracy: 0.7688\n",
      "Epoch 902/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7777 - val_loss: 0.5202 - val_accuracy: 0.7714\n",
      "Epoch 903/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7785 - val_loss: 0.5328 - val_accuracy: 0.7688\n",
      "Epoch 904/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7752 - val_loss: 0.5379 - val_accuracy: 0.7688\n",
      "Epoch 905/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7802 - val_loss: 0.5357 - val_accuracy: 0.7487\n",
      "Epoch 906/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7752 - val_loss: 0.5200 - val_accuracy: 0.7638\n",
      "Epoch 907/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7760 - val_loss: 0.5203 - val_accuracy: 0.7714\n",
      "Epoch 908/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7777 - val_loss: 0.5213 - val_accuracy: 0.7714\n",
      "Epoch 909/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7819 - val_loss: 0.5199 - val_accuracy: 0.7688\n",
      "Epoch 910/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7777 - val_loss: 0.5258 - val_accuracy: 0.7714\n",
      "Epoch 911/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7760 - val_loss: 0.5200 - val_accuracy: 0.7688\n",
      "Epoch 912/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7768 - val_loss: 0.5581 - val_accuracy: 0.7563\n",
      "Epoch 913/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7785 - val_loss: 0.5222 - val_accuracy: 0.7663\n",
      "Epoch 914/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7752 - val_loss: 0.5257 - val_accuracy: 0.7688\n",
      "Epoch 915/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7768 - val_loss: 0.5217 - val_accuracy: 0.7663\n",
      "Epoch 916/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7752 - val_loss: 0.5197 - val_accuracy: 0.7688\n",
      "Epoch 917/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7794 - val_loss: 0.5195 - val_accuracy: 0.7613\n",
      "Epoch 918/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7810 - val_loss: 0.5504 - val_accuracy: 0.7613\n",
      "Epoch 919/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7794 - val_loss: 0.5229 - val_accuracy: 0.7638\n",
      "Epoch 920/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7785 - val_loss: 0.5486 - val_accuracy: 0.7613\n",
      "Epoch 921/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7794 - val_loss: 0.5276 - val_accuracy: 0.7714\n",
      "Epoch 922/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7760 - val_loss: 0.5199 - val_accuracy: 0.7714\n",
      "Epoch 923/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7760 - val_loss: 0.5201 - val_accuracy: 0.7714\n",
      "Epoch 924/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7768 - val_loss: 0.5233 - val_accuracy: 0.7688\n",
      "Epoch 925/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7760 - val_loss: 0.5212 - val_accuracy: 0.7714\n",
      "Epoch 926/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7802 - val_loss: 0.5198 - val_accuracy: 0.7613\n",
      "Epoch 927/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7777 - val_loss: 0.5311 - val_accuracy: 0.7714\n",
      "Epoch 928/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7802 - val_loss: 0.5389 - val_accuracy: 0.7688\n",
      "Epoch 929/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7802 - val_loss: 0.5198 - val_accuracy: 0.7714\n",
      "Epoch 930/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7752 - val_loss: 0.5404 - val_accuracy: 0.7688\n",
      "Epoch 931/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7802 - val_loss: 0.5332 - val_accuracy: 0.7688\n",
      "Epoch 932/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7743 - val_loss: 0.5202 - val_accuracy: 0.7638\n",
      "Epoch 933/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7760 - val_loss: 0.5203 - val_accuracy: 0.7714\n",
      "Epoch 934/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7638\n",
      "Epoch 935/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7819 - val_loss: 0.5197 - val_accuracy: 0.7613\n",
      "Epoch 936/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7777 - val_loss: 0.5404 - val_accuracy: 0.7688\n",
      "Epoch 937/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7752 - val_loss: 0.5195 - val_accuracy: 0.7714\n",
      "Epoch 938/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7768 - val_loss: 0.5406 - val_accuracy: 0.7688\n",
      "Epoch 939/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7785 - val_loss: 0.5263 - val_accuracy: 0.7714\n",
      "Epoch 940/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7794 - val_loss: 0.5295 - val_accuracy: 0.7588\n",
      "Epoch 941/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7727 - val_loss: 0.5194 - val_accuracy: 0.7613\n",
      "Epoch 942/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7768 - val_loss: 0.5200 - val_accuracy: 0.7613\n",
      "Epoch 943/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7768 - val_loss: 0.5378 - val_accuracy: 0.7688\n",
      "Epoch 944/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7844 - val_loss: 0.5248 - val_accuracy: 0.7688\n",
      "Epoch 945/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7810 - val_loss: 0.5194 - val_accuracy: 0.7613\n",
      "Epoch 946/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7794 - val_loss: 0.5287 - val_accuracy: 0.7714\n",
      "Epoch 947/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7777 - val_loss: 0.5275 - val_accuracy: 0.7714\n",
      "Epoch 948/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7802 - val_loss: 0.5324 - val_accuracy: 0.7688\n",
      "Epoch 949/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7802 - val_loss: 0.5298 - val_accuracy: 0.7714\n",
      "Epoch 950/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7785 - val_loss: 0.5335 - val_accuracy: 0.7688\n",
      "Epoch 951/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7777 - val_loss: 0.5200 - val_accuracy: 0.7613\n",
      "Epoch 952/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7819 - val_loss: 0.5213 - val_accuracy: 0.7714\n",
      "Epoch 953/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7794 - val_loss: 0.5225 - val_accuracy: 0.7638\n",
      "Epoch 954/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7785 - val_loss: 0.5192 - val_accuracy: 0.7613\n",
      "Epoch 955/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7768 - val_loss: 0.5353 - val_accuracy: 0.7688\n",
      "Epoch 956/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7810 - val_loss: 0.5197 - val_accuracy: 0.7638\n",
      "Epoch 957/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7743 - val_loss: 0.5214 - val_accuracy: 0.7663\n",
      "Epoch 958/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7794 - val_loss: 0.5269 - val_accuracy: 0.7714\n",
      "Epoch 959/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7663\n",
      "Epoch 960/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7768 - val_loss: 0.5192 - val_accuracy: 0.7613\n",
      "Epoch 961/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7794 - val_loss: 0.5200 - val_accuracy: 0.7663\n",
      "Epoch 962/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7794 - val_loss: 0.5275 - val_accuracy: 0.7714\n",
      "Epoch 963/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7810 - val_loss: 0.5196 - val_accuracy: 0.7663\n",
      "Epoch 964/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7794 - val_loss: 0.5231 - val_accuracy: 0.7688\n",
      "Epoch 965/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7802 - val_loss: 0.5189 - val_accuracy: 0.7688\n",
      "Epoch 966/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7752 - val_loss: 0.5256 - val_accuracy: 0.7714\n",
      "Epoch 967/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7768 - val_loss: 0.5357 - val_accuracy: 0.7688\n",
      "Epoch 968/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7785 - val_loss: 0.5274 - val_accuracy: 0.7714\n",
      "Epoch 969/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7777 - val_loss: 0.5214 - val_accuracy: 0.7663\n",
      "Epoch 970/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7768 - val_loss: 0.5331 - val_accuracy: 0.7663\n",
      "Epoch 971/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7802 - val_loss: 0.5240 - val_accuracy: 0.7688\n",
      "Epoch 972/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7777 - val_loss: 0.5448 - val_accuracy: 0.7638\n",
      "Epoch 973/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7768 - val_loss: 0.5189 - val_accuracy: 0.7688\n",
      "Epoch 974/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7768 - val_loss: 0.5188 - val_accuracy: 0.7613\n",
      "Epoch 975/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7785 - val_loss: 0.5188 - val_accuracy: 0.7688\n",
      "Epoch 976/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7794 - val_loss: 0.5271 - val_accuracy: 0.7714\n",
      "Epoch 977/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7810 - val_loss: 0.5396 - val_accuracy: 0.7663\n",
      "Epoch 978/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7794 - val_loss: 0.5238 - val_accuracy: 0.7688\n",
      "Epoch 979/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7735 - val_loss: 0.5236 - val_accuracy: 0.7688\n",
      "Epoch 980/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7785 - val_loss: 0.5320 - val_accuracy: 0.7688\n",
      "Epoch 981/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7802 - val_loss: 0.5369 - val_accuracy: 0.7688\n",
      "Epoch 982/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7777 - val_loss: 0.5518 - val_accuracy: 0.7613\n",
      "Epoch 983/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7802 - val_loss: 0.5199 - val_accuracy: 0.7714\n",
      "Epoch 984/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7760 - val_loss: 0.5243 - val_accuracy: 0.7688\n",
      "Epoch 985/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7802 - val_loss: 0.5378 - val_accuracy: 0.7688\n",
      "Epoch 986/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7777 - val_loss: 0.5189 - val_accuracy: 0.7613\n",
      "Epoch 987/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7768 - val_loss: 0.5190 - val_accuracy: 0.7613\n",
      "Epoch 988/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7802 - val_loss: 0.5186 - val_accuracy: 0.7613\n",
      "Epoch 989/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7760 - val_loss: 0.5185 - val_accuracy: 0.7613\n",
      "Epoch 990/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7752 - val_loss: 0.5264 - val_accuracy: 0.7714\n",
      "Epoch 991/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7785 - val_loss: 0.5441 - val_accuracy: 0.7613\n",
      "Epoch 992/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7752 - val_loss: 0.5217 - val_accuracy: 0.7688\n",
      "Epoch 993/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7827 - val_loss: 0.5240 - val_accuracy: 0.7714\n",
      "Epoch 994/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7768 - val_loss: 0.5187 - val_accuracy: 0.7663\n",
      "Epoch 995/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7794 - val_loss: 0.5198 - val_accuracy: 0.7714\n",
      "Epoch 996/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7785 - val_loss: 0.5289 - val_accuracy: 0.7688\n",
      "Epoch 997/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7794 - val_loss: 0.5181 - val_accuracy: 0.7613\n",
      "Epoch 998/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7777 - val_loss: 0.5196 - val_accuracy: 0.7714\n",
      "Epoch 999/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7819 - val_loss: 0.5326 - val_accuracy: 0.7588\n",
      "Epoch 1000/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7710 - val_loss: 0.5226 - val_accuracy: 0.7688\n"
     ]
    }
   ],
   "source": [
    "history = model_1.fit(X_train,y_train, validation_data=(X_valid, y_valid), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f754adb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'ro', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bd95b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.507840096950531, 'accuracy': 0.7776845693588257}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(X_train, y_train, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ed6269f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5225900411605835, 'accuracy': 0.7688442468643188}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(X_valid, y_valid, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7375f3b7",
   "metadata": {},
   "source": [
    "## Model two\n",
    "\n",
    "[Adam optimiser](https://arxiv.org/abs/1412.6980)\n",
    "\n",
    "[Binary Cross entropy](https://www.analyticsvidhya.com/blog/2021/03/binary-cross-entropy-log-loss-for-binary-classification/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e5346f32",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_5 (Flatten)         (None, 12)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               3328      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,842\n",
      "Trainable params: 3,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(12,)),\n",
    "    tf.keras.layers.Dense(256, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d7f47fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_2.compile(optimizer=opt, \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5ad69255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "38/38 [==============================] - 1s 6ms/step - loss: 0.6386 - accuracy: 0.6518 - val_loss: 0.6400 - val_accuracy: 0.6256\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6535 - val_loss: 0.6107 - val_accuracy: 0.7337\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.7139 - val_loss: 0.5814 - val_accuracy: 0.7161\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.7777 - val_loss: 0.5616 - val_accuracy: 0.7714\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7735 - val_loss: 0.5454 - val_accuracy: 0.7663\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7643 - val_loss: 0.5568 - val_accuracy: 0.7663\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7752 - val_loss: 0.5435 - val_accuracy: 0.7638\n",
      "Epoch 8/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7718 - val_loss: 0.5400 - val_accuracy: 0.7588\n",
      "Epoch 9/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7727 - val_loss: 0.5394 - val_accuracy: 0.7588\n",
      "Epoch 10/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.7710 - val_loss: 0.5417 - val_accuracy: 0.7638\n",
      "Epoch 11/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7659 - val_loss: 0.5418 - val_accuracy: 0.7538\n",
      "Epoch 12/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7710 - val_loss: 0.5491 - val_accuracy: 0.7688\n",
      "Epoch 13/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7743 - val_loss: 0.5468 - val_accuracy: 0.7638\n",
      "Epoch 14/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7727 - val_loss: 0.5369 - val_accuracy: 0.7538\n",
      "Epoch 15/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7743 - val_loss: 0.5392 - val_accuracy: 0.7588\n",
      "Epoch 16/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7727 - val_loss: 0.5364 - val_accuracy: 0.7588\n",
      "Epoch 17/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7743 - val_loss: 0.5419 - val_accuracy: 0.7638\n",
      "Epoch 18/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7701 - val_loss: 0.5372 - val_accuracy: 0.7588\n",
      "Epoch 19/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7659 - val_loss: 0.5572 - val_accuracy: 0.7613\n",
      "Epoch 20/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7768 - val_loss: 0.5414 - val_accuracy: 0.7638\n",
      "Epoch 21/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7768 - val_loss: 0.5393 - val_accuracy: 0.7613\n",
      "Epoch 22/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7710 - val_loss: 0.5332 - val_accuracy: 0.7513\n",
      "Epoch 23/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7727 - val_loss: 0.5335 - val_accuracy: 0.7588\n",
      "Epoch 24/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7701 - val_loss: 0.5424 - val_accuracy: 0.7638\n",
      "Epoch 25/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7701 - val_loss: 0.5322 - val_accuracy: 0.7513\n",
      "Epoch 26/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7743 - val_loss: 0.5314 - val_accuracy: 0.7538\n",
      "Epoch 27/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7760 - val_loss: 0.5357 - val_accuracy: 0.7613\n",
      "Epoch 28/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7710 - val_loss: 0.5331 - val_accuracy: 0.7613\n",
      "Epoch 29/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7727 - val_loss: 0.5302 - val_accuracy: 0.7513\n",
      "Epoch 30/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7718 - val_loss: 0.5326 - val_accuracy: 0.7638\n",
      "Epoch 31/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7768 - val_loss: 0.5318 - val_accuracy: 0.7613\n",
      "Epoch 32/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7701 - val_loss: 0.5355 - val_accuracy: 0.7613\n",
      "Epoch 33/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7794 - val_loss: 0.5296 - val_accuracy: 0.7638\n",
      "Epoch 34/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7718 - val_loss: 0.5279 - val_accuracy: 0.7588\n",
      "Epoch 35/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7718 - val_loss: 0.5374 - val_accuracy: 0.7688\n",
      "Epoch 36/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7727 - val_loss: 0.5299 - val_accuracy: 0.7638\n",
      "Epoch 37/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7760 - val_loss: 0.5373 - val_accuracy: 0.7588\n",
      "Epoch 38/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7735 - val_loss: 0.5319 - val_accuracy: 0.7638\n",
      "Epoch 39/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7760 - val_loss: 0.5291 - val_accuracy: 0.7638\n",
      "Epoch 40/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7718 - val_loss: 0.5236 - val_accuracy: 0.7588\n",
      "Epoch 41/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7768 - val_loss: 0.5268 - val_accuracy: 0.7638\n",
      "Epoch 42/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7735 - val_loss: 0.5247 - val_accuracy: 0.7638\n",
      "Epoch 43/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7760 - val_loss: 0.5227 - val_accuracy: 0.7588\n",
      "Epoch 44/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7752 - val_loss: 0.5248 - val_accuracy: 0.7638\n",
      "Epoch 45/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7718 - val_loss: 0.5217 - val_accuracy: 0.7613\n",
      "Epoch 46/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7735 - val_loss: 0.5256 - val_accuracy: 0.7688\n",
      "Epoch 47/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7752 - val_loss: 0.5251 - val_accuracy: 0.7688\n",
      "Epoch 48/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7743 - val_loss: 0.5369 - val_accuracy: 0.7638\n",
      "Epoch 49/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7743 - val_loss: 0.5201 - val_accuracy: 0.7638\n",
      "Epoch 50/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7735 - val_loss: 0.5241 - val_accuracy: 0.7688\n",
      "Epoch 51/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7752 - val_loss: 0.5212 - val_accuracy: 0.7663\n",
      "Epoch 52/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7768 - val_loss: 0.5312 - val_accuracy: 0.7638\n",
      "Epoch 53/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7760 - val_loss: 0.5222 - val_accuracy: 0.7613\n",
      "Epoch 54/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7760 - val_loss: 0.5243 - val_accuracy: 0.7714\n",
      "Epoch 55/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7777 - val_loss: 0.5525 - val_accuracy: 0.7638\n",
      "Epoch 56/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7777 - val_loss: 0.5216 - val_accuracy: 0.7714\n",
      "Epoch 57/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7785 - val_loss: 0.5170 - val_accuracy: 0.7638\n",
      "Epoch 58/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7752 - val_loss: 0.5176 - val_accuracy: 0.7688\n",
      "Epoch 59/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7752 - val_loss: 0.5169 - val_accuracy: 0.7663\n",
      "Epoch 60/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7768 - val_loss: 0.5582 - val_accuracy: 0.7638\n",
      "Epoch 61/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7768 - val_loss: 0.5190 - val_accuracy: 0.7688\n",
      "Epoch 62/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7785 - val_loss: 0.5187 - val_accuracy: 0.7714\n",
      "Epoch 63/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7785 - val_loss: 0.5153 - val_accuracy: 0.7663\n",
      "Epoch 64/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7701 - val_loss: 0.5184 - val_accuracy: 0.7688\n",
      "Epoch 65/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7760 - val_loss: 0.5305 - val_accuracy: 0.7613\n",
      "Epoch 66/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7777 - val_loss: 0.5172 - val_accuracy: 0.7714\n",
      "Epoch 67/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7768 - val_loss: 0.5150 - val_accuracy: 0.7663\n",
      "Epoch 68/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7785 - val_loss: 0.5167 - val_accuracy: 0.7714\n",
      "Epoch 69/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7777 - val_loss: 0.5159 - val_accuracy: 0.7613\n",
      "Epoch 70/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7810 - val_loss: 0.5137 - val_accuracy: 0.7688\n",
      "Epoch 71/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7768 - val_loss: 0.5155 - val_accuracy: 0.7714\n",
      "Epoch 72/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7768 - val_loss: 0.5135 - val_accuracy: 0.7688\n",
      "Epoch 73/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7777 - val_loss: 0.5201 - val_accuracy: 0.7638\n",
      "Epoch 74/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.7777 - val_loss: 0.5250 - val_accuracy: 0.7613\n",
      "Epoch 75/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7836 - val_loss: 0.5124 - val_accuracy: 0.7688\n",
      "Epoch 76/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.7752 - val_loss: 0.5186 - val_accuracy: 0.7663\n",
      "Epoch 77/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7777 - val_loss: 0.5155 - val_accuracy: 0.7663\n",
      "Epoch 78/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.7777 - val_loss: 0.5160 - val_accuracy: 0.7663\n",
      "Epoch 79/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7836 - val_loss: 0.5219 - val_accuracy: 0.7588\n",
      "Epoch 80/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7752 - val_loss: 0.5143 - val_accuracy: 0.7663\n",
      "Epoch 81/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7794 - val_loss: 0.5417 - val_accuracy: 0.7638\n",
      "Epoch 82/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7810 - val_loss: 0.5116 - val_accuracy: 0.7714\n",
      "Epoch 83/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7802 - val_loss: 0.5193 - val_accuracy: 0.7663\n",
      "Epoch 84/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7810 - val_loss: 0.5121 - val_accuracy: 0.7714\n",
      "Epoch 85/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7785 - val_loss: 0.5170 - val_accuracy: 0.7663\n",
      "Epoch 86/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7760 - val_loss: 0.5166 - val_accuracy: 0.7739\n",
      "Epoch 87/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.7836 - val_loss: 0.5095 - val_accuracy: 0.7688\n",
      "Epoch 88/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7794 - val_loss: 0.5186 - val_accuracy: 0.7663\n",
      "Epoch 89/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7785 - val_loss: 0.5106 - val_accuracy: 0.7714\n",
      "Epoch 90/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.7802 - val_loss: 0.5111 - val_accuracy: 0.7663\n",
      "Epoch 91/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7802 - val_loss: 0.5159 - val_accuracy: 0.7663\n",
      "Epoch 92/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.7802 - val_loss: 0.5098 - val_accuracy: 0.7688\n",
      "Epoch 93/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7785 - val_loss: 0.5090 - val_accuracy: 0.7688\n",
      "Epoch 94/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.7794 - val_loss: 0.5103 - val_accuracy: 0.7688\n",
      "Epoch 95/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7802 - val_loss: 0.5129 - val_accuracy: 0.7663\n",
      "Epoch 96/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7777 - val_loss: 0.5088 - val_accuracy: 0.7688\n",
      "Epoch 97/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7785 - val_loss: 0.5191 - val_accuracy: 0.7588\n",
      "Epoch 98/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.7802 - val_loss: 0.5098 - val_accuracy: 0.7663\n",
      "Epoch 99/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7802 - val_loss: 0.5081 - val_accuracy: 0.7663\n",
      "Epoch 100/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7827 - val_loss: 0.5117 - val_accuracy: 0.7663\n",
      "Epoch 101/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7752 - val_loss: 0.5100 - val_accuracy: 0.7663\n",
      "Epoch 102/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7802 - val_loss: 0.5076 - val_accuracy: 0.7688\n",
      "Epoch 103/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7802 - val_loss: 0.5178 - val_accuracy: 0.7588\n",
      "Epoch 104/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7827 - val_loss: 0.5073 - val_accuracy: 0.7688\n",
      "Epoch 105/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.7760 - val_loss: 0.5099 - val_accuracy: 0.7764\n",
      "Epoch 106/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7794 - val_loss: 0.5143 - val_accuracy: 0.7638\n",
      "Epoch 107/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7777 - val_loss: 0.5190 - val_accuracy: 0.7588\n",
      "Epoch 108/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7785 - val_loss: 0.5070 - val_accuracy: 0.7688\n",
      "Epoch 109/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.7827 - val_loss: 0.5081 - val_accuracy: 0.7688\n",
      "Epoch 110/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7794 - val_loss: 0.5074 - val_accuracy: 0.7688\n",
      "Epoch 111/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7836 - val_loss: 0.5065 - val_accuracy: 0.7688\n",
      "Epoch 112/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7819 - val_loss: 0.5080 - val_accuracy: 0.7663\n",
      "Epoch 113/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.7802 - val_loss: 0.5091 - val_accuracy: 0.7663\n",
      "Epoch 114/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.7810 - val_loss: 0.5057 - val_accuracy: 0.7688\n",
      "Epoch 115/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7852 - val_loss: 0.5167 - val_accuracy: 0.7839\n",
      "Epoch 116/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7752 - val_loss: 0.5063 - val_accuracy: 0.7688\n",
      "Epoch 117/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7827 - val_loss: 0.5052 - val_accuracy: 0.7714\n",
      "Epoch 118/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.7827 - val_loss: 0.5108 - val_accuracy: 0.7638\n",
      "Epoch 119/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7810 - val_loss: 0.5089 - val_accuracy: 0.7663\n",
      "Epoch 120/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.7810 - val_loss: 0.5081 - val_accuracy: 0.7814\n",
      "Epoch 121/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7785 - val_loss: 0.5058 - val_accuracy: 0.7688\n",
      "Epoch 122/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7827 - val_loss: 0.5059 - val_accuracy: 0.7688\n",
      "Epoch 123/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7810 - val_loss: 0.5057 - val_accuracy: 0.7688\n",
      "Epoch 124/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7802 - val_loss: 0.5048 - val_accuracy: 0.7688\n",
      "Epoch 125/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7819 - val_loss: 0.5044 - val_accuracy: 0.7688\n",
      "Epoch 126/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7827 - val_loss: 0.5106 - val_accuracy: 0.7638\n",
      "Epoch 127/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7810 - val_loss: 0.5046 - val_accuracy: 0.7688\n",
      "Epoch 128/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7760 - val_loss: 0.5102 - val_accuracy: 0.7839\n",
      "Epoch 129/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7861 - val_loss: 0.5158 - val_accuracy: 0.7613\n",
      "Epoch 130/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7794 - val_loss: 0.5214 - val_accuracy: 0.7638\n",
      "Epoch 131/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7819 - val_loss: 0.5074 - val_accuracy: 0.7638\n",
      "Epoch 132/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7827 - val_loss: 0.5083 - val_accuracy: 0.7638\n",
      "Epoch 133/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7844 - val_loss: 0.5041 - val_accuracy: 0.7688\n",
      "Epoch 134/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7777 - val_loss: 0.5079 - val_accuracy: 0.7638\n",
      "Epoch 135/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7827 - val_loss: 0.5037 - val_accuracy: 0.7714\n",
      "Epoch 136/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7836 - val_loss: 0.5089 - val_accuracy: 0.7638\n",
      "Epoch 137/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7810 - val_loss: 0.5042 - val_accuracy: 0.7688\n",
      "Epoch 138/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7844 - val_loss: 0.5114 - val_accuracy: 0.7638\n",
      "Epoch 139/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7810 - val_loss: 0.5034 - val_accuracy: 0.7688\n",
      "Epoch 140/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7819 - val_loss: 0.5035 - val_accuracy: 0.7688\n",
      "Epoch 141/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.7844 - val_loss: 0.5042 - val_accuracy: 0.7663\n",
      "Epoch 142/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7827 - val_loss: 0.5048 - val_accuracy: 0.7663\n",
      "Epoch 143/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7836 - val_loss: 0.5037 - val_accuracy: 0.7663\n",
      "Epoch 144/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7819 - val_loss: 0.5054 - val_accuracy: 0.7814\n",
      "Epoch 145/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.7836 - val_loss: 0.5052 - val_accuracy: 0.7814\n",
      "Epoch 146/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.7844 - val_loss: 0.5043 - val_accuracy: 0.7663\n",
      "Epoch 147/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7810 - val_loss: 0.5205 - val_accuracy: 0.7663\n",
      "Epoch 148/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7802 - val_loss: 0.5054 - val_accuracy: 0.7638\n",
      "Epoch 149/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7819 - val_loss: 0.5041 - val_accuracy: 0.7864\n",
      "Epoch 150/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7844 - val_loss: 0.5331 - val_accuracy: 0.7688\n",
      "Epoch 151/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7819 - val_loss: 0.5022 - val_accuracy: 0.7714\n",
      "Epoch 152/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.7844 - val_loss: 0.5092 - val_accuracy: 0.7638\n",
      "Epoch 153/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7844 - val_loss: 0.5059 - val_accuracy: 0.7638\n",
      "Epoch 154/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7844 - val_loss: 0.5090 - val_accuracy: 0.7638\n",
      "Epoch 155/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7802 - val_loss: 0.5098 - val_accuracy: 0.7613\n",
      "Epoch 156/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7869 - val_loss: 0.5035 - val_accuracy: 0.7663\n",
      "Epoch 157/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.7861 - val_loss: 0.5059 - val_accuracy: 0.7638\n",
      "Epoch 158/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.7844 - val_loss: 0.5040 - val_accuracy: 0.7889\n",
      "Epoch 159/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7827 - val_loss: 0.5106 - val_accuracy: 0.7638\n",
      "Epoch 160/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7861 - val_loss: 0.5056 - val_accuracy: 0.7638\n",
      "Epoch 161/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7836 - val_loss: 0.5012 - val_accuracy: 0.7764\n",
      "Epoch 162/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7836 - val_loss: 0.5014 - val_accuracy: 0.7739\n",
      "Epoch 163/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7869 - val_loss: 0.5011 - val_accuracy: 0.7714\n",
      "Epoch 164/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7861 - val_loss: 0.5020 - val_accuracy: 0.7688\n",
      "Epoch 165/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7869 - val_loss: 0.5008 - val_accuracy: 0.7714\n",
      "Epoch 166/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7819 - val_loss: 0.5030 - val_accuracy: 0.7638\n",
      "Epoch 167/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7852 - val_loss: 0.5019 - val_accuracy: 0.7638\n",
      "Epoch 168/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7861 - val_loss: 0.5133 - val_accuracy: 0.7688\n",
      "Epoch 169/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7894 - val_loss: 0.5139 - val_accuracy: 0.7688\n",
      "Epoch 170/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7836 - val_loss: 0.5002 - val_accuracy: 0.7764\n",
      "Epoch 171/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7903 - val_loss: 0.5098 - val_accuracy: 0.7965\n",
      "Epoch 172/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7861 - val_loss: 0.5017 - val_accuracy: 0.7688\n",
      "Epoch 173/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7928 - val_loss: 0.5012 - val_accuracy: 0.7764\n",
      "Epoch 174/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7861 - val_loss: 0.5000 - val_accuracy: 0.7739\n",
      "Epoch 175/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.7869 - val_loss: 0.5128 - val_accuracy: 0.7663\n",
      "Epoch 176/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7852 - val_loss: 0.5001 - val_accuracy: 0.7688\n",
      "Epoch 177/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.7827 - val_loss: 0.5042 - val_accuracy: 0.7638\n",
      "Epoch 178/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7852 - val_loss: 0.4992 - val_accuracy: 0.7714\n",
      "Epoch 179/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7810 - val_loss: 0.4990 - val_accuracy: 0.7739\n",
      "Epoch 180/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7844 - val_loss: 0.5039 - val_accuracy: 0.7638\n",
      "Epoch 181/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.7852 - val_loss: 0.5004 - val_accuracy: 0.7663\n",
      "Epoch 182/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7869 - val_loss: 0.4999 - val_accuracy: 0.7688\n",
      "Epoch 183/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7861 - val_loss: 0.4981 - val_accuracy: 0.7764\n",
      "Epoch 184/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.7869 - val_loss: 0.5078 - val_accuracy: 0.7638\n",
      "Epoch 185/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7869 - val_loss: 0.5083 - val_accuracy: 0.7663\n",
      "Epoch 186/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7869 - val_loss: 0.5037 - val_accuracy: 0.7638\n",
      "Epoch 187/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7861 - val_loss: 0.5161 - val_accuracy: 0.7688\n",
      "Epoch 188/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7894 - val_loss: 0.4988 - val_accuracy: 0.7688\n",
      "Epoch 189/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7836 - val_loss: 0.5007 - val_accuracy: 0.7663\n",
      "Epoch 190/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7878 - val_loss: 0.5110 - val_accuracy: 0.7663\n",
      "Epoch 191/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7844 - val_loss: 0.4988 - val_accuracy: 0.7864\n",
      "Epoch 192/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7844 - val_loss: 0.5134 - val_accuracy: 0.7663\n",
      "Epoch 193/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7903 - val_loss: 0.5010 - val_accuracy: 0.7663\n",
      "Epoch 194/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7844 - val_loss: 0.4972 - val_accuracy: 0.7739\n",
      "Epoch 195/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7836 - val_loss: 0.4976 - val_accuracy: 0.7714\n",
      "Epoch 196/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7886 - val_loss: 0.5001 - val_accuracy: 0.7663\n",
      "Epoch 197/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7869 - val_loss: 0.4965 - val_accuracy: 0.7739\n",
      "Epoch 198/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7886 - val_loss: 0.4998 - val_accuracy: 0.7663\n",
      "Epoch 199/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7836 - val_loss: 0.4977 - val_accuracy: 0.7889\n",
      "Epoch 200/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7852 - val_loss: 0.4966 - val_accuracy: 0.7789\n",
      "Epoch 201/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7878 - val_loss: 0.5175 - val_accuracy: 0.7663\n",
      "Epoch 202/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7852 - val_loss: 0.4984 - val_accuracy: 0.7688\n",
      "Epoch 203/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.7861 - val_loss: 0.4965 - val_accuracy: 0.7789\n",
      "Epoch 204/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.7919 - val_loss: 0.4962 - val_accuracy: 0.7814\n",
      "Epoch 205/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7886 - val_loss: 0.5002 - val_accuracy: 0.7663\n",
      "Epoch 206/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7878 - val_loss: 0.4963 - val_accuracy: 0.7764\n",
      "Epoch 207/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.7911 - val_loss: 0.5140 - val_accuracy: 0.7714\n",
      "Epoch 208/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7878 - val_loss: 0.4955 - val_accuracy: 0.7789\n",
      "Epoch 209/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7878 - val_loss: 0.4957 - val_accuracy: 0.7789\n",
      "Epoch 210/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.7886 - val_loss: 0.4959 - val_accuracy: 0.7714\n",
      "Epoch 211/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7869 - val_loss: 0.5021 - val_accuracy: 0.7940\n",
      "Epoch 212/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.7945 - val_loss: 0.4967 - val_accuracy: 0.7688\n",
      "Epoch 213/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.7886 - val_loss: 0.5045 - val_accuracy: 0.7688\n",
      "Epoch 214/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.7886 - val_loss: 0.4980 - val_accuracy: 0.7839\n",
      "Epoch 215/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7928 - val_loss: 0.5015 - val_accuracy: 0.7663\n",
      "Epoch 216/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7919 - val_loss: 0.4944 - val_accuracy: 0.7814\n",
      "Epoch 217/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7919 - val_loss: 0.4951 - val_accuracy: 0.7714\n",
      "Epoch 218/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7911 - val_loss: 0.4976 - val_accuracy: 0.7688\n",
      "Epoch 219/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7894 - val_loss: 0.4949 - val_accuracy: 0.7789\n",
      "Epoch 220/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.7936 - val_loss: 0.5004 - val_accuracy: 0.7688\n",
      "Epoch 221/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7852 - val_loss: 0.4942 - val_accuracy: 0.7789\n",
      "Epoch 222/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7919 - val_loss: 0.4945 - val_accuracy: 0.7764\n",
      "Epoch 223/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7928 - val_loss: 0.4970 - val_accuracy: 0.7864\n",
      "Epoch 224/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7903 - val_loss: 0.4990 - val_accuracy: 0.7714\n",
      "Epoch 225/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7861 - val_loss: 0.4936 - val_accuracy: 0.7789\n",
      "Epoch 226/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7928 - val_loss: 0.4996 - val_accuracy: 0.7714\n",
      "Epoch 227/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7894 - val_loss: 0.4949 - val_accuracy: 0.7739\n",
      "Epoch 228/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7869 - val_loss: 0.4935 - val_accuracy: 0.7889\n",
      "Epoch 229/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7869 - val_loss: 0.4967 - val_accuracy: 0.7714\n",
      "Epoch 230/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7878 - val_loss: 0.4938 - val_accuracy: 0.7889\n",
      "Epoch 231/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7894 - val_loss: 0.4940 - val_accuracy: 0.7789\n",
      "Epoch 232/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7945 - val_loss: 0.4947 - val_accuracy: 0.7864\n",
      "Epoch 233/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7844 - val_loss: 0.4961 - val_accuracy: 0.7688\n",
      "Epoch 234/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7945 - val_loss: 0.4945 - val_accuracy: 0.7764\n",
      "Epoch 235/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7903 - val_loss: 0.4930 - val_accuracy: 0.7839\n",
      "Epoch 236/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7819 - val_loss: 0.5152 - val_accuracy: 0.7663\n",
      "Epoch 237/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7878 - val_loss: 0.4940 - val_accuracy: 0.7739\n",
      "Epoch 238/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7928 - val_loss: 0.5129 - val_accuracy: 0.7688\n",
      "Epoch 239/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7844 - val_loss: 0.4930 - val_accuracy: 0.7814\n",
      "Epoch 240/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7894 - val_loss: 0.5001 - val_accuracy: 0.7714\n",
      "Epoch 241/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.7928 - val_loss: 0.4928 - val_accuracy: 0.7764\n",
      "Epoch 242/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7911 - val_loss: 0.4930 - val_accuracy: 0.7864\n",
      "Epoch 243/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7953 - val_loss: 0.5018 - val_accuracy: 0.7965\n",
      "Epoch 244/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7953 - val_loss: 0.4932 - val_accuracy: 0.7764\n",
      "Epoch 245/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7945 - val_loss: 0.5072 - val_accuracy: 0.7688\n",
      "Epoch 246/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.7928 - val_loss: 0.4993 - val_accuracy: 0.7688\n",
      "Epoch 247/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7936 - val_loss: 0.4923 - val_accuracy: 0.7764\n",
      "Epoch 248/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7961 - val_loss: 0.4969 - val_accuracy: 0.7714\n",
      "Epoch 249/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7903 - val_loss: 0.5027 - val_accuracy: 0.7714\n",
      "Epoch 250/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7903 - val_loss: 0.4919 - val_accuracy: 0.7764\n",
      "Epoch 251/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7961 - val_loss: 0.4918 - val_accuracy: 0.7864\n",
      "Epoch 252/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7945 - val_loss: 0.4914 - val_accuracy: 0.7864\n",
      "Epoch 253/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7936 - val_loss: 0.4942 - val_accuracy: 0.7764\n",
      "Epoch 254/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7953 - val_loss: 0.4972 - val_accuracy: 0.7739\n",
      "Epoch 255/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7919 - val_loss: 0.4925 - val_accuracy: 0.7864\n",
      "Epoch 256/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7919 - val_loss: 0.4917 - val_accuracy: 0.7839\n",
      "Epoch 257/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7961 - val_loss: 0.5142 - val_accuracy: 0.7688\n",
      "Epoch 258/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7953 - val_loss: 0.4928 - val_accuracy: 0.7864\n",
      "Epoch 259/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.7936 - val_loss: 0.4956 - val_accuracy: 0.7739\n",
      "Epoch 260/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7945 - val_loss: 0.4985 - val_accuracy: 0.7714\n",
      "Epoch 261/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7894 - val_loss: 0.4906 - val_accuracy: 0.7814\n",
      "Epoch 262/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7936 - val_loss: 0.4914 - val_accuracy: 0.7789\n",
      "Epoch 263/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7928 - val_loss: 0.4910 - val_accuracy: 0.7764\n",
      "Epoch 264/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7886 - val_loss: 0.4904 - val_accuracy: 0.7839\n",
      "Epoch 265/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7995 - val_loss: 0.5004 - val_accuracy: 0.7714\n",
      "Epoch 266/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7970 - val_loss: 0.4909 - val_accuracy: 0.7864\n",
      "Epoch 267/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7945 - val_loss: 0.4909 - val_accuracy: 0.7814\n",
      "Epoch 268/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7928 - val_loss: 0.4897 - val_accuracy: 0.7814\n",
      "Epoch 269/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7928 - val_loss: 0.4996 - val_accuracy: 0.7739\n",
      "Epoch 270/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7928 - val_loss: 0.5012 - val_accuracy: 0.7764\n",
      "Epoch 271/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7945 - val_loss: 0.4912 - val_accuracy: 0.7864\n",
      "Epoch 272/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7978 - val_loss: 0.4908 - val_accuracy: 0.7789\n",
      "Epoch 273/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7903 - val_loss: 0.4899 - val_accuracy: 0.7814\n",
      "Epoch 274/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7928 - val_loss: 0.5037 - val_accuracy: 0.7739\n",
      "Epoch 275/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.8020 - val_loss: 0.4952 - val_accuracy: 0.7739\n",
      "Epoch 276/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7970 - val_loss: 0.4946 - val_accuracy: 0.7764\n",
      "Epoch 277/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7936 - val_loss: 0.4899 - val_accuracy: 0.7864\n",
      "Epoch 278/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7864\n",
      "Epoch 279/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7961 - val_loss: 0.5011 - val_accuracy: 0.7764\n",
      "Epoch 280/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7945 - val_loss: 0.4892 - val_accuracy: 0.7739\n",
      "Epoch 281/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7961 - val_loss: 0.4883 - val_accuracy: 0.7839\n",
      "Epoch 282/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7995 - val_loss: 0.5038 - val_accuracy: 0.7739\n",
      "Epoch 283/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7945 - val_loss: 0.4954 - val_accuracy: 0.7739\n",
      "Epoch 284/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7953 - val_loss: 0.4897 - val_accuracy: 0.7789\n",
      "Epoch 285/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7945 - val_loss: 0.4968 - val_accuracy: 0.7965\n",
      "Epoch 286/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7961 - val_loss: 0.4888 - val_accuracy: 0.7814\n",
      "Epoch 287/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7978 - val_loss: 0.5000 - val_accuracy: 0.7739\n",
      "Epoch 288/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7953 - val_loss: 0.4882 - val_accuracy: 0.7839\n",
      "Epoch 289/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7978 - val_loss: 0.4902 - val_accuracy: 0.7764\n",
      "Epoch 290/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7987 - val_loss: 0.4978 - val_accuracy: 0.7739\n",
      "Epoch 291/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7936 - val_loss: 0.4888 - val_accuracy: 0.7814\n",
      "Epoch 292/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7961 - val_loss: 0.4933 - val_accuracy: 0.7739\n",
      "Epoch 293/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7911 - val_loss: 0.4923 - val_accuracy: 0.7764\n",
      "Epoch 294/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.8070 - val_loss: 0.4988 - val_accuracy: 0.7739\n",
      "Epoch 295/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7995 - val_loss: 0.4917 - val_accuracy: 0.7764\n",
      "Epoch 296/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7953 - val_loss: 0.4887 - val_accuracy: 0.7839\n",
      "Epoch 297/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7945 - val_loss: 0.5032 - val_accuracy: 0.7739\n",
      "Epoch 298/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.8012 - val_loss: 0.4912 - val_accuracy: 0.7764\n",
      "Epoch 299/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7987 - val_loss: 0.4903 - val_accuracy: 0.7864\n",
      "Epoch 300/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.8020 - val_loss: 0.4970 - val_accuracy: 0.7739\n",
      "Epoch 301/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7970 - val_loss: 0.4897 - val_accuracy: 0.7864\n",
      "Epoch 302/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7970 - val_loss: 0.4962 - val_accuracy: 0.7714\n",
      "Epoch 303/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7936 - val_loss: 0.4890 - val_accuracy: 0.7839\n",
      "Epoch 304/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7978 - val_loss: 0.4886 - val_accuracy: 0.7839\n",
      "Epoch 305/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.8020 - val_loss: 0.4893 - val_accuracy: 0.7839\n",
      "Epoch 306/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7961 - val_loss: 0.4880 - val_accuracy: 0.7839\n",
      "Epoch 307/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7936 - val_loss: 0.4903 - val_accuracy: 0.7764\n",
      "Epoch 308/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7987 - val_loss: 0.4885 - val_accuracy: 0.7839\n",
      "Epoch 309/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7995 - val_loss: 0.4895 - val_accuracy: 0.7814\n",
      "Epoch 310/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7987 - val_loss: 0.5026 - val_accuracy: 0.7739\n",
      "Epoch 311/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7970 - val_loss: 0.4875 - val_accuracy: 0.7839\n",
      "Epoch 312/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7987 - val_loss: 0.4873 - val_accuracy: 0.7839\n",
      "Epoch 313/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7995 - val_loss: 0.4968 - val_accuracy: 0.7764\n",
      "Epoch 314/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.8003 - val_loss: 0.4883 - val_accuracy: 0.7889\n",
      "Epoch 315/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7987 - val_loss: 0.4879 - val_accuracy: 0.7839\n",
      "Epoch 316/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7995 - val_loss: 0.4881 - val_accuracy: 0.7839\n",
      "Epoch 317/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7970 - val_loss: 0.4927 - val_accuracy: 0.7739\n",
      "Epoch 318/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7953 - val_loss: 0.4881 - val_accuracy: 0.7839\n",
      "Epoch 319/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7978 - val_loss: 0.4878 - val_accuracy: 0.7839\n",
      "Epoch 320/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.8020 - val_loss: 0.4898 - val_accuracy: 0.7764\n",
      "Epoch 321/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.8029 - val_loss: 0.4875 - val_accuracy: 0.7839\n",
      "Epoch 322/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.8037 - val_loss: 0.4920 - val_accuracy: 0.7739\n",
      "Epoch 323/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7978 - val_loss: 0.4888 - val_accuracy: 0.7789\n",
      "Epoch 324/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7978 - val_loss: 0.4911 - val_accuracy: 0.7764\n",
      "Epoch 325/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.8003 - val_loss: 0.4992 - val_accuracy: 0.7789\n",
      "Epoch 326/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7961 - val_loss: 0.4879 - val_accuracy: 0.7839\n",
      "Epoch 327/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.8012 - val_loss: 0.4935 - val_accuracy: 0.7864\n",
      "Epoch 328/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7995 - val_loss: 0.4981 - val_accuracy: 0.7789\n",
      "Epoch 329/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7961 - val_loss: 0.4940 - val_accuracy: 0.7915\n",
      "Epoch 330/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7970 - val_loss: 0.4950 - val_accuracy: 0.7739\n",
      "Epoch 331/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7928 - val_loss: 0.4880 - val_accuracy: 0.7839\n",
      "Epoch 332/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.8045 - val_loss: 0.4918 - val_accuracy: 0.7915\n",
      "Epoch 333/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.8003 - val_loss: 0.5048 - val_accuracy: 0.7714\n",
      "Epoch 334/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.8012 - val_loss: 0.4907 - val_accuracy: 0.7789\n",
      "Epoch 335/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.8003 - val_loss: 0.4874 - val_accuracy: 0.7839\n",
      "Epoch 336/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7953 - val_loss: 0.4903 - val_accuracy: 0.7889\n",
      "Epoch 337/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7978 - val_loss: 0.4926 - val_accuracy: 0.7739\n",
      "Epoch 338/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7995 - val_loss: 0.4942 - val_accuracy: 0.7739\n",
      "Epoch 339/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.8037 - val_loss: 0.4885 - val_accuracy: 0.7814\n",
      "Epoch 340/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.8020 - val_loss: 0.4995 - val_accuracy: 0.7789\n",
      "Epoch 341/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7894 - val_loss: 0.5467 - val_accuracy: 0.7663\n",
      "Epoch 342/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7995 - val_loss: 0.4868 - val_accuracy: 0.7864\n",
      "Epoch 343/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.8012 - val_loss: 0.4884 - val_accuracy: 0.7839\n",
      "Epoch 344/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7995 - val_loss: 0.5182 - val_accuracy: 0.7714\n",
      "Epoch 345/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.8054 - val_loss: 0.4932 - val_accuracy: 0.7789\n",
      "Epoch 346/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7987 - val_loss: 0.4865 - val_accuracy: 0.7839\n",
      "Epoch 347/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.8045 - val_loss: 0.4929 - val_accuracy: 0.7739\n",
      "Epoch 348/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.8037 - val_loss: 0.4870 - val_accuracy: 0.7839\n",
      "Epoch 349/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7995 - val_loss: 0.4891 - val_accuracy: 0.7789\n",
      "Epoch 350/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.8012 - val_loss: 0.5100 - val_accuracy: 0.7739\n",
      "Epoch 351/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7978 - val_loss: 0.4875 - val_accuracy: 0.7915\n",
      "Epoch 352/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7978 - val_loss: 0.4874 - val_accuracy: 0.7814\n",
      "Epoch 353/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.8003 - val_loss: 0.5064 - val_accuracy: 0.7764\n",
      "Epoch 354/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7961 - val_loss: 0.4884 - val_accuracy: 0.7889\n",
      "Epoch 355/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.8054 - val_loss: 0.4970 - val_accuracy: 0.7814\n",
      "Epoch 356/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.8037 - val_loss: 0.4991 - val_accuracy: 0.7814\n",
      "Epoch 357/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.8079 - val_loss: 0.4912 - val_accuracy: 0.7789\n",
      "Epoch 358/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7995 - val_loss: 0.4922 - val_accuracy: 0.7789\n",
      "Epoch 359/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7995 - val_loss: 0.4881 - val_accuracy: 0.7889\n",
      "Epoch 360/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.8070 - val_loss: 0.4982 - val_accuracy: 0.7764\n",
      "Epoch 361/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.8062 - val_loss: 0.4955 - val_accuracy: 0.7814\n",
      "Epoch 362/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.8045 - val_loss: 0.5101 - val_accuracy: 0.7764\n",
      "Epoch 363/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.8012 - val_loss: 0.4881 - val_accuracy: 0.7940\n",
      "Epoch 364/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.8003 - val_loss: 0.4886 - val_accuracy: 0.7839\n",
      "Epoch 365/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.8029 - val_loss: 0.4991 - val_accuracy: 0.7789\n",
      "Epoch 366/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.8003 - val_loss: 0.5015 - val_accuracy: 0.7789\n",
      "Epoch 367/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7978 - val_loss: 0.4870 - val_accuracy: 0.7814\n",
      "Epoch 368/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.8029 - val_loss: 0.4868 - val_accuracy: 0.7889\n",
      "Epoch 369/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7886 - val_loss: 0.5094 - val_accuracy: 0.7739\n",
      "Epoch 370/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.8045 - val_loss: 0.4978 - val_accuracy: 0.7814\n",
      "Epoch 371/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.8045 - val_loss: 0.4884 - val_accuracy: 0.7839\n",
      "Epoch 372/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.8003 - val_loss: 0.4944 - val_accuracy: 0.7814\n",
      "Epoch 373/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.8020 - val_loss: 0.4894 - val_accuracy: 0.7814\n",
      "Epoch 374/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.8062 - val_loss: 0.4861 - val_accuracy: 0.7864\n",
      "Epoch 375/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.8029 - val_loss: 0.5009 - val_accuracy: 0.7839\n",
      "Epoch 376/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.8003 - val_loss: 0.4867 - val_accuracy: 0.7814\n",
      "Epoch 377/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.8020 - val_loss: 0.4916 - val_accuracy: 0.7789\n",
      "Epoch 378/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.8029 - val_loss: 0.4871 - val_accuracy: 0.7814\n",
      "Epoch 379/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.8062 - val_loss: 0.4868 - val_accuracy: 0.7814\n",
      "Epoch 380/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.8054 - val_loss: 0.4944 - val_accuracy: 0.7839\n",
      "Epoch 381/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7961 - val_loss: 0.5000 - val_accuracy: 0.7839\n",
      "Epoch 382/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7978 - val_loss: 0.4865 - val_accuracy: 0.7814\n",
      "Epoch 383/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.8029 - val_loss: 0.4886 - val_accuracy: 0.7814\n",
      "Epoch 384/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.8112 - val_loss: 0.4855 - val_accuracy: 0.7814\n",
      "Epoch 385/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.8037 - val_loss: 0.5372 - val_accuracy: 0.7638\n",
      "Epoch 386/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.8087 - val_loss: 0.4947 - val_accuracy: 0.7814\n",
      "Epoch 387/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7978 - val_loss: 0.4867 - val_accuracy: 0.7889\n",
      "Epoch 388/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.8054 - val_loss: 0.5201 - val_accuracy: 0.7789\n",
      "Epoch 389/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7995 - val_loss: 0.4923 - val_accuracy: 0.7764\n",
      "Epoch 390/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.8045 - val_loss: 0.5043 - val_accuracy: 0.7789\n",
      "Epoch 391/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7995 - val_loss: 0.4882 - val_accuracy: 0.7814\n",
      "Epoch 392/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.8062 - val_loss: 0.4968 - val_accuracy: 0.7814\n",
      "Epoch 393/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7995 - val_loss: 0.4898 - val_accuracy: 0.7814\n",
      "Epoch 394/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.8012 - val_loss: 0.4851 - val_accuracy: 0.7889\n",
      "Epoch 395/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.8003 - val_loss: 0.4855 - val_accuracy: 0.7864\n",
      "Epoch 396/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.8087 - val_loss: 0.4912 - val_accuracy: 0.7814\n",
      "Epoch 397/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.8054 - val_loss: 0.4874 - val_accuracy: 0.7814\n",
      "Epoch 398/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.8003 - val_loss: 0.4916 - val_accuracy: 0.7814\n",
      "Epoch 399/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.8020 - val_loss: 0.4875 - val_accuracy: 0.7889\n",
      "Epoch 400/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.8029 - val_loss: 0.4887 - val_accuracy: 0.7814\n",
      "Epoch 401/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.8079 - val_loss: 0.4862 - val_accuracy: 0.7814\n",
      "Epoch 402/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.8037 - val_loss: 0.4867 - val_accuracy: 0.7814\n",
      "Epoch 403/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.8054 - val_loss: 0.4857 - val_accuracy: 0.7889\n",
      "Epoch 404/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.8045 - val_loss: 0.4874 - val_accuracy: 0.7839\n",
      "Epoch 405/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.8003 - val_loss: 0.4879 - val_accuracy: 0.7915\n",
      "Epoch 406/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.8104 - val_loss: 0.4952 - val_accuracy: 0.7839\n",
      "Epoch 407/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.8112 - val_loss: 0.4893 - val_accuracy: 0.7839\n",
      "Epoch 408/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.8020 - val_loss: 0.4984 - val_accuracy: 0.7864\n",
      "Epoch 409/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.8012 - val_loss: 0.4904 - val_accuracy: 0.7864\n",
      "Epoch 410/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.8112 - val_loss: 0.4951 - val_accuracy: 0.7864\n",
      "Epoch 411/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.8054 - val_loss: 0.4868 - val_accuracy: 0.7814\n",
      "Epoch 412/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.8054 - val_loss: 0.4853 - val_accuracy: 0.7889\n",
      "Epoch 413/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.8003 - val_loss: 0.5271 - val_accuracy: 0.7739\n",
      "Epoch 414/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.8079 - val_loss: 0.4872 - val_accuracy: 0.7839\n",
      "Epoch 415/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.8054 - val_loss: 0.5184 - val_accuracy: 0.7764\n",
      "Epoch 416/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.8079 - val_loss: 0.4861 - val_accuracy: 0.7915\n",
      "Epoch 417/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.8020 - val_loss: 0.4917 - val_accuracy: 0.7915\n",
      "Epoch 418/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.8079 - val_loss: 0.4870 - val_accuracy: 0.7864\n",
      "Epoch 419/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.8087 - val_loss: 0.4867 - val_accuracy: 0.7915\n",
      "Epoch 420/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.8079 - val_loss: 0.4858 - val_accuracy: 0.7915\n",
      "Epoch 421/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.8112 - val_loss: 0.4868 - val_accuracy: 0.7864\n",
      "Epoch 422/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7995 - val_loss: 0.4961 - val_accuracy: 0.7839\n",
      "Epoch 423/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7995 - val_loss: 0.4867 - val_accuracy: 0.7839\n",
      "Epoch 424/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.8020 - val_loss: 0.4922 - val_accuracy: 0.7839\n",
      "Epoch 425/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.8062 - val_loss: 0.4902 - val_accuracy: 0.7839\n",
      "Epoch 426/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.8079 - val_loss: 0.4886 - val_accuracy: 0.7839\n",
      "Epoch 427/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.8037 - val_loss: 0.4993 - val_accuracy: 0.7839\n",
      "Epoch 428/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.8079 - val_loss: 0.4926 - val_accuracy: 0.7839\n",
      "Epoch 429/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.8062 - val_loss: 0.4914 - val_accuracy: 0.7864\n",
      "Epoch 430/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.8054 - val_loss: 0.4871 - val_accuracy: 0.7814\n",
      "Epoch 431/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.8037 - val_loss: 0.4879 - val_accuracy: 0.7839\n",
      "Epoch 432/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.8087 - val_loss: 0.4971 - val_accuracy: 0.7839\n",
      "Epoch 433/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.8045 - val_loss: 0.4907 - val_accuracy: 0.7965\n",
      "Epoch 434/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7995 - val_loss: 0.4883 - val_accuracy: 0.7839\n",
      "Epoch 435/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.8062 - val_loss: 0.4860 - val_accuracy: 0.7915\n",
      "Epoch 436/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.8045 - val_loss: 0.4927 - val_accuracy: 0.7839\n",
      "Epoch 437/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.8121 - val_loss: 0.4842 - val_accuracy: 0.7839\n",
      "Epoch 438/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.8045 - val_loss: 0.4994 - val_accuracy: 0.7839\n",
      "Epoch 439/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.8054 - val_loss: 0.4858 - val_accuracy: 0.7940\n",
      "Epoch 440/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.8054 - val_loss: 0.4863 - val_accuracy: 0.7915\n",
      "Epoch 441/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.8054 - val_loss: 0.4941 - val_accuracy: 0.7839\n",
      "Epoch 442/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.8012 - val_loss: 0.4884 - val_accuracy: 0.7940\n",
      "Epoch 443/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.8079 - val_loss: 0.4948 - val_accuracy: 0.7814\n",
      "Epoch 444/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.8087 - val_loss: 0.4848 - val_accuracy: 0.7864\n",
      "Epoch 445/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.8138 - val_loss: 0.4886 - val_accuracy: 0.7839\n",
      "Epoch 446/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.8054 - val_loss: 0.4873 - val_accuracy: 0.7839\n",
      "Epoch 447/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.8045 - val_loss: 0.4843 - val_accuracy: 0.7915\n",
      "Epoch 448/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.8020 - val_loss: 0.5117 - val_accuracy: 0.7864\n",
      "Epoch 449/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.8045 - val_loss: 0.4878 - val_accuracy: 0.7839\n",
      "Epoch 450/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.8070 - val_loss: 0.5005 - val_accuracy: 0.7839\n",
      "Epoch 451/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.8054 - val_loss: 0.5142 - val_accuracy: 0.7864\n",
      "Epoch 452/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.8070 - val_loss: 0.5008 - val_accuracy: 0.7839\n",
      "Epoch 453/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.8020 - val_loss: 0.4954 - val_accuracy: 0.7864\n",
      "Epoch 454/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.8062 - val_loss: 0.4903 - val_accuracy: 0.7864\n",
      "Epoch 455/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.8112 - val_loss: 0.4868 - val_accuracy: 0.7889\n",
      "Epoch 456/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.8070 - val_loss: 0.4857 - val_accuracy: 0.7889\n",
      "Epoch 457/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.8070 - val_loss: 0.4892 - val_accuracy: 0.7864\n",
      "Epoch 458/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.8079 - val_loss: 0.4852 - val_accuracy: 0.7889\n",
      "Epoch 459/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.8087 - val_loss: 0.4874 - val_accuracy: 0.7889\n",
      "Epoch 460/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.8012 - val_loss: 0.4906 - val_accuracy: 0.7940\n",
      "Epoch 461/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.8020 - val_loss: 0.5281 - val_accuracy: 0.7789\n",
      "Epoch 462/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.8045 - val_loss: 0.4852 - val_accuracy: 0.7839\n",
      "Epoch 463/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.8062 - val_loss: 0.4881 - val_accuracy: 0.7839\n",
      "Epoch 464/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.8079 - val_loss: 0.4868 - val_accuracy: 0.7839\n",
      "Epoch 465/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.8096 - val_loss: 0.4900 - val_accuracy: 0.7839\n",
      "Epoch 466/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.8079 - val_loss: 0.4846 - val_accuracy: 0.7889\n",
      "Epoch 467/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.8079 - val_loss: 0.4937 - val_accuracy: 0.7839\n",
      "Epoch 468/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.8045 - val_loss: 0.4848 - val_accuracy: 0.7940\n",
      "Epoch 469/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.8129 - val_loss: 0.4905 - val_accuracy: 0.7864\n",
      "Epoch 470/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.8070 - val_loss: 0.4871 - val_accuracy: 0.7839\n",
      "Epoch 471/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.8020 - val_loss: 0.4854 - val_accuracy: 0.7864\n",
      "Epoch 472/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.8121 - val_loss: 0.4926 - val_accuracy: 0.7864\n",
      "Epoch 473/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.8037 - val_loss: 0.4852 - val_accuracy: 0.7889\n",
      "Epoch 474/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.8079 - val_loss: 0.4860 - val_accuracy: 0.7889\n",
      "Epoch 475/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.8129 - val_loss: 0.4858 - val_accuracy: 0.7889\n",
      "Epoch 476/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.8062 - val_loss: 0.4860 - val_accuracy: 0.7864\n",
      "Epoch 477/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.8096 - val_loss: 0.5093 - val_accuracy: 0.7889\n",
      "Epoch 478/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.8054 - val_loss: 0.4920 - val_accuracy: 0.7839\n",
      "Epoch 479/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.8079 - val_loss: 0.4859 - val_accuracy: 0.7915\n",
      "Epoch 480/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.8062 - val_loss: 0.4854 - val_accuracy: 0.7889\n",
      "Epoch 481/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.8096 - val_loss: 0.4850 - val_accuracy: 0.7915\n",
      "Epoch 482/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.8070 - val_loss: 0.4930 - val_accuracy: 0.7864\n",
      "Epoch 483/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.8037 - val_loss: 0.4827 - val_accuracy: 0.7940\n",
      "Epoch 484/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.8146 - val_loss: 0.4882 - val_accuracy: 0.7864\n",
      "Epoch 485/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.8070 - val_loss: 0.4898 - val_accuracy: 0.7839\n",
      "Epoch 486/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.8062 - val_loss: 0.4946 - val_accuracy: 0.7864\n",
      "Epoch 487/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.8070 - val_loss: 0.4872 - val_accuracy: 0.7839\n",
      "Epoch 488/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.8070 - val_loss: 0.5036 - val_accuracy: 0.7864\n",
      "Epoch 489/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.8096 - val_loss: 0.4848 - val_accuracy: 0.7915\n",
      "Epoch 490/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.8096 - val_loss: 0.4947 - val_accuracy: 0.7864\n",
      "Epoch 491/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.8054 - val_loss: 0.4909 - val_accuracy: 0.7915\n",
      "Epoch 492/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.8129 - val_loss: 0.5107 - val_accuracy: 0.7889\n",
      "Epoch 493/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.8070 - val_loss: 0.4880 - val_accuracy: 0.7965\n",
      "Epoch 494/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.8020 - val_loss: 0.4920 - val_accuracy: 0.7864\n",
      "Epoch 495/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.8104 - val_loss: 0.4886 - val_accuracy: 0.7965\n",
      "Epoch 496/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.8062 - val_loss: 0.4845 - val_accuracy: 0.7889\n",
      "Epoch 497/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.8070 - val_loss: 0.4843 - val_accuracy: 0.7864\n",
      "Epoch 498/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.8062 - val_loss: 0.4854 - val_accuracy: 0.7864\n",
      "Epoch 499/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.8121 - val_loss: 0.4958 - val_accuracy: 0.7839\n",
      "Epoch 500/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.8045 - val_loss: 0.4916 - val_accuracy: 0.7864\n",
      "Epoch 501/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.8104 - val_loss: 0.4849 - val_accuracy: 0.7965\n",
      "Epoch 502/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.8062 - val_loss: 0.4854 - val_accuracy: 0.7839\n",
      "Epoch 503/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.8062 - val_loss: 0.4862 - val_accuracy: 0.7965\n",
      "Epoch 504/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.8079 - val_loss: 0.4868 - val_accuracy: 0.7839\n",
      "Epoch 505/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.8112 - val_loss: 0.4939 - val_accuracy: 0.7864\n",
      "Epoch 506/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.8029 - val_loss: 0.4862 - val_accuracy: 0.7965\n",
      "Epoch 507/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.8096 - val_loss: 0.4850 - val_accuracy: 0.7864\n",
      "Epoch 508/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.8037 - val_loss: 0.4996 - val_accuracy: 0.7864\n",
      "Epoch 509/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.8096 - val_loss: 0.4920 - val_accuracy: 0.7864\n",
      "Epoch 510/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.8029 - val_loss: 0.5116 - val_accuracy: 0.7864\n",
      "Epoch 511/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.8037 - val_loss: 0.5021 - val_accuracy: 0.7839\n",
      "Epoch 512/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.8087 - val_loss: 0.4857 - val_accuracy: 0.7889\n",
      "Epoch 513/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.8096 - val_loss: 0.4876 - val_accuracy: 0.7864\n",
      "Epoch 514/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.8070 - val_loss: 0.4846 - val_accuracy: 0.7940\n",
      "Epoch 515/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.8087 - val_loss: 0.4867 - val_accuracy: 0.7864\n",
      "Epoch 516/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.8096 - val_loss: 0.4867 - val_accuracy: 0.7990\n",
      "Epoch 517/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7987 - val_loss: 0.4847 - val_accuracy: 0.8015\n",
      "Epoch 518/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.8062 - val_loss: 0.5020 - val_accuracy: 0.7839\n",
      "Epoch 519/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.8062 - val_loss: 0.4851 - val_accuracy: 0.7965\n",
      "Epoch 520/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.8020 - val_loss: 0.4860 - val_accuracy: 0.7864\n",
      "Epoch 521/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.8037 - val_loss: 0.4875 - val_accuracy: 0.7965\n",
      "Epoch 522/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.8087 - val_loss: 0.4844 - val_accuracy: 0.7965\n",
      "Epoch 523/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.8070 - val_loss: 0.4892 - val_accuracy: 0.7864\n",
      "Epoch 524/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.8020 - val_loss: 0.4848 - val_accuracy: 0.7889\n",
      "Epoch 525/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.8079 - val_loss: 0.4856 - val_accuracy: 0.7864\n",
      "Epoch 526/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.8096 - val_loss: 0.4879 - val_accuracy: 0.7839\n",
      "Epoch 527/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.8104 - val_loss: 0.4900 - val_accuracy: 0.7864\n",
      "Epoch 528/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.8096 - val_loss: 0.4876 - val_accuracy: 0.7889\n",
      "Epoch 529/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.8104 - val_loss: 0.4875 - val_accuracy: 0.8015\n",
      "Epoch 530/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.8079 - val_loss: 0.4961 - val_accuracy: 0.7864\n",
      "Epoch 531/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.8087 - val_loss: 0.4871 - val_accuracy: 0.7864\n",
      "Epoch 532/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.8029 - val_loss: 0.4916 - val_accuracy: 0.8090\n",
      "Epoch 533/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.8087 - val_loss: 0.4994 - val_accuracy: 0.7864\n",
      "Epoch 534/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.8112 - val_loss: 0.4949 - val_accuracy: 0.7889\n",
      "Epoch 535/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.8096 - val_loss: 0.4931 - val_accuracy: 0.7889\n",
      "Epoch 536/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.8104 - val_loss: 0.4847 - val_accuracy: 0.7915\n",
      "Epoch 537/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.8121 - val_loss: 0.4858 - val_accuracy: 0.7915\n",
      "Epoch 538/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.8112 - val_loss: 0.4861 - val_accuracy: 0.7915\n",
      "Epoch 539/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.8062 - val_loss: 0.4928 - val_accuracy: 0.7889\n",
      "Epoch 540/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.8121 - val_loss: 0.4850 - val_accuracy: 0.8040\n",
      "Epoch 541/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.8054 - val_loss: 0.4870 - val_accuracy: 0.7839\n",
      "Epoch 542/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.8079 - val_loss: 0.4858 - val_accuracy: 0.7990\n",
      "Epoch 543/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.8087 - val_loss: 0.4946 - val_accuracy: 0.7864\n",
      "Epoch 544/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.8045 - val_loss: 0.4867 - val_accuracy: 0.7940\n",
      "Epoch 545/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.8104 - val_loss: 0.5084 - val_accuracy: 0.7889\n",
      "Epoch 546/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.8029 - val_loss: 0.4896 - val_accuracy: 0.7864\n",
      "Epoch 547/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.8029 - val_loss: 0.4867 - val_accuracy: 0.7839\n",
      "Epoch 548/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.8079 - val_loss: 0.5009 - val_accuracy: 0.7864\n",
      "Epoch 549/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.8096 - val_loss: 0.4853 - val_accuracy: 0.7864\n",
      "Epoch 550/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.8096 - val_loss: 0.4899 - val_accuracy: 0.7889\n",
      "Epoch 551/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.8062 - val_loss: 0.4887 - val_accuracy: 0.8065\n",
      "Epoch 552/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.8029 - val_loss: 0.5046 - val_accuracy: 0.7889\n",
      "Epoch 553/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.8054 - val_loss: 0.4998 - val_accuracy: 0.8065\n",
      "Epoch 554/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.8096 - val_loss: 0.4856 - val_accuracy: 0.7990\n",
      "Epoch 555/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.8079 - val_loss: 0.4844 - val_accuracy: 0.7965\n",
      "Epoch 556/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.8087 - val_loss: 0.5038 - val_accuracy: 0.7864\n",
      "Epoch 557/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.8112 - val_loss: 0.4974 - val_accuracy: 0.7864\n",
      "Epoch 558/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.8087 - val_loss: 0.4845 - val_accuracy: 0.7940\n",
      "Epoch 559/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.8104 - val_loss: 0.4877 - val_accuracy: 0.7889\n",
      "Epoch 560/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.8079 - val_loss: 0.4929 - val_accuracy: 0.7889\n",
      "Epoch 561/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.8087 - val_loss: 0.4938 - val_accuracy: 0.7889\n",
      "Epoch 562/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.8129 - val_loss: 0.4868 - val_accuracy: 0.7915\n",
      "Epoch 563/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.8129 - val_loss: 0.4833 - val_accuracy: 0.8065\n",
      "Epoch 564/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.8104 - val_loss: 0.4834 - val_accuracy: 0.7990\n",
      "Epoch 565/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.8070 - val_loss: 0.4990 - val_accuracy: 0.7864\n",
      "Epoch 566/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.8062 - val_loss: 0.4908 - val_accuracy: 0.7915\n",
      "Epoch 567/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.8096 - val_loss: 0.4847 - val_accuracy: 0.8040\n",
      "Epoch 568/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.8087 - val_loss: 0.4843 - val_accuracy: 0.7990\n",
      "Epoch 569/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.8045 - val_loss: 0.4913 - val_accuracy: 0.7889\n",
      "Epoch 570/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.8129 - val_loss: 0.4848 - val_accuracy: 0.7940\n",
      "Epoch 571/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.8062 - val_loss: 0.4858 - val_accuracy: 0.8015\n",
      "Epoch 572/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.8096 - val_loss: 0.4857 - val_accuracy: 0.7915\n",
      "Epoch 573/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.8070 - val_loss: 0.4886 - val_accuracy: 0.7889\n",
      "Epoch 574/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.8062 - val_loss: 0.4849 - val_accuracy: 0.7915\n",
      "Epoch 575/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.8112 - val_loss: 0.4956 - val_accuracy: 0.7864\n",
      "Epoch 576/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.8121 - val_loss: 0.5086 - val_accuracy: 0.7889\n",
      "Epoch 577/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.8096 - val_loss: 0.5002 - val_accuracy: 0.7889\n",
      "Epoch 578/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.8096 - val_loss: 0.4902 - val_accuracy: 0.7915\n",
      "Epoch 579/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.8138 - val_loss: 0.4884 - val_accuracy: 0.7889\n",
      "Epoch 580/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.8121 - val_loss: 0.4940 - val_accuracy: 0.7889\n",
      "Epoch 581/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.8138 - val_loss: 0.4973 - val_accuracy: 0.7864\n",
      "Epoch 582/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.8096 - val_loss: 0.4864 - val_accuracy: 0.7940\n",
      "Epoch 583/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.8112 - val_loss: 0.4850 - val_accuracy: 0.7889\n",
      "Epoch 584/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.8062 - val_loss: 0.4908 - val_accuracy: 0.7915\n",
      "Epoch 585/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.8079 - val_loss: 0.4947 - val_accuracy: 0.7864\n",
      "Epoch 586/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.8104 - val_loss: 0.4952 - val_accuracy: 0.7864\n",
      "Epoch 587/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.8129 - val_loss: 0.4836 - val_accuracy: 0.8015\n",
      "Epoch 588/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.8096 - val_loss: 0.4954 - val_accuracy: 0.7864\n",
      "Epoch 589/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.8062 - val_loss: 0.4866 - val_accuracy: 0.7864\n",
      "Epoch 590/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.8062 - val_loss: 0.4849 - val_accuracy: 0.8065\n",
      "Epoch 591/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.8087 - val_loss: 0.4859 - val_accuracy: 0.8015\n",
      "Epoch 592/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.8087 - val_loss: 0.4878 - val_accuracy: 0.8015\n",
      "Epoch 593/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.8104 - val_loss: 0.4885 - val_accuracy: 0.7940\n",
      "Epoch 594/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.8112 - val_loss: 0.4894 - val_accuracy: 0.7915\n",
      "Epoch 595/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.8121 - val_loss: 0.4885 - val_accuracy: 0.7940\n",
      "Epoch 596/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.8087 - val_loss: 0.4878 - val_accuracy: 0.7915\n",
      "Epoch 597/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.8112 - val_loss: 0.4873 - val_accuracy: 0.7889\n",
      "Epoch 598/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.8087 - val_loss: 0.4854 - val_accuracy: 0.7889\n",
      "Epoch 599/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.8112 - val_loss: 0.4882 - val_accuracy: 0.7915\n",
      "Epoch 600/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.8054 - val_loss: 0.4965 - val_accuracy: 0.7889\n",
      "Epoch 601/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.8096 - val_loss: 0.4898 - val_accuracy: 0.7940\n",
      "Epoch 602/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.8070 - val_loss: 0.4864 - val_accuracy: 0.8065\n",
      "Epoch 603/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.8104 - val_loss: 0.4833 - val_accuracy: 0.8040\n",
      "Epoch 604/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.8146 - val_loss: 0.4876 - val_accuracy: 0.7915\n",
      "Epoch 605/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.8104 - val_loss: 0.5164 - val_accuracy: 0.7915\n",
      "Epoch 606/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.8037 - val_loss: 0.4843 - val_accuracy: 0.8015\n",
      "Epoch 607/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.8070 - val_loss: 0.4886 - val_accuracy: 0.7940\n",
      "Epoch 608/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.8138 - val_loss: 0.4873 - val_accuracy: 0.7915\n",
      "Epoch 609/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.8062 - val_loss: 0.4919 - val_accuracy: 0.7915\n",
      "Epoch 610/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.8062 - val_loss: 0.4902 - val_accuracy: 0.7940\n",
      "Epoch 611/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.8104 - val_loss: 0.4866 - val_accuracy: 0.7915\n",
      "Epoch 612/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.8070 - val_loss: 0.4852 - val_accuracy: 0.8015\n",
      "Epoch 613/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.8104 - val_loss: 0.4870 - val_accuracy: 0.7990\n",
      "Epoch 614/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.8079 - val_loss: 0.5024 - val_accuracy: 0.7915\n",
      "Epoch 615/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.8112 - val_loss: 0.4918 - val_accuracy: 0.7940\n",
      "Epoch 616/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.8121 - val_loss: 0.4891 - val_accuracy: 0.7940\n",
      "Epoch 617/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.8062 - val_loss: 0.4844 - val_accuracy: 0.7940\n",
      "Epoch 618/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.8154 - val_loss: 0.4867 - val_accuracy: 0.7915\n",
      "Epoch 619/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.8079 - val_loss: 0.4924 - val_accuracy: 0.7940\n",
      "Epoch 620/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.8087 - val_loss: 0.4860 - val_accuracy: 0.8090\n",
      "Epoch 621/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.8054 - val_loss: 0.4837 - val_accuracy: 0.8040\n",
      "Epoch 622/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.8079 - val_loss: 0.4873 - val_accuracy: 0.7940\n",
      "Epoch 623/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.8079 - val_loss: 0.4847 - val_accuracy: 0.7940\n",
      "Epoch 624/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.8104 - val_loss: 0.4901 - val_accuracy: 0.7940\n",
      "Epoch 625/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.8112 - val_loss: 0.5115 - val_accuracy: 0.7940\n",
      "Epoch 626/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.8079 - val_loss: 0.4840 - val_accuracy: 0.8015\n",
      "Epoch 627/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.8096 - val_loss: 0.4843 - val_accuracy: 0.7915\n",
      "Epoch 628/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.8104 - val_loss: 0.4909 - val_accuracy: 0.7940\n",
      "Epoch 629/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.8112 - val_loss: 0.4888 - val_accuracy: 0.7965\n",
      "Epoch 630/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.8121 - val_loss: 0.4852 - val_accuracy: 0.8090\n",
      "Epoch 631/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.8070 - val_loss: 0.4848 - val_accuracy: 0.7965\n",
      "Epoch 632/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.8121 - val_loss: 0.4915 - val_accuracy: 0.7940\n",
      "Epoch 633/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.8138 - val_loss: 0.4944 - val_accuracy: 0.7965\n",
      "Epoch 634/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.8096 - val_loss: 0.4833 - val_accuracy: 0.8015\n",
      "Epoch 635/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.8129 - val_loss: 0.4938 - val_accuracy: 0.7915\n",
      "Epoch 636/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.8070 - val_loss: 0.4858 - val_accuracy: 0.7940\n",
      "Epoch 637/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.8121 - val_loss: 0.4978 - val_accuracy: 0.7915\n",
      "Epoch 638/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.8121 - val_loss: 0.4865 - val_accuracy: 0.8090\n",
      "Epoch 639/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.8087 - val_loss: 0.4892 - val_accuracy: 0.7965\n",
      "Epoch 640/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.8121 - val_loss: 0.4838 - val_accuracy: 0.8015\n",
      "Epoch 641/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.8104 - val_loss: 0.4848 - val_accuracy: 0.8015\n",
      "Epoch 642/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.8070 - val_loss: 0.4855 - val_accuracy: 0.8065\n",
      "Epoch 643/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.8087 - val_loss: 0.4838 - val_accuracy: 0.8015\n",
      "Epoch 644/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.8112 - val_loss: 0.4868 - val_accuracy: 0.8065\n",
      "Epoch 645/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.8096 - val_loss: 0.4920 - val_accuracy: 0.7940\n",
      "Epoch 646/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.8129 - val_loss: 0.5026 - val_accuracy: 0.7915\n",
      "Epoch 647/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.8104 - val_loss: 0.4899 - val_accuracy: 0.7965\n",
      "Epoch 648/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.8104 - val_loss: 0.4866 - val_accuracy: 0.8040\n",
      "Epoch 649/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.8087 - val_loss: 0.5267 - val_accuracy: 0.7915\n",
      "Epoch 650/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.8129 - val_loss: 0.4946 - val_accuracy: 0.7889\n",
      "Epoch 651/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.8079 - val_loss: 0.4839 - val_accuracy: 0.8040\n",
      "Epoch 652/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.8079 - val_loss: 0.4855 - val_accuracy: 0.8065\n",
      "Epoch 653/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.8054 - val_loss: 0.4872 - val_accuracy: 0.7940\n",
      "Epoch 654/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.8087 - val_loss: 0.4898 - val_accuracy: 0.7940\n",
      "Epoch 655/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.8087 - val_loss: 0.4899 - val_accuracy: 0.7940\n",
      "Epoch 656/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.8121 - val_loss: 0.5098 - val_accuracy: 0.7965\n",
      "Epoch 657/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.8112 - val_loss: 0.4927 - val_accuracy: 0.7940\n",
      "Epoch 658/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.8121 - val_loss: 0.4911 - val_accuracy: 0.7965\n",
      "Epoch 659/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.8062 - val_loss: 0.4857 - val_accuracy: 0.8040\n",
      "Epoch 660/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.8112 - val_loss: 0.4857 - val_accuracy: 0.8116\n",
      "Epoch 661/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.8171 - val_loss: 0.5020 - val_accuracy: 0.7889\n",
      "Epoch 662/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.8104 - val_loss: 0.4903 - val_accuracy: 0.7965\n",
      "Epoch 663/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.8112 - val_loss: 0.4876 - val_accuracy: 0.7990\n",
      "Epoch 664/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.8096 - val_loss: 0.4865 - val_accuracy: 0.8040\n",
      "Epoch 665/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.8096 - val_loss: 0.4867 - val_accuracy: 0.8065\n",
      "Epoch 666/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.8062 - val_loss: 0.4900 - val_accuracy: 0.7965\n",
      "Epoch 667/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.8171 - val_loss: 0.5021 - val_accuracy: 0.7940\n",
      "Epoch 668/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.8129 - val_loss: 0.4861 - val_accuracy: 0.7940\n",
      "Epoch 669/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.8129 - val_loss: 0.4911 - val_accuracy: 0.8015\n",
      "Epoch 670/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.8121 - val_loss: 0.4865 - val_accuracy: 0.8015\n",
      "Epoch 671/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.8045 - val_loss: 0.4894 - val_accuracy: 0.7990\n",
      "Epoch 672/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.8138 - val_loss: 0.4888 - val_accuracy: 0.7940\n",
      "Epoch 673/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.8121 - val_loss: 0.4906 - val_accuracy: 0.7965\n",
      "Epoch 674/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.8112 - val_loss: 0.4859 - val_accuracy: 0.8090\n",
      "Epoch 675/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.8054 - val_loss: 0.4884 - val_accuracy: 0.8065\n",
      "Epoch 676/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.8112 - val_loss: 0.4931 - val_accuracy: 0.7965\n",
      "Epoch 677/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8138 - val_loss: 0.4891 - val_accuracy: 0.7940\n",
      "Epoch 678/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.8104 - val_loss: 0.5049 - val_accuracy: 0.7940\n",
      "Epoch 679/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.8121 - val_loss: 0.4867 - val_accuracy: 0.8040\n",
      "Epoch 680/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.8121 - val_loss: 0.4952 - val_accuracy: 0.7940\n",
      "Epoch 681/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.8121 - val_loss: 0.4839 - val_accuracy: 0.8040\n",
      "Epoch 682/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.8079 - val_loss: 0.4933 - val_accuracy: 0.7965\n",
      "Epoch 683/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.8062 - val_loss: 0.5015 - val_accuracy: 0.8015\n",
      "Epoch 684/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.8104 - val_loss: 0.4965 - val_accuracy: 0.7940\n",
      "Epoch 685/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.8129 - val_loss: 0.4889 - val_accuracy: 0.7965\n",
      "Epoch 686/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.8112 - val_loss: 0.4870 - val_accuracy: 0.7965\n",
      "Epoch 687/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.8138 - val_loss: 0.5022 - val_accuracy: 0.7940\n",
      "Epoch 688/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.8112 - val_loss: 0.4866 - val_accuracy: 0.8090\n",
      "Epoch 689/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.8163 - val_loss: 0.4922 - val_accuracy: 0.7965\n",
      "Epoch 690/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.8096 - val_loss: 0.4887 - val_accuracy: 0.8065\n",
      "Epoch 691/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.8138 - val_loss: 0.5087 - val_accuracy: 0.7965\n",
      "Epoch 692/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.8138 - val_loss: 0.4868 - val_accuracy: 0.7990\n",
      "Epoch 693/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.8180 - val_loss: 0.4855 - val_accuracy: 0.8090\n",
      "Epoch 694/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.8096 - val_loss: 0.4889 - val_accuracy: 0.7990\n",
      "Epoch 695/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.8129 - val_loss: 0.4871 - val_accuracy: 0.8090\n",
      "Epoch 696/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.8129 - val_loss: 0.4861 - val_accuracy: 0.8090\n",
      "Epoch 697/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.8121 - val_loss: 0.4973 - val_accuracy: 0.8015\n",
      "Epoch 698/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.8112 - val_loss: 0.4946 - val_accuracy: 0.7965\n",
      "Epoch 699/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.8045 - val_loss: 0.4848 - val_accuracy: 0.8065\n",
      "Epoch 700/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8154 - val_loss: 0.4910 - val_accuracy: 0.7965\n",
      "Epoch 701/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.8112 - val_loss: 0.4964 - val_accuracy: 0.7990\n",
      "Epoch 702/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8163 - val_loss: 0.4970 - val_accuracy: 0.8015\n",
      "Epoch 703/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.8096 - val_loss: 0.4953 - val_accuracy: 0.7990\n",
      "Epoch 704/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.8112 - val_loss: 0.5013 - val_accuracy: 0.8015\n",
      "Epoch 705/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8154 - val_loss: 0.4851 - val_accuracy: 0.8040\n",
      "Epoch 706/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.8138 - val_loss: 0.4868 - val_accuracy: 0.8090\n",
      "Epoch 707/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.8062 - val_loss: 0.4883 - val_accuracy: 0.8090\n",
      "Epoch 708/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.8096 - val_loss: 0.4981 - val_accuracy: 0.7915\n",
      "Epoch 709/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.8146 - val_loss: 0.4922 - val_accuracy: 0.7990\n",
      "Epoch 710/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.8138 - val_loss: 0.4883 - val_accuracy: 0.8040\n",
      "Epoch 711/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.8154 - val_loss: 0.4916 - val_accuracy: 0.8040\n",
      "Epoch 712/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.8112 - val_loss: 0.4924 - val_accuracy: 0.7965\n",
      "Epoch 713/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.8087 - val_loss: 0.4912 - val_accuracy: 0.7990\n",
      "Epoch 714/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8112 - val_loss: 0.4893 - val_accuracy: 0.8090\n",
      "Epoch 715/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.8138 - val_loss: 0.4879 - val_accuracy: 0.8015\n",
      "Epoch 716/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.8146 - val_loss: 0.4909 - val_accuracy: 0.8040\n",
      "Epoch 717/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.8129 - val_loss: 0.4885 - val_accuracy: 0.8015\n",
      "Epoch 718/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.8104 - val_loss: 0.4886 - val_accuracy: 0.7965\n",
      "Epoch 719/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.8112 - val_loss: 0.4878 - val_accuracy: 0.8040\n",
      "Epoch 720/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.8104 - val_loss: 0.4958 - val_accuracy: 0.7940\n",
      "Epoch 721/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.8121 - val_loss: 0.5015 - val_accuracy: 0.8015\n",
      "Epoch 722/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.8096 - val_loss: 0.5027 - val_accuracy: 0.7965\n",
      "Epoch 723/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8129 - val_loss: 0.4870 - val_accuracy: 0.8065\n",
      "Epoch 724/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.8129 - val_loss: 0.4887 - val_accuracy: 0.7965\n",
      "Epoch 725/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.8129 - val_loss: 0.4865 - val_accuracy: 0.8040\n",
      "Epoch 726/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.8146 - val_loss: 0.4877 - val_accuracy: 0.8116\n",
      "Epoch 727/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.8079 - val_loss: 0.5090 - val_accuracy: 0.7940\n",
      "Epoch 728/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.8154 - val_loss: 0.4934 - val_accuracy: 0.7965\n",
      "Epoch 729/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.8079 - val_loss: 0.4892 - val_accuracy: 0.8090\n",
      "Epoch 730/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.8146 - val_loss: 0.4873 - val_accuracy: 0.8040\n",
      "Epoch 731/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.8121 - val_loss: 0.4930 - val_accuracy: 0.8065\n",
      "Epoch 732/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.8163 - val_loss: 0.5067 - val_accuracy: 0.7965\n",
      "Epoch 733/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.8121 - val_loss: 0.4874 - val_accuracy: 0.8040\n",
      "Epoch 734/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.8188 - val_loss: 0.4931 - val_accuracy: 0.7940\n",
      "Epoch 735/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.8129 - val_loss: 0.4903 - val_accuracy: 0.8090\n",
      "Epoch 736/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.8154 - val_loss: 0.4898 - val_accuracy: 0.8040\n",
      "Epoch 737/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.8112 - val_loss: 0.4950 - val_accuracy: 0.7990\n",
      "Epoch 738/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.8129 - val_loss: 0.4894 - val_accuracy: 0.8090\n",
      "Epoch 739/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.8104 - val_loss: 0.4900 - val_accuracy: 0.8141\n",
      "Epoch 740/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.8112 - val_loss: 0.4875 - val_accuracy: 0.8090\n",
      "Epoch 741/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.8104 - val_loss: 0.4903 - val_accuracy: 0.8090\n",
      "Epoch 742/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.8112 - val_loss: 0.4862 - val_accuracy: 0.8040\n",
      "Epoch 743/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.8112 - val_loss: 0.5076 - val_accuracy: 0.7990\n",
      "Epoch 744/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.8121 - val_loss: 0.4923 - val_accuracy: 0.8015\n",
      "Epoch 745/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.8129 - val_loss: 0.4912 - val_accuracy: 0.7965\n",
      "Epoch 746/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8188 - val_loss: 0.4890 - val_accuracy: 0.8065\n",
      "Epoch 747/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.8129 - val_loss: 0.4894 - val_accuracy: 0.8116\n",
      "Epoch 748/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8121 - val_loss: 0.4914 - val_accuracy: 0.8040\n",
      "Epoch 749/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.8129 - val_loss: 0.5075 - val_accuracy: 0.7990\n",
      "Epoch 750/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8163 - val_loss: 0.4925 - val_accuracy: 0.7990\n",
      "Epoch 751/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.8112 - val_loss: 0.5030 - val_accuracy: 0.7965\n",
      "Epoch 752/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.8138 - val_loss: 0.4918 - val_accuracy: 0.8090\n",
      "Epoch 753/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.8138 - val_loss: 0.5182 - val_accuracy: 0.7965\n",
      "Epoch 754/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.8171 - val_loss: 0.4878 - val_accuracy: 0.8040\n",
      "Epoch 755/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.8112 - val_loss: 0.4920 - val_accuracy: 0.8065\n",
      "Epoch 756/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.8180 - val_loss: 0.4911 - val_accuracy: 0.8065\n",
      "Epoch 757/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.8129 - val_loss: 0.4888 - val_accuracy: 0.8015\n",
      "Epoch 758/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.8146 - val_loss: 0.5016 - val_accuracy: 0.7990\n",
      "Epoch 759/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.8112 - val_loss: 0.4926 - val_accuracy: 0.7990\n",
      "Epoch 760/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8112 - val_loss: 0.4988 - val_accuracy: 0.7990\n",
      "Epoch 761/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.8079 - val_loss: 0.5002 - val_accuracy: 0.8015\n",
      "Epoch 762/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.8138 - val_loss: 0.4897 - val_accuracy: 0.8090\n",
      "Epoch 763/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.8154 - val_loss: 0.4965 - val_accuracy: 0.7990\n",
      "Epoch 764/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.8146 - val_loss: 0.4934 - val_accuracy: 0.8065\n",
      "Epoch 765/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8146 - val_loss: 0.4896 - val_accuracy: 0.8065\n",
      "Epoch 766/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.8138 - val_loss: 0.4881 - val_accuracy: 0.8065\n",
      "Epoch 767/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.8146 - val_loss: 0.4919 - val_accuracy: 0.7940\n",
      "Epoch 768/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.8163 - val_loss: 0.4952 - val_accuracy: 0.7965\n",
      "Epoch 769/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.8087 - val_loss: 0.4901 - val_accuracy: 0.8065\n",
      "Epoch 770/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.8154 - val_loss: 0.4904 - val_accuracy: 0.8015\n",
      "Epoch 771/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.8138 - val_loss: 0.4927 - val_accuracy: 0.7990\n",
      "Epoch 772/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.8129 - val_loss: 0.4903 - val_accuracy: 0.8116\n",
      "Epoch 773/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.8138 - val_loss: 0.4895 - val_accuracy: 0.8065\n",
      "Epoch 774/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.8112 - val_loss: 0.4994 - val_accuracy: 0.8040\n",
      "Epoch 775/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.8104 - val_loss: 0.4944 - val_accuracy: 0.7965\n",
      "Epoch 776/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8163 - val_loss: 0.4914 - val_accuracy: 0.8040\n",
      "Epoch 777/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.8096 - val_loss: 0.4940 - val_accuracy: 0.8015\n",
      "Epoch 778/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.8121 - val_loss: 0.4888 - val_accuracy: 0.8065\n",
      "Epoch 779/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.8163 - val_loss: 0.4897 - val_accuracy: 0.8090\n",
      "Epoch 780/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.8129 - val_loss: 0.4888 - val_accuracy: 0.8090\n",
      "Epoch 781/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.8180 - val_loss: 0.4906 - val_accuracy: 0.8065\n",
      "Epoch 782/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.8146 - val_loss: 0.4895 - val_accuracy: 0.8116\n",
      "Epoch 783/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.8154 - val_loss: 0.5062 - val_accuracy: 0.7990\n",
      "Epoch 784/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.8180 - val_loss: 0.4907 - val_accuracy: 0.8040\n",
      "Epoch 785/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.8146 - val_loss: 0.5063 - val_accuracy: 0.7990\n",
      "Epoch 786/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.8154 - val_loss: 0.5089 - val_accuracy: 0.7990\n",
      "Epoch 787/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.8112 - val_loss: 0.4923 - val_accuracy: 0.8040\n",
      "Epoch 788/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.8154 - val_loss: 0.5111 - val_accuracy: 0.7990\n",
      "Epoch 789/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.8171 - val_loss: 0.4984 - val_accuracy: 0.8040\n",
      "Epoch 790/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.8129 - val_loss: 0.5040 - val_accuracy: 0.7990\n",
      "Epoch 791/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.8096 - val_loss: 0.5000 - val_accuracy: 0.8040\n",
      "Epoch 792/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.8188 - val_loss: 0.5218 - val_accuracy: 0.7965\n",
      "Epoch 793/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.8121 - val_loss: 0.4966 - val_accuracy: 0.8065\n",
      "Epoch 794/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.8112 - val_loss: 0.5099 - val_accuracy: 0.8015\n",
      "Epoch 795/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.8121 - val_loss: 0.4906 - val_accuracy: 0.8040\n",
      "Epoch 796/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.8171 - val_loss: 0.4872 - val_accuracy: 0.8141\n",
      "Epoch 797/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8154 - val_loss: 0.4884 - val_accuracy: 0.8116\n",
      "Epoch 798/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8180 - val_loss: 0.4874 - val_accuracy: 0.8116\n",
      "Epoch 799/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.8087 - val_loss: 0.4910 - val_accuracy: 0.8090\n",
      "Epoch 800/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.8112 - val_loss: 0.5028 - val_accuracy: 0.8015\n",
      "Epoch 801/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.8121 - val_loss: 0.4940 - val_accuracy: 0.7965\n",
      "Epoch 802/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.8062 - val_loss: 0.5151 - val_accuracy: 0.7990\n",
      "Epoch 803/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8138 - val_loss: 0.4924 - val_accuracy: 0.8040\n",
      "Epoch 804/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8171 - val_loss: 0.4972 - val_accuracy: 0.8040\n",
      "Epoch 805/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.8112 - val_loss: 0.4891 - val_accuracy: 0.8065\n",
      "Epoch 806/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8171 - val_loss: 0.5112 - val_accuracy: 0.7990\n",
      "Epoch 807/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.8138 - val_loss: 0.4954 - val_accuracy: 0.8040\n",
      "Epoch 808/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.8205 - val_loss: 0.4911 - val_accuracy: 0.8116\n",
      "Epoch 809/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8121 - val_loss: 0.4923 - val_accuracy: 0.8040\n",
      "Epoch 810/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8163 - val_loss: 0.4920 - val_accuracy: 0.8141\n",
      "Epoch 811/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8129 - val_loss: 0.4901 - val_accuracy: 0.8116\n",
      "Epoch 812/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8129 - val_loss: 0.4926 - val_accuracy: 0.8040\n",
      "Epoch 813/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.8146 - val_loss: 0.4979 - val_accuracy: 0.8015\n",
      "Epoch 814/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8154 - val_loss: 0.4929 - val_accuracy: 0.8015\n",
      "Epoch 815/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.8129 - val_loss: 0.4924 - val_accuracy: 0.8040\n",
      "Epoch 816/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.8213 - val_loss: 0.4985 - val_accuracy: 0.8065\n",
      "Epoch 817/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.8121 - val_loss: 0.4967 - val_accuracy: 0.8040\n",
      "Epoch 818/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.8087 - val_loss: 0.4953 - val_accuracy: 0.8065\n",
      "Epoch 819/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8154 - val_loss: 0.4977 - val_accuracy: 0.8040\n",
      "Epoch 820/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8221 - val_loss: 0.4915 - val_accuracy: 0.8090\n",
      "Epoch 821/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8112 - val_loss: 0.4916 - val_accuracy: 0.8090\n",
      "Epoch 822/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8146 - val_loss: 0.4951 - val_accuracy: 0.8040\n",
      "Epoch 823/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.8121 - val_loss: 0.4997 - val_accuracy: 0.8090\n",
      "Epoch 824/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8096 - val_loss: 0.4897 - val_accuracy: 0.8065\n",
      "Epoch 825/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8188 - val_loss: 0.4982 - val_accuracy: 0.7965\n",
      "Epoch 826/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.8180 - val_loss: 0.4939 - val_accuracy: 0.8090\n",
      "Epoch 827/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.8121 - val_loss: 0.4915 - val_accuracy: 0.8065\n",
      "Epoch 828/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8112 - val_loss: 0.5022 - val_accuracy: 0.8090\n",
      "Epoch 829/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8121 - val_loss: 0.4928 - val_accuracy: 0.8116\n",
      "Epoch 830/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8138 - val_loss: 0.4923 - val_accuracy: 0.8065\n",
      "Epoch 831/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.8138 - val_loss: 0.5021 - val_accuracy: 0.8090\n",
      "Epoch 832/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8171 - val_loss: 0.5114 - val_accuracy: 0.8040\n",
      "Epoch 833/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.8138 - val_loss: 0.5034 - val_accuracy: 0.8090\n",
      "Epoch 834/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8163 - val_loss: 0.4936 - val_accuracy: 0.8116\n",
      "Epoch 835/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.8138 - val_loss: 0.5033 - val_accuracy: 0.8040\n",
      "Epoch 836/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.8045 - val_loss: 0.5061 - val_accuracy: 0.8065\n",
      "Epoch 837/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8129 - val_loss: 0.4931 - val_accuracy: 0.8065\n",
      "Epoch 838/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8154 - val_loss: 0.4940 - val_accuracy: 0.8090\n",
      "Epoch 839/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.8171 - val_loss: 0.4908 - val_accuracy: 0.8141\n",
      "Epoch 840/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.8180 - val_loss: 0.4937 - val_accuracy: 0.8166\n",
      "Epoch 841/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8154 - val_loss: 0.4937 - val_accuracy: 0.8116\n",
      "Epoch 842/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8104 - val_loss: 0.4944 - val_accuracy: 0.8065\n",
      "Epoch 843/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.8138 - val_loss: 0.4944 - val_accuracy: 0.8090\n",
      "Epoch 844/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.8213 - val_loss: 0.5068 - val_accuracy: 0.8065\n",
      "Epoch 845/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.8079 - val_loss: 0.5005 - val_accuracy: 0.8040\n",
      "Epoch 846/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8188 - val_loss: 0.4943 - val_accuracy: 0.8065\n",
      "Epoch 847/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.8196 - val_loss: 0.4945 - val_accuracy: 0.8166\n",
      "Epoch 848/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8129 - val_loss: 0.5044 - val_accuracy: 0.8040\n",
      "Epoch 849/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.8146 - val_loss: 0.4955 - val_accuracy: 0.8191\n",
      "Epoch 850/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.8205 - val_loss: 0.5018 - val_accuracy: 0.8040\n",
      "Epoch 851/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8146 - val_loss: 0.4931 - val_accuracy: 0.8116\n",
      "Epoch 852/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8138 - val_loss: 0.4994 - val_accuracy: 0.8040\n",
      "Epoch 853/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8196 - val_loss: 0.4953 - val_accuracy: 0.8141\n",
      "Epoch 854/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.8121 - val_loss: 0.4945 - val_accuracy: 0.8166\n",
      "Epoch 855/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.8188 - val_loss: 0.5163 - val_accuracy: 0.7990\n",
      "Epoch 856/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.8188 - val_loss: 0.5061 - val_accuracy: 0.8040\n",
      "Epoch 857/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.8096 - val_loss: 0.4928 - val_accuracy: 0.8191\n",
      "Epoch 858/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8163 - val_loss: 0.4929 - val_accuracy: 0.8065\n",
      "Epoch 859/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8180 - val_loss: 0.4929 - val_accuracy: 0.8116\n",
      "Epoch 860/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8221 - val_loss: 0.4935 - val_accuracy: 0.8090\n",
      "Epoch 861/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8163 - val_loss: 0.4917 - val_accuracy: 0.8040\n",
      "Epoch 862/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8196 - val_loss: 0.4931 - val_accuracy: 0.8116\n",
      "Epoch 863/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8154 - val_loss: 0.5147 - val_accuracy: 0.7990\n",
      "Epoch 864/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8163 - val_loss: 0.4977 - val_accuracy: 0.8166\n",
      "Epoch 865/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.8163 - val_loss: 0.4931 - val_accuracy: 0.8090\n",
      "Epoch 866/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8154 - val_loss: 0.4925 - val_accuracy: 0.8040\n",
      "Epoch 867/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8154 - val_loss: 0.4954 - val_accuracy: 0.8090\n",
      "Epoch 868/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8154 - val_loss: 0.4941 - val_accuracy: 0.8040\n",
      "Epoch 869/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.8205 - val_loss: 0.4958 - val_accuracy: 0.8090\n",
      "Epoch 870/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8163 - val_loss: 0.4941 - val_accuracy: 0.8141\n",
      "Epoch 871/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8188 - val_loss: 0.5018 - val_accuracy: 0.8116\n",
      "Epoch 872/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8096 - val_loss: 0.4967 - val_accuracy: 0.8191\n",
      "Epoch 873/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.8163 - val_loss: 0.4953 - val_accuracy: 0.8141\n",
      "Epoch 874/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.8171 - val_loss: 0.4948 - val_accuracy: 0.8090\n",
      "Epoch 875/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.8121 - val_loss: 0.4990 - val_accuracy: 0.8090\n",
      "Epoch 876/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8138 - val_loss: 0.4971 - val_accuracy: 0.8090\n",
      "Epoch 877/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.8180 - val_loss: 0.4969 - val_accuracy: 0.8191\n",
      "Epoch 878/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.8129 - val_loss: 0.4990 - val_accuracy: 0.8040\n",
      "Epoch 879/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8154 - val_loss: 0.4941 - val_accuracy: 0.8040\n",
      "Epoch 880/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.8163 - val_loss: 0.4942 - val_accuracy: 0.8015\n",
      "Epoch 881/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8163 - val_loss: 0.4919 - val_accuracy: 0.8065\n",
      "Epoch 882/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.8138 - val_loss: 0.5009 - val_accuracy: 0.8065\n",
      "Epoch 883/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.8196 - val_loss: 0.4967 - val_accuracy: 0.8166\n",
      "Epoch 884/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.8146 - val_loss: 0.4997 - val_accuracy: 0.8166\n",
      "Epoch 885/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8221 - val_loss: 0.4991 - val_accuracy: 0.8191\n",
      "Epoch 886/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8213 - val_loss: 0.4936 - val_accuracy: 0.8116\n",
      "Epoch 887/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.8121 - val_loss: 0.4958 - val_accuracy: 0.8141\n",
      "Epoch 888/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.8221 - val_loss: 0.4980 - val_accuracy: 0.8141\n",
      "Epoch 889/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8188 - val_loss: 0.5014 - val_accuracy: 0.8065\n",
      "Epoch 890/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8180 - val_loss: 0.5033 - val_accuracy: 0.8040\n",
      "Epoch 891/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.8188 - val_loss: 0.5019 - val_accuracy: 0.8116\n",
      "Epoch 892/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8121 - val_loss: 0.4941 - val_accuracy: 0.8065\n",
      "Epoch 893/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8188 - val_loss: 0.4996 - val_accuracy: 0.8166\n",
      "Epoch 894/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.8129 - val_loss: 0.4939 - val_accuracy: 0.8216\n",
      "Epoch 895/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.8180 - val_loss: 0.4986 - val_accuracy: 0.8191\n",
      "Epoch 896/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8196 - val_loss: 0.4968 - val_accuracy: 0.8090\n",
      "Epoch 897/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.8221 - val_loss: 0.4968 - val_accuracy: 0.8166\n",
      "Epoch 898/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8138 - val_loss: 0.4967 - val_accuracy: 0.8191\n",
      "Epoch 899/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.8171 - val_loss: 0.5106 - val_accuracy: 0.8116\n",
      "Epoch 900/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.8171 - val_loss: 0.4983 - val_accuracy: 0.8216\n",
      "Epoch 901/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8196 - val_loss: 0.4984 - val_accuracy: 0.8141\n",
      "Epoch 902/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8146 - val_loss: 0.5086 - val_accuracy: 0.8065\n",
      "Epoch 903/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8230 - val_loss: 0.5014 - val_accuracy: 0.8065\n",
      "Epoch 904/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8205 - val_loss: 0.4946 - val_accuracy: 0.8040\n",
      "Epoch 905/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8196 - val_loss: 0.4978 - val_accuracy: 0.8191\n",
      "Epoch 906/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.8154 - val_loss: 0.5314 - val_accuracy: 0.7990\n",
      "Epoch 907/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8104 - val_loss: 0.5046 - val_accuracy: 0.8090\n",
      "Epoch 908/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.8171 - val_loss: 0.5062 - val_accuracy: 0.8065\n",
      "Epoch 909/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.8129 - val_loss: 0.4944 - val_accuracy: 0.8090\n",
      "Epoch 910/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8087 - val_loss: 0.5054 - val_accuracy: 0.8116\n",
      "Epoch 911/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8188 - val_loss: 0.5004 - val_accuracy: 0.8166\n",
      "Epoch 912/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.8221 - val_loss: 0.5016 - val_accuracy: 0.8116\n",
      "Epoch 913/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.8230 - val_loss: 0.4952 - val_accuracy: 0.8116\n",
      "Epoch 914/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.8138 - val_loss: 0.5082 - val_accuracy: 0.8065\n",
      "Epoch 915/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.8121 - val_loss: 0.4937 - val_accuracy: 0.8040\n",
      "Epoch 916/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.8205 - val_loss: 0.4989 - val_accuracy: 0.8216\n",
      "Epoch 917/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.8188 - val_loss: 0.4986 - val_accuracy: 0.8090\n",
      "Epoch 918/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.8188 - val_loss: 0.4961 - val_accuracy: 0.8141\n",
      "Epoch 919/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8180 - val_loss: 0.5138 - val_accuracy: 0.8040\n",
      "Epoch 920/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.8188 - val_loss: 0.5036 - val_accuracy: 0.8090\n",
      "Epoch 921/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.8163 - val_loss: 0.4976 - val_accuracy: 0.8166\n",
      "Epoch 922/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.8146 - val_loss: 0.5016 - val_accuracy: 0.8166\n",
      "Epoch 923/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.8180 - val_loss: 0.5038 - val_accuracy: 0.8141\n",
      "Epoch 924/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.8205 - val_loss: 0.5108 - val_accuracy: 0.8090\n",
      "Epoch 925/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.8196 - val_loss: 0.4984 - val_accuracy: 0.8166\n",
      "Epoch 926/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8247 - val_loss: 0.5057 - val_accuracy: 0.8116\n",
      "Epoch 927/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.8188 - val_loss: 0.5039 - val_accuracy: 0.8141\n",
      "Epoch 928/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8146 - val_loss: 0.5013 - val_accuracy: 0.8090\n",
      "Epoch 929/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8247 - val_loss: 0.5097 - val_accuracy: 0.8065\n",
      "Epoch 930/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.8213 - val_loss: 0.4977 - val_accuracy: 0.8141\n",
      "Epoch 931/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8171 - val_loss: 0.5053 - val_accuracy: 0.8191\n",
      "Epoch 932/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8205 - val_loss: 0.4974 - val_accuracy: 0.8141\n",
      "Epoch 933/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8213 - val_loss: 0.5003 - val_accuracy: 0.8241\n",
      "Epoch 934/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8247 - val_loss: 0.4989 - val_accuracy: 0.8065\n",
      "Epoch 935/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8221 - val_loss: 0.5122 - val_accuracy: 0.8040\n",
      "Epoch 936/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.8180 - val_loss: 0.4970 - val_accuracy: 0.8040\n",
      "Epoch 937/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8163 - val_loss: 0.4969 - val_accuracy: 0.8116\n",
      "Epoch 938/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.8196 - val_loss: 0.4974 - val_accuracy: 0.8116\n",
      "Epoch 939/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8180 - val_loss: 0.5140 - val_accuracy: 0.8065\n",
      "Epoch 940/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.8213 - val_loss: 0.4992 - val_accuracy: 0.8141\n",
      "Epoch 941/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.8171 - val_loss: 0.5102 - val_accuracy: 0.8065\n",
      "Epoch 942/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.8180 - val_loss: 0.5031 - val_accuracy: 0.8191\n",
      "Epoch 943/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8188 - val_loss: 0.4982 - val_accuracy: 0.8141\n",
      "Epoch 944/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8087 - val_loss: 0.4976 - val_accuracy: 0.8090\n",
      "Epoch 945/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8221 - val_loss: 0.4985 - val_accuracy: 0.8090\n",
      "Epoch 946/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.8163 - val_loss: 0.5012 - val_accuracy: 0.8116\n",
      "Epoch 947/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8205 - val_loss: 0.5147 - val_accuracy: 0.8040\n",
      "Epoch 948/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.8171 - val_loss: 0.5028 - val_accuracy: 0.8116\n",
      "Epoch 949/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8163 - val_loss: 0.5059 - val_accuracy: 0.8166\n",
      "Epoch 950/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8196 - val_loss: 0.4995 - val_accuracy: 0.8141\n",
      "Epoch 951/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.8213 - val_loss: 0.5004 - val_accuracy: 0.8141\n",
      "Epoch 952/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8213 - val_loss: 0.4963 - val_accuracy: 0.8116\n",
      "Epoch 953/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8213 - val_loss: 0.5026 - val_accuracy: 0.8216\n",
      "Epoch 954/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8188 - val_loss: 0.4979 - val_accuracy: 0.8090\n",
      "Epoch 955/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8213 - val_loss: 0.5187 - val_accuracy: 0.8065\n",
      "Epoch 956/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8087 - val_loss: 0.4976 - val_accuracy: 0.8090\n",
      "Epoch 957/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8255 - val_loss: 0.5009 - val_accuracy: 0.8216\n",
      "Epoch 958/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8247 - val_loss: 0.5040 - val_accuracy: 0.8116\n",
      "Epoch 959/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8188 - val_loss: 0.5007 - val_accuracy: 0.8040\n",
      "Epoch 960/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8255 - val_loss: 0.4975 - val_accuracy: 0.8166\n",
      "Epoch 961/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.8221 - val_loss: 0.5001 - val_accuracy: 0.8116\n",
      "Epoch 962/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8263 - val_loss: 0.4968 - val_accuracy: 0.8065\n",
      "Epoch 963/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8263 - val_loss: 0.5088 - val_accuracy: 0.8090\n",
      "Epoch 964/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8171 - val_loss: 0.5020 - val_accuracy: 0.8191\n",
      "Epoch 965/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.8238 - val_loss: 0.4988 - val_accuracy: 0.8065\n",
      "Epoch 966/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8221 - val_loss: 0.5025 - val_accuracy: 0.8191\n",
      "Epoch 967/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.8213 - val_loss: 0.5020 - val_accuracy: 0.8166\n",
      "Epoch 968/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.8238 - val_loss: 0.5044 - val_accuracy: 0.8166\n",
      "Epoch 969/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8171 - val_loss: 0.4968 - val_accuracy: 0.8065\n",
      "Epoch 970/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8247 - val_loss: 0.5238 - val_accuracy: 0.7990\n",
      "Epoch 971/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.8188 - val_loss: 0.4989 - val_accuracy: 0.8141\n",
      "Epoch 972/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8205 - val_loss: 0.4997 - val_accuracy: 0.8116\n",
      "Epoch 973/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8230 - val_loss: 0.5238 - val_accuracy: 0.7739\n",
      "Epoch 974/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8171 - val_loss: 0.5031 - val_accuracy: 0.8116\n",
      "Epoch 975/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.8171 - val_loss: 0.5050 - val_accuracy: 0.8216\n",
      "Epoch 976/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.8138 - val_loss: 0.5002 - val_accuracy: 0.8166\n",
      "Epoch 977/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8205 - val_loss: 0.5005 - val_accuracy: 0.8141\n",
      "Epoch 978/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.8221 - val_loss: 0.5018 - val_accuracy: 0.8191\n",
      "Epoch 979/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8196 - val_loss: 0.5032 - val_accuracy: 0.8141\n",
      "Epoch 980/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8230 - val_loss: 0.5005 - val_accuracy: 0.8141\n",
      "Epoch 981/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8154 - val_loss: 0.5173 - val_accuracy: 0.8065\n",
      "Epoch 982/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8196 - val_loss: 0.5096 - val_accuracy: 0.8090\n",
      "Epoch 983/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8221 - val_loss: 0.5110 - val_accuracy: 0.8040\n",
      "Epoch 984/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8221 - val_loss: 0.5006 - val_accuracy: 0.8116\n",
      "Epoch 985/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8263 - val_loss: 0.5117 - val_accuracy: 0.8141\n",
      "Epoch 986/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.8263 - val_loss: 0.5013 - val_accuracy: 0.8116\n",
      "Epoch 987/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8205 - val_loss: 0.5005 - val_accuracy: 0.8065\n",
      "Epoch 988/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8255 - val_loss: 0.5060 - val_accuracy: 0.8090\n",
      "Epoch 989/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.8154 - val_loss: 0.5023 - val_accuracy: 0.8141\n",
      "Epoch 990/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8230 - val_loss: 0.5026 - val_accuracy: 0.8216\n",
      "Epoch 991/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.8221 - val_loss: 0.5022 - val_accuracy: 0.8116\n",
      "Epoch 992/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8213 - val_loss: 0.5100 - val_accuracy: 0.8116\n",
      "Epoch 993/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8247 - val_loss: 0.5022 - val_accuracy: 0.8090\n",
      "Epoch 994/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8280 - val_loss: 0.5022 - val_accuracy: 0.8166\n",
      "Epoch 995/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8221 - val_loss: 0.4989 - val_accuracy: 0.8141\n",
      "Epoch 996/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8213 - val_loss: 0.5019 - val_accuracy: 0.8166\n",
      "Epoch 997/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8213 - val_loss: 0.5232 - val_accuracy: 0.7789\n",
      "Epoch 998/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8255 - val_loss: 0.5028 - val_accuracy: 0.8116\n",
      "Epoch 999/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.8196 - val_loss: 0.5487 - val_accuracy: 0.7864\n",
      "Epoch 1000/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8247 - val_loss: 0.5084 - val_accuracy: 0.8090\n"
     ]
    }
   ],
   "source": [
    "history = model_2.fit(X_train,y_train, validation_data=(X_valid, y_valid), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4c55d32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'ro', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "80d521d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.414171427488327, 'accuracy': 0.8246644139289856}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(X_train, y_train, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d5be43ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.8090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5084015130996704, 'accuracy': 0.8090452551841736}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(X_valid, y_valid, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6c0f1d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model Three\n",
    "\n",
    "[SGD](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)\n",
    "\n",
    "[Binary Cross entropy](https://www.analyticsvidhya.com/blog/2021/03/binary-cross-entropy-log-loss-for-binary-classification/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0001573e",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 12)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 512)               6656      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 270,338\n",
      "Trainable params: 270,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(12,)),\n",
    "    tf.keras.layers.Dense(512, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(512, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "])\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f952581e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_3.compile(optimizer='SGD', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "288f0c14",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "38/38 [==============================] - 1s 10ms/step - loss: 0.6487 - accuracy: 0.6518 - val_loss: 0.6615 - val_accuracy: 0.6256\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.6518 - val_loss: 0.6691 - val_accuracy: 0.6256\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.6518 - val_loss: 0.6608 - val_accuracy: 0.6256\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.6518 - val_loss: 0.6807 - val_accuracy: 0.6256\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.6518 - val_loss: 0.6691 - val_accuracy: 0.6256\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.6518 - val_loss: 0.6599 - val_accuracy: 0.6256\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.6518 - val_loss: 0.6651 - val_accuracy: 0.6256\n",
      "Epoch 8/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.6518 - val_loss: 0.6654 - val_accuracy: 0.6256\n",
      "Epoch 9/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.6518 - val_loss: 0.6589 - val_accuracy: 0.6256\n",
      "Epoch 10/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.6518 - val_loss: 0.6829 - val_accuracy: 0.6256\n",
      "Epoch 11/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.6518 - val_loss: 0.6599 - val_accuracy: 0.6256\n",
      "Epoch 12/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.6518 - val_loss: 0.6684 - val_accuracy: 0.6256\n",
      "Epoch 13/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.6518 - val_loss: 0.6797 - val_accuracy: 0.6256\n",
      "Epoch 14/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.6518 - val_loss: 0.6588 - val_accuracy: 0.6256\n",
      "Epoch 15/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.6518 - val_loss: 0.6581 - val_accuracy: 0.6256\n",
      "Epoch 16/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.6518 - val_loss: 0.6584 - val_accuracy: 0.6256\n",
      "Epoch 17/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.6518 - val_loss: 0.6595 - val_accuracy: 0.6256\n",
      "Epoch 18/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.6518 - val_loss: 0.6613 - val_accuracy: 0.6256\n",
      "Epoch 19/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.6518 - val_loss: 0.6674 - val_accuracy: 0.6256\n",
      "Epoch 20/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6446 - accuracy: 0.6518 - val_loss: 0.6614 - val_accuracy: 0.6256\n",
      "Epoch 21/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.6518 - val_loss: 0.6585 - val_accuracy: 0.6256\n",
      "Epoch 22/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.6518 - val_loss: 0.6619 - val_accuracy: 0.6256\n",
      "Epoch 23/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.6518 - val_loss: 0.6580 - val_accuracy: 0.6256\n",
      "Epoch 24/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.6518 - val_loss: 0.6616 - val_accuracy: 0.6256\n",
      "Epoch 25/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.6518 - val_loss: 0.6666 - val_accuracy: 0.6256\n",
      "Epoch 26/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.6518 - val_loss: 0.6575 - val_accuracy: 0.6256\n",
      "Epoch 27/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.6518 - val_loss: 0.6747 - val_accuracy: 0.6256\n",
      "Epoch 28/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.6518 - val_loss: 0.6595 - val_accuracy: 0.6256\n",
      "Epoch 29/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6444 - accuracy: 0.6518 - val_loss: 0.6568 - val_accuracy: 0.6256\n",
      "Epoch 30/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.6518 - val_loss: 0.6608 - val_accuracy: 0.6256\n",
      "Epoch 31/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.6518 - val_loss: 0.6593 - val_accuracy: 0.6256\n",
      "Epoch 32/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6433 - accuracy: 0.6518 - val_loss: 0.6704 - val_accuracy: 0.6256\n",
      "Epoch 33/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.6518 - val_loss: 0.6556 - val_accuracy: 0.6256\n",
      "Epoch 34/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6431 - accuracy: 0.6518 - val_loss: 0.6549 - val_accuracy: 0.6256\n",
      "Epoch 35/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6518 - val_loss: 0.6565 - val_accuracy: 0.6256\n",
      "Epoch 36/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.6518 - val_loss: 0.6550 - val_accuracy: 0.6256\n",
      "Epoch 37/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6433 - accuracy: 0.6518 - val_loss: 0.6562 - val_accuracy: 0.6256\n",
      "Epoch 38/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.6518 - val_loss: 0.6544 - val_accuracy: 0.6256\n",
      "Epoch 39/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6518 - val_loss: 0.6546 - val_accuracy: 0.6256\n",
      "Epoch 40/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6518 - val_loss: 0.6539 - val_accuracy: 0.6256\n",
      "Epoch 41/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.6518 - val_loss: 0.6549 - val_accuracy: 0.6256\n",
      "Epoch 42/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.6518 - val_loss: 0.6537 - val_accuracy: 0.6256\n",
      "Epoch 43/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.6518 - val_loss: 0.6532 - val_accuracy: 0.6256\n",
      "Epoch 44/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.6518 - val_loss: 0.6530 - val_accuracy: 0.6256\n",
      "Epoch 45/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.6518 - val_loss: 0.6559 - val_accuracy: 0.6256\n",
      "Epoch 46/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.6518 - val_loss: 0.6533 - val_accuracy: 0.6256\n",
      "Epoch 47/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.6518 - val_loss: 0.6538 - val_accuracy: 0.6256\n",
      "Epoch 48/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.6518 - val_loss: 0.6564 - val_accuracy: 0.6256\n",
      "Epoch 49/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6518 - val_loss: 0.6612 - val_accuracy: 0.6256\n",
      "Epoch 50/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6518 - val_loss: 0.6518 - val_accuracy: 0.6256\n",
      "Epoch 51/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.6518 - val_loss: 0.6595 - val_accuracy: 0.6256\n",
      "Epoch 52/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.6518 - val_loss: 0.6569 - val_accuracy: 0.6256\n",
      "Epoch 53/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.6518 - val_loss: 0.6535 - val_accuracy: 0.6256\n",
      "Epoch 54/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.6518 - val_loss: 0.6564 - val_accuracy: 0.6256\n",
      "Epoch 55/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.6518 - val_loss: 0.6577 - val_accuracy: 0.6256\n",
      "Epoch 56/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.6518 - val_loss: 0.6540 - val_accuracy: 0.6256\n",
      "Epoch 57/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6518 - val_loss: 0.6688 - val_accuracy: 0.6256\n",
      "Epoch 58/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.6518 - val_loss: 0.6546 - val_accuracy: 0.6256\n",
      "Epoch 59/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.6518 - val_loss: 0.6524 - val_accuracy: 0.6256\n",
      "Epoch 60/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.6518 - val_loss: 0.6608 - val_accuracy: 0.6256\n",
      "Epoch 61/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.6518 - val_loss: 0.6496 - val_accuracy: 0.6256\n",
      "Epoch 62/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.6518 - val_loss: 0.6516 - val_accuracy: 0.6256\n",
      "Epoch 63/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.6518 - val_loss: 0.6577 - val_accuracy: 0.6256\n",
      "Epoch 64/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.6518 - val_loss: 0.6508 - val_accuracy: 0.6256\n",
      "Epoch 65/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.6518 - val_loss: 0.6488 - val_accuracy: 0.6256\n",
      "Epoch 66/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.6518 - val_loss: 0.6571 - val_accuracy: 0.6256\n",
      "Epoch 67/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.6518 - val_loss: 0.6488 - val_accuracy: 0.6256\n",
      "Epoch 68/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.6518 - val_loss: 0.6545 - val_accuracy: 0.6256\n",
      "Epoch 69/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.6518 - val_loss: 0.6630 - val_accuracy: 0.6256\n",
      "Epoch 70/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.6518 - val_loss: 0.6487 - val_accuracy: 0.6256\n",
      "Epoch 71/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.6518 - val_loss: 0.6588 - val_accuracy: 0.6256\n",
      "Epoch 72/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.6518 - val_loss: 0.6515 - val_accuracy: 0.6256\n",
      "Epoch 73/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.6518 - val_loss: 0.6499 - val_accuracy: 0.6256\n",
      "Epoch 74/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.6518 - val_loss: 0.6527 - val_accuracy: 0.6256\n",
      "Epoch 75/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.6518 - val_loss: 0.6467 - val_accuracy: 0.6256\n",
      "Epoch 76/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.6518 - val_loss: 0.6501 - val_accuracy: 0.6256\n",
      "Epoch 77/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.6518 - val_loss: 0.6455 - val_accuracy: 0.6256\n",
      "Epoch 78/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.6518 - val_loss: 0.6450 - val_accuracy: 0.6256\n",
      "Epoch 79/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.6518 - val_loss: 0.6461 - val_accuracy: 0.6256\n",
      "Epoch 80/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.6518 - val_loss: 0.6519 - val_accuracy: 0.6256\n",
      "Epoch 81/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.6518 - val_loss: 0.6444 - val_accuracy: 0.6256\n",
      "Epoch 82/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6518 - val_loss: 0.6443 - val_accuracy: 0.6256\n",
      "Epoch 83/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.6518 - val_loss: 0.6497 - val_accuracy: 0.6256\n",
      "Epoch 84/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.6518 - val_loss: 0.6449 - val_accuracy: 0.6256\n",
      "Epoch 85/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.6518 - val_loss: 0.6445 - val_accuracy: 0.6256\n",
      "Epoch 86/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.6518 - val_loss: 0.6472 - val_accuracy: 0.6256\n",
      "Epoch 87/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6293 - accuracy: 0.6518 - val_loss: 0.6506 - val_accuracy: 0.6256\n",
      "Epoch 88/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.6518 - val_loss: 0.6485 - val_accuracy: 0.6256\n",
      "Epoch 89/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.6518 - val_loss: 0.6415 - val_accuracy: 0.6256\n",
      "Epoch 90/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6304 - accuracy: 0.6518 - val_loss: 0.6435 - val_accuracy: 0.6256\n",
      "Epoch 91/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6294 - accuracy: 0.6518 - val_loss: 0.6496 - val_accuracy: 0.6256\n",
      "Epoch 92/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.6518 - val_loss: 0.6406 - val_accuracy: 0.6256\n",
      "Epoch 93/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.6518 - val_loss: 0.6463 - val_accuracy: 0.6256\n",
      "Epoch 94/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6300 - accuracy: 0.6518 - val_loss: 0.6535 - val_accuracy: 0.6256\n",
      "Epoch 95/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.6518 - val_loss: 0.6394 - val_accuracy: 0.6256\n",
      "Epoch 96/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.6518 - val_loss: 0.6396 - val_accuracy: 0.6256\n",
      "Epoch 97/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.6518 - val_loss: 0.6435 - val_accuracy: 0.6256\n",
      "Epoch 98/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.6518 - val_loss: 0.6490 - val_accuracy: 0.6256\n",
      "Epoch 99/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.6518 - val_loss: 0.6435 - val_accuracy: 0.6256\n",
      "Epoch 100/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6252 - accuracy: 0.6518 - val_loss: 0.6386 - val_accuracy: 0.6256\n",
      "Epoch 101/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.6518 - val_loss: 0.6451 - val_accuracy: 0.6256\n",
      "Epoch 102/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.6518 - val_loss: 0.6389 - val_accuracy: 0.6256\n",
      "Epoch 103/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.6518 - val_loss: 0.6363 - val_accuracy: 0.6256\n",
      "Epoch 104/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.6518 - val_loss: 0.6372 - val_accuracy: 0.6256\n",
      "Epoch 105/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.6518 - val_loss: 0.6473 - val_accuracy: 0.6256\n",
      "Epoch 106/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.6518 - val_loss: 0.6362 - val_accuracy: 0.6256\n",
      "Epoch 107/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.6518 - val_loss: 0.6352 - val_accuracy: 0.6256\n",
      "Epoch 108/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.6518 - val_loss: 0.6426 - val_accuracy: 0.6256\n",
      "Epoch 109/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6217 - accuracy: 0.6518 - val_loss: 0.6532 - val_accuracy: 0.6256\n",
      "Epoch 110/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.6518 - val_loss: 0.6339 - val_accuracy: 0.6256\n",
      "Epoch 111/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6224 - accuracy: 0.6518 - val_loss: 0.6397 - val_accuracy: 0.6256\n",
      "Epoch 112/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.6518 - val_loss: 0.6368 - val_accuracy: 0.6256\n",
      "Epoch 113/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6212 - accuracy: 0.6518 - val_loss: 0.6322 - val_accuracy: 0.6256\n",
      "Epoch 114/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6216 - accuracy: 0.6518 - val_loss: 0.6331 - val_accuracy: 0.6256\n",
      "Epoch 115/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6518 - val_loss: 0.6317 - val_accuracy: 0.6256\n",
      "Epoch 116/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.6518 - val_loss: 0.6318 - val_accuracy: 0.6256\n",
      "Epoch 117/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.6518 - val_loss: 0.6365 - val_accuracy: 0.6256\n",
      "Epoch 118/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.6518 - val_loss: 0.6312 - val_accuracy: 0.6256\n",
      "Epoch 119/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.6518 - val_loss: 0.6292 - val_accuracy: 0.6256\n",
      "Epoch 120/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.6518 - val_loss: 0.6315 - val_accuracy: 0.6256\n",
      "Epoch 121/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6164 - accuracy: 0.6527 - val_loss: 0.6319 - val_accuracy: 0.6256\n",
      "Epoch 122/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.6518 - val_loss: 0.6282 - val_accuracy: 0.6256\n",
      "Epoch 123/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.6518 - val_loss: 0.6269 - val_accuracy: 0.6256\n",
      "Epoch 124/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.6518 - val_loss: 0.6273 - val_accuracy: 0.6256\n",
      "Epoch 125/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.6518 - val_loss: 0.6280 - val_accuracy: 0.6256\n",
      "Epoch 126/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.6518 - val_loss: 0.6254 - val_accuracy: 0.6256\n",
      "Epoch 127/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.6518 - val_loss: 0.6382 - val_accuracy: 0.6256\n",
      "Epoch 128/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.6518 - val_loss: 0.6381 - val_accuracy: 0.6256\n",
      "Epoch 129/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.6518 - val_loss: 0.6237 - val_accuracy: 0.6256\n",
      "Epoch 130/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.6535 - val_loss: 0.6289 - val_accuracy: 0.6256\n",
      "Epoch 131/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.6518 - val_loss: 0.6283 - val_accuracy: 0.6256\n",
      "Epoch 132/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.6518 - val_loss: 0.6219 - val_accuracy: 0.6256\n",
      "Epoch 133/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.6518 - val_loss: 0.6216 - val_accuracy: 0.6256\n",
      "Epoch 134/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.6518 - val_loss: 0.6214 - val_accuracy: 0.6256\n",
      "Epoch 135/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.6518 - val_loss: 0.6200 - val_accuracy: 0.6256\n",
      "Epoch 136/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.6518 - val_loss: 0.6416 - val_accuracy: 0.6256\n",
      "Epoch 137/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.6518 - val_loss: 0.6190 - val_accuracy: 0.6307\n",
      "Epoch 138/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.6577 - val_loss: 0.6197 - val_accuracy: 0.6583\n",
      "Epoch 139/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6552 - val_loss: 0.6259 - val_accuracy: 0.6256\n",
      "Epoch 140/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6061 - accuracy: 0.6560 - val_loss: 0.6306 - val_accuracy: 0.6256\n",
      "Epoch 141/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.6535 - val_loss: 0.6163 - val_accuracy: 0.6256\n",
      "Epoch 142/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.6535 - val_loss: 0.6305 - val_accuracy: 0.6256\n",
      "Epoch 143/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.6544 - val_loss: 0.6151 - val_accuracy: 0.6357\n",
      "Epoch 144/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6044 - accuracy: 0.6569 - val_loss: 0.6225 - val_accuracy: 0.6256\n",
      "Epoch 145/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.6518 - val_loss: 0.6171 - val_accuracy: 0.6256\n",
      "Epoch 146/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6044 - accuracy: 0.6527 - val_loss: 0.6332 - val_accuracy: 0.6256\n",
      "Epoch 147/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6034 - accuracy: 0.6577 - val_loss: 0.6127 - val_accuracy: 0.6281\n",
      "Epoch 148/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6024 - accuracy: 0.6569 - val_loss: 0.6169 - val_accuracy: 0.6256\n",
      "Epoch 149/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6018 - accuracy: 0.6527 - val_loss: 0.6289 - val_accuracy: 0.6256\n",
      "Epoch 150/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.6569 - val_loss: 0.6149 - val_accuracy: 0.6256\n",
      "Epoch 151/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.6594 - val_loss: 0.6118 - val_accuracy: 0.7211\n",
      "Epoch 152/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.6636 - val_loss: 0.6130 - val_accuracy: 0.7412\n",
      "Epoch 153/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5988 - accuracy: 0.6720 - val_loss: 0.6081 - val_accuracy: 0.6633\n",
      "Epoch 154/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.6678 - val_loss: 0.6108 - val_accuracy: 0.6256\n",
      "Epoch 155/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.6611 - val_loss: 0.6125 - val_accuracy: 0.6256\n",
      "Epoch 156/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.6644 - val_loss: 0.6076 - val_accuracy: 0.6307\n",
      "Epoch 157/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.6686 - val_loss: 0.6217 - val_accuracy: 0.6256\n",
      "Epoch 158/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.6594 - val_loss: 0.6072 - val_accuracy: 0.6307\n",
      "Epoch 159/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.6686 - val_loss: 0.6041 - val_accuracy: 0.6558\n",
      "Epoch 160/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.6711 - val_loss: 0.6113 - val_accuracy: 0.6256\n",
      "Epoch 161/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.6686 - val_loss: 0.6152 - val_accuracy: 0.6256\n",
      "Epoch 162/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.6661 - val_loss: 0.6048 - val_accuracy: 0.6281\n",
      "Epoch 163/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.6720 - val_loss: 0.6158 - val_accuracy: 0.6256\n",
      "Epoch 164/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.6720 - val_loss: 0.6202 - val_accuracy: 0.6256\n",
      "Epoch 165/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.6820 - val_loss: 0.6182 - val_accuracy: 0.6256\n",
      "Epoch 166/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.6804 - val_loss: 0.6049 - val_accuracy: 0.6307\n",
      "Epoch 167/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.6804 - val_loss: 0.6106 - val_accuracy: 0.7513\n",
      "Epoch 168/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.6997 - val_loss: 0.5970 - val_accuracy: 0.6960\n",
      "Epoch 169/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.6888 - val_loss: 0.5965 - val_accuracy: 0.6935\n",
      "Epoch 170/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.6896 - val_loss: 0.5985 - val_accuracy: 0.6558\n",
      "Epoch 171/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.7055 - val_loss: 0.5947 - val_accuracy: 0.6985\n",
      "Epoch 172/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.6913 - val_loss: 0.5941 - val_accuracy: 0.7437\n",
      "Epoch 173/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.6980 - val_loss: 0.5944 - val_accuracy: 0.6759\n",
      "Epoch 174/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.6946 - val_loss: 0.5923 - val_accuracy: 0.7186\n",
      "Epoch 175/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.6971 - val_loss: 0.5929 - val_accuracy: 0.7688\n",
      "Epoch 176/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.7139 - val_loss: 0.5958 - val_accuracy: 0.6633\n",
      "Epoch 177/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7055 - val_loss: 0.5966 - val_accuracy: 0.6558\n",
      "Epoch 178/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.7022 - val_loss: 0.6029 - val_accuracy: 0.7513\n",
      "Epoch 179/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.7198 - val_loss: 0.5905 - val_accuracy: 0.7714\n",
      "Epoch 180/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.7232 - val_loss: 0.5887 - val_accuracy: 0.7714\n",
      "Epoch 181/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.7248 - val_loss: 0.5999 - val_accuracy: 0.6382\n",
      "Epoch 182/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7240 - val_loss: 0.5905 - val_accuracy: 0.6809\n",
      "Epoch 183/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.7282 - val_loss: 0.5857 - val_accuracy: 0.7337\n",
      "Epoch 184/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.7223 - val_loss: 0.5878 - val_accuracy: 0.7714\n",
      "Epoch 185/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.7399 - val_loss: 0.5838 - val_accuracy: 0.7714\n",
      "Epoch 186/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.7265 - val_loss: 0.5903 - val_accuracy: 0.7513\n",
      "Epoch 187/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7458 - val_loss: 0.5946 - val_accuracy: 0.6633\n",
      "Epoch 188/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.7391 - val_loss: 0.5849 - val_accuracy: 0.7085\n",
      "Epoch 189/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.7324 - val_loss: 0.5863 - val_accuracy: 0.6985\n",
      "Epoch 190/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7332 - val_loss: 0.5895 - val_accuracy: 0.6759\n",
      "Epoch 191/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7383 - val_loss: 0.5812 - val_accuracy: 0.7387\n",
      "Epoch 192/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7475 - val_loss: 0.5802 - val_accuracy: 0.7387\n",
      "Epoch 193/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.7366 - val_loss: 0.5806 - val_accuracy: 0.7362\n",
      "Epoch 194/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.7492 - val_loss: 0.5848 - val_accuracy: 0.6985\n",
      "Epoch 195/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.7592 - val_loss: 0.5826 - val_accuracy: 0.7085\n",
      "Epoch 196/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7517 - val_loss: 0.5962 - val_accuracy: 0.6633\n",
      "Epoch 197/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7441 - val_loss: 0.5789 - val_accuracy: 0.7387\n",
      "Epoch 198/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7500 - val_loss: 0.5744 - val_accuracy: 0.7714\n",
      "Epoch 199/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.7534 - val_loss: 0.5795 - val_accuracy: 0.7211\n",
      "Epoch 200/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.7508 - val_loss: 0.5730 - val_accuracy: 0.7714\n",
      "Epoch 201/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.7517 - val_loss: 0.5729 - val_accuracy: 0.7688\n",
      "Epoch 202/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.7567 - val_loss: 0.5797 - val_accuracy: 0.7211\n",
      "Epoch 203/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7475 - val_loss: 0.5734 - val_accuracy: 0.7638\n",
      "Epoch 204/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.7592 - val_loss: 0.5704 - val_accuracy: 0.7663\n",
      "Epoch 205/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.7508 - val_loss: 0.5752 - val_accuracy: 0.7412\n",
      "Epoch 206/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.7727 - val_loss: 0.5823 - val_accuracy: 0.7085\n",
      "Epoch 207/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7651 - val_loss: 0.5932 - val_accuracy: 0.6759\n",
      "Epoch 208/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7634 - val_loss: 0.5954 - val_accuracy: 0.6784\n",
      "Epoch 209/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.7601 - val_loss: 0.5858 - val_accuracy: 0.6985\n",
      "Epoch 210/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7601 - val_loss: 0.5850 - val_accuracy: 0.6985\n",
      "Epoch 211/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5588 - accuracy: 0.7651 - val_loss: 0.5663 - val_accuracy: 0.7663\n",
      "Epoch 212/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7651 - val_loss: 0.5658 - val_accuracy: 0.7739\n",
      "Epoch 213/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7727 - val_loss: 0.5706 - val_accuracy: 0.7563\n",
      "Epoch 214/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7743 - val_loss: 0.5745 - val_accuracy: 0.7387\n",
      "Epoch 215/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7626 - val_loss: 0.5652 - val_accuracy: 0.7714\n",
      "Epoch 216/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.7643 - val_loss: 0.5665 - val_accuracy: 0.7714\n",
      "Epoch 217/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.7768 - val_loss: 0.5642 - val_accuracy: 0.7563\n",
      "Epoch 218/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7685 - val_loss: 0.5655 - val_accuracy: 0.7538\n",
      "Epoch 219/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.7735 - val_loss: 0.5970 - val_accuracy: 0.6508\n",
      "Epoch 220/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7651 - val_loss: 0.5747 - val_accuracy: 0.7387\n",
      "Epoch 221/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.7752 - val_loss: 0.5621 - val_accuracy: 0.7663\n",
      "Epoch 222/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.7752 - val_loss: 0.5649 - val_accuracy: 0.7563\n",
      "Epoch 223/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5486 - accuracy: 0.7727 - val_loss: 0.6450 - val_accuracy: 0.6281\n",
      "Epoch 224/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.7592 - val_loss: 0.5682 - val_accuracy: 0.7362\n",
      "Epoch 225/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5486 - accuracy: 0.7634 - val_loss: 0.5665 - val_accuracy: 0.7563\n",
      "Epoch 226/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.7718 - val_loss: 0.5628 - val_accuracy: 0.7563\n",
      "Epoch 227/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7752 - val_loss: 0.5633 - val_accuracy: 0.7714\n",
      "Epoch 228/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7785 - val_loss: 0.5638 - val_accuracy: 0.7739\n",
      "Epoch 229/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7768 - val_loss: 0.5768 - val_accuracy: 0.7387\n",
      "Epoch 230/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.7743 - val_loss: 0.5877 - val_accuracy: 0.7161\n",
      "Epoch 231/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.7777 - val_loss: 0.5567 - val_accuracy: 0.7714\n",
      "Epoch 232/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7727 - val_loss: 0.5665 - val_accuracy: 0.7714\n",
      "Epoch 233/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7743 - val_loss: 0.5589 - val_accuracy: 0.7663\n",
      "Epoch 234/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7768 - val_loss: 0.5785 - val_accuracy: 0.7362\n",
      "Epoch 235/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5477 - accuracy: 0.7760 - val_loss: 0.5563 - val_accuracy: 0.7663\n",
      "Epoch 236/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7794 - val_loss: 0.5619 - val_accuracy: 0.7714\n",
      "Epoch 237/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.7718 - val_loss: 0.5656 - val_accuracy: 0.7714\n",
      "Epoch 238/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7760 - val_loss: 0.5579 - val_accuracy: 0.7663\n",
      "Epoch 239/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7760 - val_loss: 0.5578 - val_accuracy: 0.7663\n",
      "Epoch 240/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7743 - val_loss: 0.5568 - val_accuracy: 0.7563\n",
      "Epoch 241/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7735 - val_loss: 0.5543 - val_accuracy: 0.7588\n",
      "Epoch 242/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.7743 - val_loss: 0.5557 - val_accuracy: 0.7638\n",
      "Epoch 243/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7735 - val_loss: 0.5692 - val_accuracy: 0.7714\n",
      "Epoch 244/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.7794 - val_loss: 0.5528 - val_accuracy: 0.7613\n",
      "Epoch 245/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7735 - val_loss: 0.5699 - val_accuracy: 0.7714\n",
      "Epoch 246/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7760 - val_loss: 0.5558 - val_accuracy: 0.7638\n",
      "Epoch 247/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7727 - val_loss: 0.5679 - val_accuracy: 0.7688\n",
      "Epoch 248/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.7743 - val_loss: 0.5577 - val_accuracy: 0.7663\n",
      "Epoch 249/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7727 - val_loss: 0.5599 - val_accuracy: 0.7714\n",
      "Epoch 250/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7727 - val_loss: 0.5826 - val_accuracy: 0.7462\n",
      "Epoch 251/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.7727 - val_loss: 0.5542 - val_accuracy: 0.7663\n",
      "Epoch 252/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7760 - val_loss: 0.5534 - val_accuracy: 0.7663\n",
      "Epoch 253/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7735 - val_loss: 0.5534 - val_accuracy: 0.7663\n",
      "Epoch 254/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7760 - val_loss: 0.5520 - val_accuracy: 0.7563\n",
      "Epoch 255/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7710 - val_loss: 0.5553 - val_accuracy: 0.7462\n",
      "Epoch 256/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7727 - val_loss: 0.5570 - val_accuracy: 0.7663\n",
      "Epoch 257/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.7768 - val_loss: 0.5732 - val_accuracy: 0.7714\n",
      "Epoch 258/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7668 - val_loss: 0.5491 - val_accuracy: 0.7613\n",
      "Epoch 259/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7743 - val_loss: 0.5491 - val_accuracy: 0.7638\n",
      "Epoch 260/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7727 - val_loss: 0.5494 - val_accuracy: 0.7563\n",
      "Epoch 261/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7685 - val_loss: 0.5838 - val_accuracy: 0.7538\n",
      "Epoch 262/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7743 - val_loss: 0.5565 - val_accuracy: 0.7663\n",
      "Epoch 263/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.7693 - val_loss: 0.5495 - val_accuracy: 0.7714\n",
      "Epoch 264/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.7727 - val_loss: 0.5518 - val_accuracy: 0.7513\n",
      "Epoch 265/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7701 - val_loss: 0.5525 - val_accuracy: 0.7663\n",
      "Epoch 266/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.7693 - val_loss: 0.5829 - val_accuracy: 0.7613\n",
      "Epoch 267/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7735 - val_loss: 0.5855 - val_accuracy: 0.7563\n",
      "Epoch 268/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7727 - val_loss: 0.5488 - val_accuracy: 0.7714\n",
      "Epoch 269/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.7752 - val_loss: 0.5581 - val_accuracy: 0.7663\n",
      "Epoch 270/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7760 - val_loss: 0.5584 - val_accuracy: 0.7663\n",
      "Epoch 271/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7743 - val_loss: 0.5487 - val_accuracy: 0.7714\n",
      "Epoch 272/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7701 - val_loss: 0.5540 - val_accuracy: 0.7663\n",
      "Epoch 273/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7727 - val_loss: 0.5485 - val_accuracy: 0.7714\n",
      "Epoch 274/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7659 - val_loss: 0.5680 - val_accuracy: 0.7714\n",
      "Epoch 275/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7626 - val_loss: 0.5463 - val_accuracy: 0.7663\n",
      "Epoch 276/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7668 - val_loss: 0.5548 - val_accuracy: 0.7663\n",
      "Epoch 277/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7760 - val_loss: 0.5483 - val_accuracy: 0.7714\n",
      "Epoch 278/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.7752 - val_loss: 0.5460 - val_accuracy: 0.7638\n",
      "Epoch 279/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7634 - val_loss: 0.5469 - val_accuracy: 0.7739\n",
      "Epoch 280/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7735 - val_loss: 0.5668 - val_accuracy: 0.7714\n",
      "Epoch 281/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7760 - val_loss: 0.5635 - val_accuracy: 0.7714\n",
      "Epoch 282/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7768 - val_loss: 0.5555 - val_accuracy: 0.7663\n",
      "Epoch 283/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7584 - val_loss: 0.5618 - val_accuracy: 0.7663\n",
      "Epoch 284/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7718 - val_loss: 0.5457 - val_accuracy: 0.7764\n",
      "Epoch 285/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7668 - val_loss: 0.5454 - val_accuracy: 0.7663\n",
      "Epoch 286/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7668 - val_loss: 0.5580 - val_accuracy: 0.7638\n",
      "Epoch 287/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7785 - val_loss: 0.5449 - val_accuracy: 0.7663\n",
      "Epoch 288/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7626 - val_loss: 0.5496 - val_accuracy: 0.7613\n",
      "Epoch 289/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7743 - val_loss: 0.5461 - val_accuracy: 0.7588\n",
      "Epoch 290/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7760 - val_loss: 0.5478 - val_accuracy: 0.7513\n",
      "Epoch 291/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7718 - val_loss: 0.5472 - val_accuracy: 0.7714\n",
      "Epoch 292/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7794 - val_loss: 0.5639 - val_accuracy: 0.6784\n",
      "Epoch 293/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7659 - val_loss: 0.5839 - val_accuracy: 0.7739\n",
      "Epoch 294/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7768 - val_loss: 0.5444 - val_accuracy: 0.7714\n",
      "Epoch 295/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7743 - val_loss: 0.5647 - val_accuracy: 0.6734\n",
      "Epoch 296/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7752 - val_loss: 0.5595 - val_accuracy: 0.6859\n",
      "Epoch 297/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7727 - val_loss: 0.5441 - val_accuracy: 0.7688\n",
      "Epoch 298/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7701 - val_loss: 0.5536 - val_accuracy: 0.7111\n",
      "Epoch 299/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7668 - val_loss: 0.5484 - val_accuracy: 0.7613\n",
      "Epoch 300/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7685 - val_loss: 0.5627 - val_accuracy: 0.7663\n",
      "Epoch 301/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7727 - val_loss: 0.5671 - val_accuracy: 0.7714\n",
      "Epoch 302/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7710 - val_loss: 0.5441 - val_accuracy: 0.7814\n",
      "Epoch 303/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7659 - val_loss: 0.5448 - val_accuracy: 0.7764\n",
      "Epoch 304/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7752 - val_loss: 0.5673 - val_accuracy: 0.7714\n",
      "Epoch 305/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.7693 - val_loss: 0.5530 - val_accuracy: 0.7638\n",
      "Epoch 306/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7701 - val_loss: 0.5433 - val_accuracy: 0.7663\n",
      "Epoch 307/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.7752 - val_loss: 0.5564 - val_accuracy: 0.7663\n",
      "Epoch 308/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7743 - val_loss: 0.5467 - val_accuracy: 0.7638\n",
      "Epoch 309/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7668 - val_loss: 0.5985 - val_accuracy: 0.6382\n",
      "Epoch 310/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7626 - val_loss: 0.5429 - val_accuracy: 0.7688\n",
      "Epoch 311/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7752 - val_loss: 0.5494 - val_accuracy: 0.7613\n",
      "Epoch 312/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7701 - val_loss: 0.5535 - val_accuracy: 0.7638\n",
      "Epoch 313/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7701 - val_loss: 0.5563 - val_accuracy: 0.7663\n",
      "Epoch 314/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7685 - val_loss: 0.5491 - val_accuracy: 0.7613\n",
      "Epoch 315/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7752 - val_loss: 0.5703 - val_accuracy: 0.6558\n",
      "Epoch 316/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7701 - val_loss: 0.5802 - val_accuracy: 0.7764\n",
      "Epoch 317/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7727 - val_loss: 0.5598 - val_accuracy: 0.7663\n",
      "Epoch 318/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7710 - val_loss: 0.5846 - val_accuracy: 0.7714\n",
      "Epoch 319/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7819 - val_loss: 0.5435 - val_accuracy: 0.7764\n",
      "Epoch 320/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7743 - val_loss: 0.5452 - val_accuracy: 0.7739\n",
      "Epoch 321/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7743 - val_loss: 0.5431 - val_accuracy: 0.7764\n",
      "Epoch 322/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7727 - val_loss: 0.5557 - val_accuracy: 0.7663\n",
      "Epoch 323/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7735 - val_loss: 0.5446 - val_accuracy: 0.7739\n",
      "Epoch 324/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7693 - val_loss: 0.5554 - val_accuracy: 0.7663\n",
      "Epoch 325/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.7693 - val_loss: 0.5423 - val_accuracy: 0.7814\n",
      "Epoch 326/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7701 - val_loss: 0.5519 - val_accuracy: 0.7613\n",
      "Epoch 327/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7659 - val_loss: 0.5631 - val_accuracy: 0.7638\n",
      "Epoch 328/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7760 - val_loss: 0.5458 - val_accuracy: 0.7462\n",
      "Epoch 329/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7676 - val_loss: 0.5422 - val_accuracy: 0.7814\n",
      "Epoch 330/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7752 - val_loss: 0.5429 - val_accuracy: 0.7764\n",
      "Epoch 331/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.7693 - val_loss: 0.5421 - val_accuracy: 0.7814\n",
      "Epoch 332/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7752 - val_loss: 0.5493 - val_accuracy: 0.7613\n",
      "Epoch 333/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7701 - val_loss: 0.5496 - val_accuracy: 0.7613\n",
      "Epoch 334/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7735 - val_loss: 0.5424 - val_accuracy: 0.7563\n",
      "Epoch 335/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7693 - val_loss: 0.5500 - val_accuracy: 0.7613\n",
      "Epoch 336/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7617 - val_loss: 0.5894 - val_accuracy: 0.7688\n",
      "Epoch 337/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7727 - val_loss: 0.5456 - val_accuracy: 0.7663\n",
      "Epoch 338/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.7735 - val_loss: 0.5449 - val_accuracy: 0.7462\n",
      "Epoch 339/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7752 - val_loss: 0.5471 - val_accuracy: 0.7613\n",
      "Epoch 340/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5310 - accuracy: 0.7701 - val_loss: 0.5691 - val_accuracy: 0.7663\n",
      "Epoch 341/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7768 - val_loss: 0.5805 - val_accuracy: 0.7764\n",
      "Epoch 342/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7701 - val_loss: 0.5923 - val_accuracy: 0.7688\n",
      "Epoch 343/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.7735 - val_loss: 0.5417 - val_accuracy: 0.7789\n",
      "Epoch 344/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7693 - val_loss: 0.5794 - val_accuracy: 0.7739\n",
      "Epoch 345/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7760 - val_loss: 0.5418 - val_accuracy: 0.7789\n",
      "Epoch 346/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.7710 - val_loss: 0.5418 - val_accuracy: 0.7789\n",
      "Epoch 347/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7743 - val_loss: 0.5627 - val_accuracy: 0.7663\n",
      "Epoch 348/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7735 - val_loss: 0.5432 - val_accuracy: 0.7739\n",
      "Epoch 349/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7760 - val_loss: 0.5413 - val_accuracy: 0.7789\n",
      "Epoch 350/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.7651 - val_loss: 0.5541 - val_accuracy: 0.7613\n",
      "Epoch 351/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7768 - val_loss: 0.5528 - val_accuracy: 0.7613\n",
      "Epoch 352/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.7752 - val_loss: 0.5422 - val_accuracy: 0.7789\n",
      "Epoch 353/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.7718 - val_loss: 0.5469 - val_accuracy: 0.7638\n",
      "Epoch 354/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7743 - val_loss: 0.5400 - val_accuracy: 0.7714\n",
      "Epoch 355/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7735 - val_loss: 0.5488 - val_accuracy: 0.7337\n",
      "Epoch 356/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7693 - val_loss: 0.5458 - val_accuracy: 0.7638\n",
      "Epoch 357/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7651 - val_loss: 0.5848 - val_accuracy: 0.7764\n",
      "Epoch 358/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7727 - val_loss: 0.5399 - val_accuracy: 0.7814\n",
      "Epoch 359/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7777 - val_loss: 0.5418 - val_accuracy: 0.7563\n",
      "Epoch 360/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7752 - val_loss: 0.5559 - val_accuracy: 0.7638\n",
      "Epoch 361/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.7718 - val_loss: 0.5649 - val_accuracy: 0.7663\n",
      "Epoch 362/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7668 - val_loss: 0.5606 - val_accuracy: 0.7663\n",
      "Epoch 363/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7701 - val_loss: 0.5428 - val_accuracy: 0.7487\n",
      "Epoch 364/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5310 - accuracy: 0.7718 - val_loss: 0.5437 - val_accuracy: 0.7437\n",
      "Epoch 365/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7710 - val_loss: 0.5801 - val_accuracy: 0.7739\n",
      "Epoch 366/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7768 - val_loss: 0.5425 - val_accuracy: 0.7764\n",
      "Epoch 367/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7727 - val_loss: 0.5653 - val_accuracy: 0.7663\n",
      "Epoch 368/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7752 - val_loss: 0.5418 - val_accuracy: 0.7764\n",
      "Epoch 369/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7743 - val_loss: 0.5501 - val_accuracy: 0.7613\n",
      "Epoch 370/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7785 - val_loss: 0.5435 - val_accuracy: 0.7663\n",
      "Epoch 371/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7718 - val_loss: 0.5513 - val_accuracy: 0.7613\n",
      "Epoch 372/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7643 - val_loss: 0.5489 - val_accuracy: 0.7613\n",
      "Epoch 373/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7743 - val_loss: 0.5647 - val_accuracy: 0.7663\n",
      "Epoch 374/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7810 - val_loss: 0.5551 - val_accuracy: 0.7613\n",
      "Epoch 375/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7735 - val_loss: 0.5399 - val_accuracy: 0.7613\n",
      "Epoch 376/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7701 - val_loss: 0.5554 - val_accuracy: 0.7613\n",
      "Epoch 377/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7777 - val_loss: 0.5818 - val_accuracy: 0.7739\n",
      "Epoch 378/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7693 - val_loss: 0.5581 - val_accuracy: 0.7663\n",
      "Epoch 379/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7768 - val_loss: 0.5392 - val_accuracy: 0.7613\n",
      "Epoch 380/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7718 - val_loss: 0.5791 - val_accuracy: 0.6457\n",
      "Epoch 381/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7743 - val_loss: 0.5386 - val_accuracy: 0.7789\n",
      "Epoch 382/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7752 - val_loss: 0.5612 - val_accuracy: 0.7663\n",
      "Epoch 383/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7794 - val_loss: 0.5742 - val_accuracy: 0.7714\n",
      "Epoch 384/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.7710 - val_loss: 0.5874 - val_accuracy: 0.7714\n",
      "Epoch 385/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7768 - val_loss: 0.5661 - val_accuracy: 0.7688\n",
      "Epoch 386/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7685 - val_loss: 0.5516 - val_accuracy: 0.7613\n",
      "Epoch 387/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7710 - val_loss: 0.5443 - val_accuracy: 0.7638\n",
      "Epoch 388/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7718 - val_loss: 0.5514 - val_accuracy: 0.7613\n",
      "Epoch 389/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7777 - val_loss: 0.5752 - val_accuracy: 0.6482\n",
      "Epoch 390/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7701 - val_loss: 0.5786 - val_accuracy: 0.7739\n",
      "Epoch 391/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7752 - val_loss: 0.5542 - val_accuracy: 0.7613\n",
      "Epoch 392/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7718 - val_loss: 0.5524 - val_accuracy: 0.7613\n",
      "Epoch 393/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7785 - val_loss: 0.5438 - val_accuracy: 0.7638\n",
      "Epoch 394/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7718 - val_loss: 0.5486 - val_accuracy: 0.7613\n",
      "Epoch 395/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7718 - val_loss: 0.5576 - val_accuracy: 0.7638\n",
      "Epoch 396/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7693 - val_loss: 0.5382 - val_accuracy: 0.7789\n",
      "Epoch 397/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7760 - val_loss: 0.5383 - val_accuracy: 0.7613\n",
      "Epoch 398/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7718 - val_loss: 0.5496 - val_accuracy: 0.7613\n",
      "Epoch 399/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7718 - val_loss: 0.5536 - val_accuracy: 0.7613\n",
      "Epoch 400/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7743 - val_loss: 0.5433 - val_accuracy: 0.7638\n",
      "Epoch 401/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7735 - val_loss: 0.5470 - val_accuracy: 0.7638\n",
      "Epoch 402/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7727 - val_loss: 0.5711 - val_accuracy: 0.6608\n",
      "Epoch 403/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7651 - val_loss: 0.5451 - val_accuracy: 0.7638\n",
      "Epoch 404/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7777 - val_loss: 0.5433 - val_accuracy: 0.7638\n",
      "Epoch 405/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7836 - val_loss: 0.5387 - val_accuracy: 0.7814\n",
      "Epoch 406/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7718 - val_loss: 0.5379 - val_accuracy: 0.7789\n",
      "Epoch 407/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7777 - val_loss: 0.5479 - val_accuracy: 0.7312\n",
      "Epoch 408/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7676 - val_loss: 0.5607 - val_accuracy: 0.7663\n",
      "Epoch 409/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7752 - val_loss: 0.5373 - val_accuracy: 0.7764\n",
      "Epoch 410/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7794 - val_loss: 0.5411 - val_accuracy: 0.7688\n",
      "Epoch 411/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7685 - val_loss: 0.5373 - val_accuracy: 0.7714\n",
      "Epoch 412/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.7727 - val_loss: 0.5385 - val_accuracy: 0.7613\n",
      "Epoch 413/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7777 - val_loss: 0.5371 - val_accuracy: 0.7764\n",
      "Epoch 414/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7693 - val_loss: 0.5464 - val_accuracy: 0.7638\n",
      "Epoch 415/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7668 - val_loss: 0.5386 - val_accuracy: 0.7814\n",
      "Epoch 416/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7701 - val_loss: 0.5434 - val_accuracy: 0.7663\n",
      "Epoch 417/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7685 - val_loss: 0.5718 - val_accuracy: 0.7688\n",
      "Epoch 418/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7802 - val_loss: 0.5412 - val_accuracy: 0.7663\n",
      "Epoch 419/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7794 - val_loss: 0.5369 - val_accuracy: 0.7764\n",
      "Epoch 420/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7785 - val_loss: 0.5383 - val_accuracy: 0.7814\n",
      "Epoch 421/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7794 - val_loss: 0.5498 - val_accuracy: 0.7638\n",
      "Epoch 422/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7743 - val_loss: 0.5379 - val_accuracy: 0.7588\n",
      "Epoch 423/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7735 - val_loss: 0.5534 - val_accuracy: 0.7613\n",
      "Epoch 424/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7685 - val_loss: 0.5391 - val_accuracy: 0.7588\n",
      "Epoch 425/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7735 - val_loss: 0.5391 - val_accuracy: 0.7588\n",
      "Epoch 426/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.7710 - val_loss: 0.5375 - val_accuracy: 0.7789\n",
      "Epoch 427/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7727 - val_loss: 0.5631 - val_accuracy: 0.7663\n",
      "Epoch 428/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7735 - val_loss: 0.5580 - val_accuracy: 0.6759\n",
      "Epoch 429/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7651 - val_loss: 0.5371 - val_accuracy: 0.7789\n",
      "Epoch 430/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7777 - val_loss: 0.5497 - val_accuracy: 0.7638\n",
      "Epoch 431/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7810 - val_loss: 0.5644 - val_accuracy: 0.7688\n",
      "Epoch 432/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7794 - val_loss: 0.5378 - val_accuracy: 0.7814\n",
      "Epoch 433/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7710 - val_loss: 0.5378 - val_accuracy: 0.7814\n",
      "Epoch 434/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7735 - val_loss: 0.5383 - val_accuracy: 0.7789\n",
      "Epoch 435/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7727 - val_loss: 0.5509 - val_accuracy: 0.7613\n",
      "Epoch 436/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7768 - val_loss: 0.5389 - val_accuracy: 0.7588\n",
      "Epoch 437/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7794 - val_loss: 0.5632 - val_accuracy: 0.7688\n",
      "Epoch 438/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7777 - val_loss: 0.5362 - val_accuracy: 0.7714\n",
      "Epoch 439/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7727 - val_loss: 0.5423 - val_accuracy: 0.7663\n",
      "Epoch 440/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.7768 - val_loss: 0.5362 - val_accuracy: 0.7764\n",
      "Epoch 441/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7752 - val_loss: 0.5382 - val_accuracy: 0.7739\n",
      "Epoch 442/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7752 - val_loss: 0.5493 - val_accuracy: 0.7638\n",
      "Epoch 443/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7727 - val_loss: 0.5362 - val_accuracy: 0.7764\n",
      "Epoch 444/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7760 - val_loss: 0.5469 - val_accuracy: 0.7312\n",
      "Epoch 445/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7710 - val_loss: 0.5444 - val_accuracy: 0.7387\n",
      "Epoch 446/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7743 - val_loss: 0.5359 - val_accuracy: 0.7764\n",
      "Epoch 447/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7752 - val_loss: 0.5441 - val_accuracy: 0.7437\n",
      "Epoch 448/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7685 - val_loss: 0.5358 - val_accuracy: 0.7764\n",
      "Epoch 449/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7626 - val_loss: 0.5390 - val_accuracy: 0.7563\n",
      "Epoch 450/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7718 - val_loss: 0.5574 - val_accuracy: 0.7613\n",
      "Epoch 451/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7802 - val_loss: 0.5356 - val_accuracy: 0.7764\n",
      "Epoch 452/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7802 - val_loss: 0.5395 - val_accuracy: 0.7487\n",
      "Epoch 453/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7701 - val_loss: 0.5357 - val_accuracy: 0.7714\n",
      "Epoch 454/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7718 - val_loss: 0.5361 - val_accuracy: 0.7663\n",
      "Epoch 455/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7752 - val_loss: 0.5370 - val_accuracy: 0.7764\n",
      "Epoch 456/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7693 - val_loss: 0.5798 - val_accuracy: 0.7663\n",
      "Epoch 457/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7701 - val_loss: 0.5370 - val_accuracy: 0.7764\n",
      "Epoch 458/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7768 - val_loss: 0.5488 - val_accuracy: 0.7638\n",
      "Epoch 459/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7735 - val_loss: 0.5534 - val_accuracy: 0.7613\n",
      "Epoch 460/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7743 - val_loss: 0.5545 - val_accuracy: 0.7613\n",
      "Epoch 461/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7743 - val_loss: 0.5400 - val_accuracy: 0.7663\n",
      "Epoch 462/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.7743 - val_loss: 0.5594 - val_accuracy: 0.7638\n",
      "Epoch 463/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7785 - val_loss: 0.5388 - val_accuracy: 0.7688\n",
      "Epoch 464/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7768 - val_loss: 0.5497 - val_accuracy: 0.7638\n",
      "Epoch 465/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7760 - val_loss: 0.5397 - val_accuracy: 0.7663\n",
      "Epoch 466/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7760 - val_loss: 0.5352 - val_accuracy: 0.7739\n",
      "Epoch 467/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7718 - val_loss: 0.5353 - val_accuracy: 0.7764\n",
      "Epoch 468/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7777 - val_loss: 0.5374 - val_accuracy: 0.7588\n",
      "Epoch 469/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7710 - val_loss: 0.5590 - val_accuracy: 0.7638\n",
      "Epoch 470/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7685 - val_loss: 0.5352 - val_accuracy: 0.7764\n",
      "Epoch 471/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7643 - val_loss: 0.5449 - val_accuracy: 0.7663\n",
      "Epoch 472/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7752 - val_loss: 0.5353 - val_accuracy: 0.7764\n",
      "Epoch 473/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7743 - val_loss: 0.5363 - val_accuracy: 0.7613\n",
      "Epoch 474/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7727 - val_loss: 0.5398 - val_accuracy: 0.7487\n",
      "Epoch 475/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7718 - val_loss: 0.5792 - val_accuracy: 0.7663\n",
      "Epoch 476/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7777 - val_loss: 0.5456 - val_accuracy: 0.7638\n",
      "Epoch 477/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7718 - val_loss: 0.6225 - val_accuracy: 0.7312\n",
      "Epoch 478/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7768 - val_loss: 0.5352 - val_accuracy: 0.7764\n",
      "Epoch 479/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7752 - val_loss: 0.5347 - val_accuracy: 0.7714\n",
      "Epoch 480/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7743 - val_loss: 0.5554 - val_accuracy: 0.7613\n",
      "Epoch 481/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7752 - val_loss: 0.5417 - val_accuracy: 0.7462\n",
      "Epoch 482/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7752 - val_loss: 0.5656 - val_accuracy: 0.7688\n",
      "Epoch 483/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7785 - val_loss: 0.5346 - val_accuracy: 0.7764\n",
      "Epoch 484/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7693 - val_loss: 0.5363 - val_accuracy: 0.7714\n",
      "Epoch 485/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7727 - val_loss: 0.5565 - val_accuracy: 0.7638\n",
      "Epoch 486/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7727 - val_loss: 0.5383 - val_accuracy: 0.7513\n",
      "Epoch 487/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7752 - val_loss: 0.5617 - val_accuracy: 0.6709\n",
      "Epoch 488/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7735 - val_loss: 0.5350 - val_accuracy: 0.7764\n",
      "Epoch 489/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7718 - val_loss: 0.5461 - val_accuracy: 0.7638\n",
      "Epoch 490/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7727 - val_loss: 0.5344 - val_accuracy: 0.7688\n",
      "Epoch 491/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7685 - val_loss: 0.5380 - val_accuracy: 0.7688\n",
      "Epoch 492/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7735 - val_loss: 0.5540 - val_accuracy: 0.7613\n",
      "Epoch 493/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7701 - val_loss: 0.5345 - val_accuracy: 0.7714\n",
      "Epoch 494/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7659 - val_loss: 0.5386 - val_accuracy: 0.7487\n",
      "Epoch 495/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7718 - val_loss: 0.5370 - val_accuracy: 0.7588\n",
      "Epoch 496/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7768 - val_loss: 0.5342 - val_accuracy: 0.7714\n",
      "Epoch 497/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7777 - val_loss: 0.5342 - val_accuracy: 0.7764\n",
      "Epoch 498/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7777 - val_loss: 0.5356 - val_accuracy: 0.7714\n",
      "Epoch 499/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7735 - val_loss: 0.5868 - val_accuracy: 0.7588\n",
      "Epoch 500/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7743 - val_loss: 0.5345 - val_accuracy: 0.7764\n",
      "Epoch 501/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.7743 - val_loss: 0.5686 - val_accuracy: 0.7638\n",
      "Epoch 502/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7777 - val_loss: 0.5655 - val_accuracy: 0.7663\n",
      "Epoch 503/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7727 - val_loss: 0.5355 - val_accuracy: 0.7613\n",
      "Epoch 504/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7752 - val_loss: 0.5687 - val_accuracy: 0.6683\n",
      "Epoch 505/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7584 - val_loss: 0.5427 - val_accuracy: 0.7663\n",
      "Epoch 506/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7794 - val_loss: 0.5515 - val_accuracy: 0.7663\n",
      "Epoch 507/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7785 - val_loss: 0.5450 - val_accuracy: 0.7337\n",
      "Epoch 508/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7685 - val_loss: 0.5470 - val_accuracy: 0.7337\n",
      "Epoch 509/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7718 - val_loss: 0.5497 - val_accuracy: 0.7638\n",
      "Epoch 510/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7760 - val_loss: 0.5359 - val_accuracy: 0.7714\n",
      "Epoch 511/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7710 - val_loss: 0.5417 - val_accuracy: 0.7663\n",
      "Epoch 512/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7743 - val_loss: 0.5412 - val_accuracy: 0.7462\n",
      "Epoch 513/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7685 - val_loss: 0.5339 - val_accuracy: 0.7764\n",
      "Epoch 514/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7760 - val_loss: 0.5388 - val_accuracy: 0.7688\n",
      "Epoch 515/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7743 - val_loss: 0.5377 - val_accuracy: 0.7688\n",
      "Epoch 516/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7752 - val_loss: 0.5340 - val_accuracy: 0.7764\n",
      "Epoch 517/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7752 - val_loss: 0.5378 - val_accuracy: 0.7688\n",
      "Epoch 518/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7735 - val_loss: 0.5336 - val_accuracy: 0.7739\n",
      "Epoch 519/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7810 - val_loss: 0.5539 - val_accuracy: 0.7060\n",
      "Epoch 520/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7685 - val_loss: 0.5378 - val_accuracy: 0.7513\n",
      "Epoch 521/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7768 - val_loss: 0.5465 - val_accuracy: 0.7337\n",
      "Epoch 522/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7718 - val_loss: 0.5337 - val_accuracy: 0.7714\n",
      "Epoch 523/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7743 - val_loss: 0.5413 - val_accuracy: 0.7437\n",
      "Epoch 524/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7743 - val_loss: 0.5385 - val_accuracy: 0.7688\n",
      "Epoch 525/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7794 - val_loss: 0.5397 - val_accuracy: 0.7688\n",
      "Epoch 526/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7710 - val_loss: 0.5337 - val_accuracy: 0.7764\n",
      "Epoch 527/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7802 - val_loss: 0.5384 - val_accuracy: 0.7688\n",
      "Epoch 528/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7777 - val_loss: 0.5375 - val_accuracy: 0.7688\n",
      "Epoch 529/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7777 - val_loss: 0.5394 - val_accuracy: 0.7462\n",
      "Epoch 530/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7727 - val_loss: 0.5431 - val_accuracy: 0.7663\n",
      "Epoch 531/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7777 - val_loss: 0.5341 - val_accuracy: 0.7688\n",
      "Epoch 532/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7676 - val_loss: 0.5362 - val_accuracy: 0.7663\n",
      "Epoch 533/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7760 - val_loss: 0.5340 - val_accuracy: 0.7739\n",
      "Epoch 534/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7760 - val_loss: 0.5378 - val_accuracy: 0.7513\n",
      "Epoch 535/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7718 - val_loss: 0.5362 - val_accuracy: 0.7663\n",
      "Epoch 536/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7752 - val_loss: 0.5866 - val_accuracy: 0.7563\n",
      "Epoch 537/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7735 - val_loss: 0.5634 - val_accuracy: 0.7613\n",
      "Epoch 538/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7735 - val_loss: 0.5332 - val_accuracy: 0.7739\n",
      "Epoch 539/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7718 - val_loss: 0.5877 - val_accuracy: 0.7563\n",
      "Epoch 540/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7794 - val_loss: 0.5445 - val_accuracy: 0.7663\n",
      "Epoch 541/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7802 - val_loss: 0.5394 - val_accuracy: 0.7688\n",
      "Epoch 542/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7827 - val_loss: 0.5811 - val_accuracy: 0.6533\n",
      "Epoch 543/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7676 - val_loss: 0.5450 - val_accuracy: 0.7337\n",
      "Epoch 544/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7710 - val_loss: 0.5359 - val_accuracy: 0.7588\n",
      "Epoch 545/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7735 - val_loss: 0.5967 - val_accuracy: 0.7588\n",
      "Epoch 546/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7752 - val_loss: 0.5332 - val_accuracy: 0.7764\n",
      "Epoch 547/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7735 - val_loss: 0.5332 - val_accuracy: 0.7714\n",
      "Epoch 548/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7785 - val_loss: 0.5490 - val_accuracy: 0.7663\n",
      "Epoch 549/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7727 - val_loss: 0.5374 - val_accuracy: 0.7513\n",
      "Epoch 550/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7676 - val_loss: 0.5336 - val_accuracy: 0.7688\n",
      "Epoch 551/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7760 - val_loss: 0.5422 - val_accuracy: 0.7412\n",
      "Epoch 552/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7752 - val_loss: 0.5454 - val_accuracy: 0.7663\n",
      "Epoch 553/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7802 - val_loss: 0.5414 - val_accuracy: 0.7663\n",
      "Epoch 554/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7752 - val_loss: 0.5401 - val_accuracy: 0.7437\n",
      "Epoch 555/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7727 - val_loss: 0.5372 - val_accuracy: 0.7663\n",
      "Epoch 556/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7743 - val_loss: 0.5333 - val_accuracy: 0.7764\n",
      "Epoch 557/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7760 - val_loss: 0.5339 - val_accuracy: 0.7688\n",
      "Epoch 558/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7760 - val_loss: 0.5436 - val_accuracy: 0.7663\n",
      "Epoch 559/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7735 - val_loss: 0.5340 - val_accuracy: 0.7688\n",
      "Epoch 560/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7760 - val_loss: 0.5344 - val_accuracy: 0.7663\n",
      "Epoch 561/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7701 - val_loss: 0.5362 - val_accuracy: 0.7563\n",
      "Epoch 562/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7727 - val_loss: 0.5498 - val_accuracy: 0.7638\n",
      "Epoch 563/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7768 - val_loss: 0.5442 - val_accuracy: 0.7663\n",
      "Epoch 564/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7794 - val_loss: 0.5327 - val_accuracy: 0.7739\n",
      "Epoch 565/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7727 - val_loss: 0.5436 - val_accuracy: 0.7663\n",
      "Epoch 566/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7701 - val_loss: 0.5525 - val_accuracy: 0.7663\n",
      "Epoch 567/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7785 - val_loss: 0.5344 - val_accuracy: 0.7663\n",
      "Epoch 568/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7802 - val_loss: 0.5472 - val_accuracy: 0.7688\n",
      "Epoch 569/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7794 - val_loss: 0.5359 - val_accuracy: 0.7588\n",
      "Epoch 570/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7777 - val_loss: 0.5412 - val_accuracy: 0.7663\n",
      "Epoch 571/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7752 - val_loss: 0.5330 - val_accuracy: 0.7739\n",
      "Epoch 572/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7752 - val_loss: 0.5334 - val_accuracy: 0.7688\n",
      "Epoch 573/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7727 - val_loss: 0.5364 - val_accuracy: 0.7663\n",
      "Epoch 574/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7802 - val_loss: 0.5668 - val_accuracy: 0.7613\n",
      "Epoch 575/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7752 - val_loss: 0.5636 - val_accuracy: 0.7613\n",
      "Epoch 576/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7718 - val_loss: 0.5324 - val_accuracy: 0.7739\n",
      "Epoch 577/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7718 - val_loss: 0.5325 - val_accuracy: 0.7688\n",
      "Epoch 578/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7685 - val_loss: 0.5442 - val_accuracy: 0.7663\n",
      "Epoch 579/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7727 - val_loss: 0.5328 - val_accuracy: 0.7739\n",
      "Epoch 580/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7760 - val_loss: 0.5373 - val_accuracy: 0.7487\n",
      "Epoch 581/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7777 - val_loss: 0.5326 - val_accuracy: 0.7739\n",
      "Epoch 582/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7735 - val_loss: 0.5724 - val_accuracy: 0.6633\n",
      "Epoch 583/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7676 - val_loss: 0.5327 - val_accuracy: 0.7663\n",
      "Epoch 584/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7743 - val_loss: 0.5400 - val_accuracy: 0.7688\n",
      "Epoch 585/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7676 - val_loss: 0.5438 - val_accuracy: 0.7663\n",
      "Epoch 586/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7752 - val_loss: 0.5394 - val_accuracy: 0.7688\n",
      "Epoch 587/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7752 - val_loss: 0.5320 - val_accuracy: 0.7739\n",
      "Epoch 588/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7701 - val_loss: 0.5973 - val_accuracy: 0.6432\n",
      "Epoch 589/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7743 - val_loss: 0.5529 - val_accuracy: 0.7663\n",
      "Epoch 590/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7777 - val_loss: 0.5351 - val_accuracy: 0.7563\n",
      "Epoch 591/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7752 - val_loss: 0.5612 - val_accuracy: 0.7588\n",
      "Epoch 592/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7718 - val_loss: 0.5324 - val_accuracy: 0.7714\n",
      "Epoch 593/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7752 - val_loss: 0.5390 - val_accuracy: 0.7462\n",
      "Epoch 594/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7760 - val_loss: 0.5571 - val_accuracy: 0.7613\n",
      "Epoch 595/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7768 - val_loss: 0.5359 - val_accuracy: 0.7663\n",
      "Epoch 596/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7802 - val_loss: 0.5316 - val_accuracy: 0.7739\n",
      "Epoch 597/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7743 - val_loss: 0.5316 - val_accuracy: 0.7739\n",
      "Epoch 598/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7718 - val_loss: 0.5323 - val_accuracy: 0.7663\n",
      "Epoch 599/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7743 - val_loss: 0.5987 - val_accuracy: 0.7613\n",
      "Epoch 600/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7743 - val_loss: 0.5370 - val_accuracy: 0.7462\n",
      "Epoch 601/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7727 - val_loss: 0.5415 - val_accuracy: 0.7663\n",
      "Epoch 602/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7752 - val_loss: 0.5561 - val_accuracy: 0.7638\n",
      "Epoch 603/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7777 - val_loss: 0.5762 - val_accuracy: 0.7538\n",
      "Epoch 604/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7752 - val_loss: 0.5334 - val_accuracy: 0.7638\n",
      "Epoch 605/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7768 - val_loss: 0.5332 - val_accuracy: 0.7638\n",
      "Epoch 606/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7752 - val_loss: 0.5415 - val_accuracy: 0.7412\n",
      "Epoch 607/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7802 - val_loss: 0.5338 - val_accuracy: 0.7663\n",
      "Epoch 608/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7760 - val_loss: 0.5776 - val_accuracy: 0.7538\n",
      "Epoch 609/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7727 - val_loss: 0.5322 - val_accuracy: 0.7663\n",
      "Epoch 610/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7752 - val_loss: 0.5361 - val_accuracy: 0.7663\n",
      "Epoch 611/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7743 - val_loss: 0.5379 - val_accuracy: 0.7487\n",
      "Epoch 612/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7752 - val_loss: 0.5375 - val_accuracy: 0.7688\n",
      "Epoch 613/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7743 - val_loss: 0.5531 - val_accuracy: 0.7663\n",
      "Epoch 614/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7785 - val_loss: 0.5378 - val_accuracy: 0.7688\n",
      "Epoch 615/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7735 - val_loss: 0.5387 - val_accuracy: 0.7462\n",
      "Epoch 616/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7743 - val_loss: 0.5343 - val_accuracy: 0.7638\n",
      "Epoch 617/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7701 - val_loss: 0.5492 - val_accuracy: 0.7688\n",
      "Epoch 618/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7710 - val_loss: 0.5373 - val_accuracy: 0.7663\n",
      "Epoch 619/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7760 - val_loss: 0.5337 - val_accuracy: 0.7638\n",
      "Epoch 620/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7735 - val_loss: 0.5312 - val_accuracy: 0.7739\n",
      "Epoch 621/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7752 - val_loss: 0.5560 - val_accuracy: 0.7613\n",
      "Epoch 622/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7768 - val_loss: 0.5600 - val_accuracy: 0.6859\n",
      "Epoch 623/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.7735 - val_loss: 0.5365 - val_accuracy: 0.7663\n",
      "Epoch 624/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7785 - val_loss: 0.5326 - val_accuracy: 0.7714\n",
      "Epoch 625/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7802 - val_loss: 0.5431 - val_accuracy: 0.7688\n",
      "Epoch 626/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7752 - val_loss: 0.5381 - val_accuracy: 0.7688\n",
      "Epoch 627/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7794 - val_loss: 0.5626 - val_accuracy: 0.7588\n",
      "Epoch 628/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7760 - val_loss: 0.5371 - val_accuracy: 0.7663\n",
      "Epoch 629/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7794 - val_loss: 0.5629 - val_accuracy: 0.7588\n",
      "Epoch 630/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7701 - val_loss: 0.5551 - val_accuracy: 0.7613\n",
      "Epoch 631/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7701 - val_loss: 0.5332 - val_accuracy: 0.7638\n",
      "Epoch 632/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7794 - val_loss: 0.5323 - val_accuracy: 0.7688\n",
      "Epoch 633/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7760 - val_loss: 0.5336 - val_accuracy: 0.7638\n",
      "Epoch 634/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7760 - val_loss: 0.5363 - val_accuracy: 0.7462\n",
      "Epoch 635/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7693 - val_loss: 0.5713 - val_accuracy: 0.7538\n",
      "Epoch 636/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7727 - val_loss: 0.5403 - val_accuracy: 0.7688\n",
      "Epoch 637/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7743 - val_loss: 0.5502 - val_accuracy: 0.7688\n",
      "Epoch 638/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7827 - val_loss: 0.5856 - val_accuracy: 0.7513\n",
      "Epoch 639/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7752 - val_loss: 0.5450 - val_accuracy: 0.7663\n",
      "Epoch 640/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7777 - val_loss: 0.5314 - val_accuracy: 0.7663\n",
      "Epoch 641/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7752 - val_loss: 0.5311 - val_accuracy: 0.7739\n",
      "Epoch 642/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7752 - val_loss: 0.5466 - val_accuracy: 0.7688\n",
      "Epoch 643/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7710 - val_loss: 0.5370 - val_accuracy: 0.7663\n",
      "Epoch 644/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7794 - val_loss: 0.5306 - val_accuracy: 0.7739\n",
      "Epoch 645/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7760 - val_loss: 0.5327 - val_accuracy: 0.7739\n",
      "Epoch 646/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7727 - val_loss: 0.5463 - val_accuracy: 0.7688\n",
      "Epoch 647/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7735 - val_loss: 0.5722 - val_accuracy: 0.6709\n",
      "Epoch 648/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7752 - val_loss: 0.5435 - val_accuracy: 0.7663\n",
      "Epoch 649/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7768 - val_loss: 0.5315 - val_accuracy: 0.7663\n",
      "Epoch 650/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7743 - val_loss: 0.5303 - val_accuracy: 0.7739\n",
      "Epoch 651/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7777 - val_loss: 0.5408 - val_accuracy: 0.7412\n",
      "Epoch 652/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7794 - val_loss: 0.5304 - val_accuracy: 0.7739\n",
      "Epoch 653/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7710 - val_loss: 0.5332 - val_accuracy: 0.7638\n",
      "Epoch 654/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7735 - val_loss: 0.5315 - val_accuracy: 0.7739\n",
      "Epoch 655/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7693 - val_loss: 0.5480 - val_accuracy: 0.7688\n",
      "Epoch 656/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7794 - val_loss: 0.5313 - val_accuracy: 0.7739\n",
      "Epoch 657/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7718 - val_loss: 0.5397 - val_accuracy: 0.7714\n",
      "Epoch 658/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7743 - val_loss: 0.5424 - val_accuracy: 0.7663\n",
      "Epoch 659/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7794 - val_loss: 0.5330 - val_accuracy: 0.7638\n",
      "Epoch 660/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7760 - val_loss: 0.5313 - val_accuracy: 0.7638\n",
      "Epoch 661/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7685 - val_loss: 0.5369 - val_accuracy: 0.7663\n",
      "Epoch 662/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7760 - val_loss: 0.5712 - val_accuracy: 0.6709\n",
      "Epoch 663/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7651 - val_loss: 0.5623 - val_accuracy: 0.7588\n",
      "Epoch 664/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7768 - val_loss: 0.5625 - val_accuracy: 0.7588\n",
      "Epoch 665/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7727 - val_loss: 0.5307 - val_accuracy: 0.7663\n",
      "Epoch 666/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7752 - val_loss: 0.5394 - val_accuracy: 0.7688\n",
      "Epoch 667/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7743 - val_loss: 0.5310 - val_accuracy: 0.7663\n",
      "Epoch 668/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7710 - val_loss: 0.5319 - val_accuracy: 0.7613\n",
      "Epoch 669/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7743 - val_loss: 0.5349 - val_accuracy: 0.7638\n",
      "Epoch 670/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7802 - val_loss: 0.5703 - val_accuracy: 0.6759\n",
      "Epoch 671/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7718 - val_loss: 0.5676 - val_accuracy: 0.7513\n",
      "Epoch 672/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7802 - val_loss: 0.5417 - val_accuracy: 0.7714\n",
      "Epoch 673/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7794 - val_loss: 0.5301 - val_accuracy: 0.7714\n",
      "Epoch 674/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7777 - val_loss: 0.5316 - val_accuracy: 0.7613\n",
      "Epoch 675/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7710 - val_loss: 0.5327 - val_accuracy: 0.7688\n",
      "Epoch 676/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7760 - val_loss: 0.5731 - val_accuracy: 0.7538\n",
      "Epoch 677/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7768 - val_loss: 0.5314 - val_accuracy: 0.7739\n",
      "Epoch 678/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7760 - val_loss: 0.5443 - val_accuracy: 0.7688\n",
      "Epoch 679/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7794 - val_loss: 0.5376 - val_accuracy: 0.7462\n",
      "Epoch 680/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7727 - val_loss: 0.5317 - val_accuracy: 0.7739\n",
      "Epoch 681/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7819 - val_loss: 0.5437 - val_accuracy: 0.7688\n",
      "Epoch 682/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7785 - val_loss: 0.5298 - val_accuracy: 0.7714\n",
      "Epoch 683/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7777 - val_loss: 0.5664 - val_accuracy: 0.7513\n",
      "Epoch 684/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7701 - val_loss: 0.5329 - val_accuracy: 0.7663\n",
      "Epoch 685/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7743 - val_loss: 0.5371 - val_accuracy: 0.7462\n",
      "Epoch 686/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7802 - val_loss: 0.5400 - val_accuracy: 0.7714\n",
      "Epoch 687/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7802 - val_loss: 0.5318 - val_accuracy: 0.7638\n",
      "Epoch 688/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7743 - val_loss: 0.5342 - val_accuracy: 0.7638\n",
      "Epoch 689/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7752 - val_loss: 0.5364 - val_accuracy: 0.7663\n",
      "Epoch 690/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7743 - val_loss: 0.5895 - val_accuracy: 0.6508\n",
      "Epoch 691/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7768 - val_loss: 0.5312 - val_accuracy: 0.7739\n",
      "Epoch 692/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7743 - val_loss: 0.5297 - val_accuracy: 0.7714\n",
      "Epoch 693/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7785 - val_loss: 0.5383 - val_accuracy: 0.7688\n",
      "Epoch 694/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7768 - val_loss: 0.5386 - val_accuracy: 0.7437\n",
      "Epoch 695/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.7693 - val_loss: 0.5358 - val_accuracy: 0.7462\n",
      "Epoch 696/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7794 - val_loss: 0.5592 - val_accuracy: 0.6935\n",
      "Epoch 697/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7701 - val_loss: 0.5310 - val_accuracy: 0.7739\n",
      "Epoch 698/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7794 - val_loss: 0.5327 - val_accuracy: 0.7638\n",
      "Epoch 699/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7727 - val_loss: 0.5508 - val_accuracy: 0.7161\n",
      "Epoch 700/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7735 - val_loss: 0.5357 - val_accuracy: 0.7638\n",
      "Epoch 701/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7752 - val_loss: 0.5336 - val_accuracy: 0.7638\n",
      "Epoch 702/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7727 - val_loss: 0.5524 - val_accuracy: 0.7638\n",
      "Epoch 703/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7768 - val_loss: 0.5299 - val_accuracy: 0.7663\n",
      "Epoch 704/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7777 - val_loss: 0.5356 - val_accuracy: 0.7437\n",
      "Epoch 705/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7743 - val_loss: 0.5320 - val_accuracy: 0.7638\n",
      "Epoch 706/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7752 - val_loss: 0.5349 - val_accuracy: 0.7638\n",
      "Epoch 707/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7777 - val_loss: 0.5294 - val_accuracy: 0.7714\n",
      "Epoch 708/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7752 - val_loss: 0.5505 - val_accuracy: 0.7638\n",
      "Epoch 709/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7794 - val_loss: 0.5374 - val_accuracy: 0.7688\n",
      "Epoch 710/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7727 - val_loss: 0.5716 - val_accuracy: 0.7538\n",
      "Epoch 711/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7710 - val_loss: 0.5318 - val_accuracy: 0.7638\n",
      "Epoch 712/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7810 - val_loss: 0.5294 - val_accuracy: 0.7739\n",
      "Epoch 713/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7794 - val_loss: 0.5304 - val_accuracy: 0.7613\n",
      "Epoch 714/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7710 - val_loss: 0.5634 - val_accuracy: 0.7487\n",
      "Epoch 715/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7710 - val_loss: 0.5309 - val_accuracy: 0.7613\n",
      "Epoch 716/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7727 - val_loss: 0.5789 - val_accuracy: 0.6608\n",
      "Epoch 717/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7676 - val_loss: 0.5295 - val_accuracy: 0.7714\n",
      "Epoch 718/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7752 - val_loss: 0.5293 - val_accuracy: 0.7739\n",
      "Epoch 719/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7727 - val_loss: 0.5308 - val_accuracy: 0.7613\n",
      "Epoch 720/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7727 - val_loss: 0.5816 - val_accuracy: 0.7538\n",
      "Epoch 721/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7802 - val_loss: 0.5334 - val_accuracy: 0.7588\n",
      "Epoch 722/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7760 - val_loss: 0.5338 - val_accuracy: 0.7638\n",
      "Epoch 723/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7768 - val_loss: 0.5644 - val_accuracy: 0.6734\n",
      "Epoch 724/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7752 - val_loss: 0.5355 - val_accuracy: 0.7462\n",
      "Epoch 725/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7693 - val_loss: 0.5398 - val_accuracy: 0.7714\n",
      "Epoch 726/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7794 - val_loss: 0.5307 - val_accuracy: 0.7613\n",
      "Epoch 727/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7760 - val_loss: 0.5709 - val_accuracy: 0.7538\n",
      "Epoch 728/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7718 - val_loss: 0.5388 - val_accuracy: 0.7714\n",
      "Epoch 729/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7752 - val_loss: 0.5337 - val_accuracy: 0.7563\n",
      "Epoch 730/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7727 - val_loss: 0.5309 - val_accuracy: 0.7688\n",
      "Epoch 731/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7743 - val_loss: 0.6104 - val_accuracy: 0.7588\n",
      "Epoch 732/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7768 - val_loss: 0.5714 - val_accuracy: 0.7538\n",
      "Epoch 733/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7752 - val_loss: 0.5502 - val_accuracy: 0.7638\n",
      "Epoch 734/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7727 - val_loss: 0.5300 - val_accuracy: 0.7688\n",
      "Epoch 735/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7727 - val_loss: 0.5529 - val_accuracy: 0.7186\n",
      "Epoch 736/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7701 - val_loss: 0.5812 - val_accuracy: 0.7538\n",
      "Epoch 737/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7785 - val_loss: 0.5634 - val_accuracy: 0.6834\n",
      "Epoch 738/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7685 - val_loss: 0.5296 - val_accuracy: 0.7638\n",
      "Epoch 739/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7794 - val_loss: 0.5331 - val_accuracy: 0.7638\n",
      "Epoch 740/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7794 - val_loss: 0.5656 - val_accuracy: 0.7487\n",
      "Epoch 741/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7768 - val_loss: 0.5575 - val_accuracy: 0.7613\n",
      "Epoch 742/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7785 - val_loss: 0.5374 - val_accuracy: 0.7714\n",
      "Epoch 743/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7727 - val_loss: 0.5321 - val_accuracy: 0.7663\n",
      "Epoch 744/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7768 - val_loss: 0.5288 - val_accuracy: 0.7714\n",
      "Epoch 745/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7727 - val_loss: 0.5418 - val_accuracy: 0.7714\n",
      "Epoch 746/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7802 - val_loss: 0.5287 - val_accuracy: 0.7714\n",
      "Epoch 747/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7727 - val_loss: 0.5308 - val_accuracy: 0.7613\n",
      "Epoch 748/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7768 - val_loss: 0.5527 - val_accuracy: 0.7638\n",
      "Epoch 749/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7710 - val_loss: 0.5721 - val_accuracy: 0.7538\n",
      "Epoch 750/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7802 - val_loss: 0.5426 - val_accuracy: 0.7714\n",
      "Epoch 751/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7701 - val_loss: 0.5301 - val_accuracy: 0.7714\n",
      "Epoch 752/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7752 - val_loss: 0.5322 - val_accuracy: 0.7638\n",
      "Epoch 753/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7752 - val_loss: 0.5372 - val_accuracy: 0.7714\n",
      "Epoch 754/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7718 - val_loss: 0.5367 - val_accuracy: 0.7487\n",
      "Epoch 755/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7743 - val_loss: 0.5296 - val_accuracy: 0.7688\n",
      "Epoch 756/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7760 - val_loss: 0.5407 - val_accuracy: 0.7714\n",
      "Epoch 757/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7718 - val_loss: 0.5356 - val_accuracy: 0.7663\n",
      "Epoch 758/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7794 - val_loss: 0.5367 - val_accuracy: 0.7688\n",
      "Epoch 759/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7727 - val_loss: 0.5322 - val_accuracy: 0.7638\n",
      "Epoch 760/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7760 - val_loss: 0.5291 - val_accuracy: 0.7663\n",
      "Epoch 761/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7727 - val_loss: 0.5362 - val_accuracy: 0.7663\n",
      "Epoch 762/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7743 - val_loss: 0.5311 - val_accuracy: 0.7638\n",
      "Epoch 763/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7819 - val_loss: 0.5297 - val_accuracy: 0.7613\n",
      "Epoch 764/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7760 - val_loss: 0.5600 - val_accuracy: 0.6985\n",
      "Epoch 765/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7794 - val_loss: 0.5418 - val_accuracy: 0.7714\n",
      "Epoch 766/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7768 - val_loss: 0.5283 - val_accuracy: 0.7714\n",
      "Epoch 767/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7727 - val_loss: 0.5284 - val_accuracy: 0.7688\n",
      "Epoch 768/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7701 - val_loss: 0.5312 - val_accuracy: 0.7638\n",
      "Epoch 769/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7701 - val_loss: 0.5466 - val_accuracy: 0.7688\n",
      "Epoch 770/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7727 - val_loss: 0.5283 - val_accuracy: 0.7739\n",
      "Epoch 771/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7760 - val_loss: 0.5536 - val_accuracy: 0.7638\n",
      "Epoch 772/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7785 - val_loss: 0.5451 - val_accuracy: 0.7688\n",
      "Epoch 773/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7710 - val_loss: 0.5462 - val_accuracy: 0.7688\n",
      "Epoch 774/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7727 - val_loss: 0.5527 - val_accuracy: 0.7638\n",
      "Epoch 775/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7727 - val_loss: 0.5403 - val_accuracy: 0.7714\n",
      "Epoch 776/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7827 - val_loss: 0.5420 - val_accuracy: 0.7714\n",
      "Epoch 777/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7785 - val_loss: 0.5836 - val_accuracy: 0.7563\n",
      "Epoch 778/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7768 - val_loss: 0.5308 - val_accuracy: 0.7613\n",
      "Epoch 779/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7735 - val_loss: 0.5294 - val_accuracy: 0.7613\n",
      "Epoch 780/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7810 - val_loss: 0.5311 - val_accuracy: 0.7714\n",
      "Epoch 781/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7785 - val_loss: 0.5448 - val_accuracy: 0.7362\n",
      "Epoch 782/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7777 - val_loss: 0.5463 - val_accuracy: 0.7688\n",
      "Epoch 783/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7727 - val_loss: 0.5372 - val_accuracy: 0.7714\n",
      "Epoch 784/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7710 - val_loss: 0.5285 - val_accuracy: 0.7714\n",
      "Epoch 785/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7760 - val_loss: 0.5967 - val_accuracy: 0.7588\n",
      "Epoch 786/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7701 - val_loss: 0.5384 - val_accuracy: 0.7688\n",
      "Epoch 787/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7777 - val_loss: 0.5320 - val_accuracy: 0.7638\n",
      "Epoch 788/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7659 - val_loss: 0.5422 - val_accuracy: 0.7437\n",
      "Epoch 789/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7718 - val_loss: 0.5755 - val_accuracy: 0.7513\n",
      "Epoch 790/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7794 - val_loss: 0.5387 - val_accuracy: 0.7688\n",
      "Epoch 791/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7802 - val_loss: 0.5279 - val_accuracy: 0.7714\n",
      "Epoch 792/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7718 - val_loss: 0.5344 - val_accuracy: 0.7638\n",
      "Epoch 793/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7752 - val_loss: 0.5333 - val_accuracy: 0.7638\n",
      "Epoch 794/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7777 - val_loss: 0.5324 - val_accuracy: 0.7588\n",
      "Epoch 795/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7735 - val_loss: 0.5347 - val_accuracy: 0.7638\n",
      "Epoch 796/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7760 - val_loss: 0.5338 - val_accuracy: 0.7638\n",
      "Epoch 797/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7777 - val_loss: 0.5448 - val_accuracy: 0.7688\n",
      "Epoch 798/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7794 - val_loss: 0.5289 - val_accuracy: 0.7663\n",
      "Epoch 799/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7810 - val_loss: 0.5279 - val_accuracy: 0.7714\n",
      "Epoch 800/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7768 - val_loss: 0.5701 - val_accuracy: 0.6709\n",
      "Epoch 801/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7676 - val_loss: 0.5325 - val_accuracy: 0.7588\n",
      "Epoch 802/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7752 - val_loss: 0.5293 - val_accuracy: 0.7613\n",
      "Epoch 803/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7768 - val_loss: 0.5293 - val_accuracy: 0.7613\n",
      "Epoch 804/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7768 - val_loss: 0.5389 - val_accuracy: 0.7688\n",
      "Epoch 805/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7768 - val_loss: 0.5309 - val_accuracy: 0.7638\n",
      "Epoch 806/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7760 - val_loss: 0.5708 - val_accuracy: 0.6784\n",
      "Epoch 807/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7710 - val_loss: 0.5481 - val_accuracy: 0.7337\n",
      "Epoch 808/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7768 - val_loss: 0.5317 - val_accuracy: 0.7663\n",
      "Epoch 809/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7701 - val_loss: 0.5344 - val_accuracy: 0.7638\n",
      "Epoch 810/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7727 - val_loss: 0.5331 - val_accuracy: 0.7513\n",
      "Epoch 811/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7760 - val_loss: 0.5290 - val_accuracy: 0.7663\n",
      "Epoch 812/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7777 - val_loss: 0.5343 - val_accuracy: 0.7638\n",
      "Epoch 813/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7735 - val_loss: 0.5480 - val_accuracy: 0.7337\n",
      "Epoch 814/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7785 - val_loss: 0.5346 - val_accuracy: 0.7462\n",
      "Epoch 815/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7727 - val_loss: 0.5441 - val_accuracy: 0.7688\n",
      "Epoch 816/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7760 - val_loss: 0.5314 - val_accuracy: 0.7688\n",
      "Epoch 817/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7794 - val_loss: 0.5298 - val_accuracy: 0.7613\n",
      "Epoch 818/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7735 - val_loss: 0.5295 - val_accuracy: 0.7714\n",
      "Epoch 819/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7693 - val_loss: 0.5388 - val_accuracy: 0.7714\n",
      "Epoch 820/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7743 - val_loss: 0.5275 - val_accuracy: 0.7714\n",
      "Epoch 821/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7752 - val_loss: 0.5536 - val_accuracy: 0.7638\n",
      "Epoch 822/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7727 - val_loss: 0.5421 - val_accuracy: 0.7714\n",
      "Epoch 823/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7777 - val_loss: 0.5316 - val_accuracy: 0.7638\n",
      "Epoch 824/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7752 - val_loss: 0.5288 - val_accuracy: 0.7613\n",
      "Epoch 825/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7727 - val_loss: 0.5570 - val_accuracy: 0.7613\n",
      "Epoch 826/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7802 - val_loss: 0.5360 - val_accuracy: 0.7462\n",
      "Epoch 827/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7760 - val_loss: 0.5361 - val_accuracy: 0.7688\n",
      "Epoch 828/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7760 - val_loss: 0.5304 - val_accuracy: 0.7714\n",
      "Epoch 829/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7794 - val_loss: 0.5413 - val_accuracy: 0.7412\n",
      "Epoch 830/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7768 - val_loss: 0.5685 - val_accuracy: 0.7513\n",
      "Epoch 831/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7819 - val_loss: 0.5311 - val_accuracy: 0.7638\n",
      "Epoch 832/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7710 - val_loss: 0.5289 - val_accuracy: 0.7688\n",
      "Epoch 833/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7752 - val_loss: 0.5271 - val_accuracy: 0.7714\n",
      "Epoch 834/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7743 - val_loss: 0.5301 - val_accuracy: 0.7613\n",
      "Epoch 835/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7735 - val_loss: 0.5454 - val_accuracy: 0.7688\n",
      "Epoch 836/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7760 - val_loss: 0.5282 - val_accuracy: 0.7613\n",
      "Epoch 837/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7802 - val_loss: 0.5344 - val_accuracy: 0.7638\n",
      "Epoch 838/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7836 - val_loss: 0.5788 - val_accuracy: 0.7538\n",
      "Epoch 839/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7735 - val_loss: 0.5418 - val_accuracy: 0.7714\n",
      "Epoch 840/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7752 - val_loss: 0.5659 - val_accuracy: 0.7487\n",
      "Epoch 841/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7743 - val_loss: 0.5394 - val_accuracy: 0.7462\n",
      "Epoch 842/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7760 - val_loss: 0.5606 - val_accuracy: 0.7513\n",
      "Epoch 843/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7819 - val_loss: 0.5579 - val_accuracy: 0.7588\n",
      "Epoch 844/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7819 - val_loss: 0.5313 - val_accuracy: 0.7638\n",
      "Epoch 845/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7743 - val_loss: 0.5278 - val_accuracy: 0.7663\n",
      "Epoch 846/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7743 - val_loss: 0.5293 - val_accuracy: 0.7613\n",
      "Epoch 847/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7777 - val_loss: 0.5389 - val_accuracy: 0.7714\n",
      "Epoch 848/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7735 - val_loss: 0.5513 - val_accuracy: 0.7186\n",
      "Epoch 849/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7668 - val_loss: 0.5392 - val_accuracy: 0.7714\n",
      "Epoch 850/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7777 - val_loss: 0.5422 - val_accuracy: 0.7714\n",
      "Epoch 851/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7743 - val_loss: 0.5269 - val_accuracy: 0.7714\n",
      "Epoch 852/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7710 - val_loss: 0.5432 - val_accuracy: 0.7714\n",
      "Epoch 853/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7743 - val_loss: 0.5268 - val_accuracy: 0.7714\n",
      "Epoch 854/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7752 - val_loss: 0.5277 - val_accuracy: 0.7613\n",
      "Epoch 855/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7760 - val_loss: 0.5492 - val_accuracy: 0.7638\n",
      "Epoch 856/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7735 - val_loss: 0.5314 - val_accuracy: 0.7638\n",
      "Epoch 857/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7777 - val_loss: 0.5566 - val_accuracy: 0.7563\n",
      "Epoch 858/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7819 - val_loss: 0.5267 - val_accuracy: 0.7714\n",
      "Epoch 859/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7785 - val_loss: 0.5454 - val_accuracy: 0.7412\n",
      "Epoch 860/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7735 - val_loss: 0.5335 - val_accuracy: 0.7638\n",
      "Epoch 861/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7693 - val_loss: 0.5337 - val_accuracy: 0.7638\n",
      "Epoch 862/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7760 - val_loss: 0.5310 - val_accuracy: 0.7663\n",
      "Epoch 863/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7735 - val_loss: 0.5307 - val_accuracy: 0.7638\n",
      "Epoch 864/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7727 - val_loss: 0.5762 - val_accuracy: 0.7513\n",
      "Epoch 865/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7668 - val_loss: 0.5278 - val_accuracy: 0.7638\n",
      "Epoch 866/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7693 - val_loss: 0.5416 - val_accuracy: 0.7437\n",
      "Epoch 867/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7727 - val_loss: 0.5292 - val_accuracy: 0.7613\n",
      "Epoch 868/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7743 - val_loss: 0.5504 - val_accuracy: 0.7211\n",
      "Epoch 869/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.7752 - val_loss: 0.5280 - val_accuracy: 0.7613\n",
      "Epoch 870/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7785 - val_loss: 0.5644 - val_accuracy: 0.6809\n",
      "Epoch 871/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7659 - val_loss: 0.5452 - val_accuracy: 0.7688\n",
      "Epoch 872/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7777 - val_loss: 0.5616 - val_accuracy: 0.6859\n",
      "Epoch 873/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7743 - val_loss: 0.5265 - val_accuracy: 0.7714\n",
      "Epoch 874/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7743 - val_loss: 0.5412 - val_accuracy: 0.7714\n",
      "Epoch 875/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7752 - val_loss: 0.5360 - val_accuracy: 0.7688\n",
      "Epoch 876/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7810 - val_loss: 0.5332 - val_accuracy: 0.7538\n",
      "Epoch 877/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7718 - val_loss: 0.5297 - val_accuracy: 0.7613\n",
      "Epoch 878/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7735 - val_loss: 0.5375 - val_accuracy: 0.7714\n",
      "Epoch 879/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7768 - val_loss: 0.5793 - val_accuracy: 0.7538\n",
      "Epoch 880/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7701 - val_loss: 0.5285 - val_accuracy: 0.7613\n",
      "Epoch 881/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7735 - val_loss: 0.5447 - val_accuracy: 0.7688\n",
      "Epoch 882/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7752 - val_loss: 0.5299 - val_accuracy: 0.7638\n",
      "Epoch 883/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7752 - val_loss: 0.5265 - val_accuracy: 0.7663\n",
      "Epoch 884/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7777 - val_loss: 0.5264 - val_accuracy: 0.7714\n",
      "Epoch 885/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7768 - val_loss: 0.5314 - val_accuracy: 0.7638\n",
      "Epoch 886/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7752 - val_loss: 0.5460 - val_accuracy: 0.7688\n",
      "Epoch 887/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7802 - val_loss: 0.5268 - val_accuracy: 0.7638\n",
      "Epoch 888/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7718 - val_loss: 0.5378 - val_accuracy: 0.7714\n",
      "Epoch 889/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7785 - val_loss: 0.5350 - val_accuracy: 0.7688\n",
      "Epoch 890/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7743 - val_loss: 0.5614 - val_accuracy: 0.7513\n",
      "Epoch 891/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7668 - val_loss: 0.5428 - val_accuracy: 0.7714\n",
      "Epoch 892/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7743 - val_loss: 0.5295 - val_accuracy: 0.7688\n",
      "Epoch 893/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7819 - val_loss: 0.5262 - val_accuracy: 0.7714\n",
      "Epoch 894/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7777 - val_loss: 0.5407 - val_accuracy: 0.7714\n",
      "Epoch 895/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7777 - val_loss: 0.5278 - val_accuracy: 0.7663\n",
      "Epoch 896/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7785 - val_loss: 0.5382 - val_accuracy: 0.7462\n",
      "Epoch 897/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7735 - val_loss: 0.5260 - val_accuracy: 0.7714\n",
      "Epoch 898/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7760 - val_loss: 0.5455 - val_accuracy: 0.7638\n",
      "Epoch 899/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7743 - val_loss: 0.5323 - val_accuracy: 0.7663\n",
      "Epoch 900/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7710 - val_loss: 0.5465 - val_accuracy: 0.7638\n",
      "Epoch 901/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7760 - val_loss: 0.5292 - val_accuracy: 0.7638\n",
      "Epoch 902/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7735 - val_loss: 0.5331 - val_accuracy: 0.7513\n",
      "Epoch 903/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7743 - val_loss: 0.5679 - val_accuracy: 0.7513\n",
      "Epoch 904/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7768 - val_loss: 0.5271 - val_accuracy: 0.7663\n",
      "Epoch 905/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7760 - val_loss: 0.5393 - val_accuracy: 0.7714\n",
      "Epoch 906/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7743 - val_loss: 0.5506 - val_accuracy: 0.7211\n",
      "Epoch 907/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7727 - val_loss: 0.5566 - val_accuracy: 0.7563\n",
      "Epoch 908/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7718 - val_loss: 0.5260 - val_accuracy: 0.7714\n",
      "Epoch 909/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7777 - val_loss: 0.5546 - val_accuracy: 0.7613\n",
      "Epoch 910/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7727 - val_loss: 0.5294 - val_accuracy: 0.7638\n",
      "Epoch 911/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7735 - val_loss: 0.5318 - val_accuracy: 0.7638\n",
      "Epoch 912/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7777 - val_loss: 0.5467 - val_accuracy: 0.7638\n",
      "Epoch 913/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7752 - val_loss: 0.5318 - val_accuracy: 0.7638\n",
      "Epoch 914/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7794 - val_loss: 0.5394 - val_accuracy: 0.7714\n",
      "Epoch 915/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7760 - val_loss: 0.5318 - val_accuracy: 0.7563\n",
      "Epoch 916/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7777 - val_loss: 0.5556 - val_accuracy: 0.7613\n",
      "Epoch 917/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7777 - val_loss: 0.5275 - val_accuracy: 0.7663\n",
      "Epoch 918/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7827 - val_loss: 0.5442 - val_accuracy: 0.7412\n",
      "Epoch 919/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7794 - val_loss: 0.5263 - val_accuracy: 0.7638\n",
      "Epoch 920/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7777 - val_loss: 0.5280 - val_accuracy: 0.7688\n",
      "Epoch 921/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7760 - val_loss: 0.5521 - val_accuracy: 0.7186\n",
      "Epoch 922/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7718 - val_loss: 0.5274 - val_accuracy: 0.7663\n",
      "Epoch 923/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7777 - val_loss: 0.5269 - val_accuracy: 0.7613\n",
      "Epoch 924/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7777 - val_loss: 0.5318 - val_accuracy: 0.7563\n",
      "Epoch 925/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7727 - val_loss: 0.5257 - val_accuracy: 0.7714\n",
      "Epoch 926/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7768 - val_loss: 0.5260 - val_accuracy: 0.7714\n",
      "Epoch 927/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7693 - val_loss: 0.5501 - val_accuracy: 0.7236\n",
      "Epoch 928/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7777 - val_loss: 0.5261 - val_accuracy: 0.7638\n",
      "Epoch 929/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7785 - val_loss: 0.5269 - val_accuracy: 0.7663\n",
      "Epoch 930/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7760 - val_loss: 0.5291 - val_accuracy: 0.7613\n",
      "Epoch 931/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7785 - val_loss: 0.5259 - val_accuracy: 0.7638\n",
      "Epoch 932/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7760 - val_loss: 0.5258 - val_accuracy: 0.7663\n",
      "Epoch 933/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7768 - val_loss: 0.5278 - val_accuracy: 0.7688\n",
      "Epoch 934/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7710 - val_loss: 0.5265 - val_accuracy: 0.7638\n",
      "Epoch 935/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7785 - val_loss: 0.5580 - val_accuracy: 0.7538\n",
      "Epoch 936/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7752 - val_loss: 0.5375 - val_accuracy: 0.7714\n",
      "Epoch 937/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7777 - val_loss: 0.5460 - val_accuracy: 0.7688\n",
      "Epoch 938/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7718 - val_loss: 0.5270 - val_accuracy: 0.7613\n",
      "Epoch 939/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7743 - val_loss: 0.5297 - val_accuracy: 0.7638\n",
      "Epoch 940/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7752 - val_loss: 0.5374 - val_accuracy: 0.7714\n",
      "Epoch 941/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7735 - val_loss: 0.5257 - val_accuracy: 0.7714\n",
      "Epoch 942/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7777 - val_loss: 0.5280 - val_accuracy: 0.7613\n",
      "Epoch 943/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7760 - val_loss: 0.5259 - val_accuracy: 0.7714\n",
      "Epoch 944/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7785 - val_loss: 0.5331 - val_accuracy: 0.7663\n",
      "Epoch 945/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7785 - val_loss: 0.5279 - val_accuracy: 0.7688\n",
      "Epoch 946/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7727 - val_loss: 0.5255 - val_accuracy: 0.7714\n",
      "Epoch 947/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7768 - val_loss: 0.5326 - val_accuracy: 0.7638\n",
      "Epoch 948/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7768 - val_loss: 0.5577 - val_accuracy: 0.7513\n",
      "Epoch 949/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7802 - val_loss: 0.5254 - val_accuracy: 0.7714\n",
      "Epoch 950/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7768 - val_loss: 0.5257 - val_accuracy: 0.7714\n",
      "Epoch 951/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7810 - val_loss: 0.5492 - val_accuracy: 0.7312\n",
      "Epoch 952/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7668 - val_loss: 0.5267 - val_accuracy: 0.7613\n",
      "Epoch 953/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7768 - val_loss: 0.5449 - val_accuracy: 0.7688\n",
      "Epoch 954/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7794 - val_loss: 0.5475 - val_accuracy: 0.7638\n",
      "Epoch 955/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7777 - val_loss: 0.5332 - val_accuracy: 0.7663\n",
      "Epoch 956/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7743 - val_loss: 0.5255 - val_accuracy: 0.7613\n",
      "Epoch 957/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7727 - val_loss: 0.5302 - val_accuracy: 0.7638\n",
      "Epoch 958/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7743 - val_loss: 0.5316 - val_accuracy: 0.7638\n",
      "Epoch 959/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7752 - val_loss: 0.5402 - val_accuracy: 0.7714\n",
      "Epoch 960/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7836 - val_loss: 0.5254 - val_accuracy: 0.7714\n",
      "Epoch 961/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7785 - val_loss: 0.5373 - val_accuracy: 0.7487\n",
      "Epoch 962/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7768 - val_loss: 0.5252 - val_accuracy: 0.7714\n",
      "Epoch 963/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7718 - val_loss: 0.5266 - val_accuracy: 0.7663\n",
      "Epoch 964/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7710 - val_loss: 0.5499 - val_accuracy: 0.7236\n",
      "Epoch 965/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7718 - val_loss: 0.5263 - val_accuracy: 0.7663\n",
      "Epoch 966/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7735 - val_loss: 0.5345 - val_accuracy: 0.7688\n",
      "Epoch 967/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7768 - val_loss: 0.5364 - val_accuracy: 0.7714\n",
      "Epoch 968/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7668 - val_loss: 0.5674 - val_accuracy: 0.7487\n",
      "Epoch 969/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7752 - val_loss: 0.5266 - val_accuracy: 0.7613\n",
      "Epoch 970/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7794 - val_loss: 0.5274 - val_accuracy: 0.7613\n",
      "Epoch 971/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7760 - val_loss: 0.5353 - val_accuracy: 0.7688\n",
      "Epoch 972/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7727 - val_loss: 0.5454 - val_accuracy: 0.7638\n",
      "Epoch 973/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7827 - val_loss: 0.5295 - val_accuracy: 0.7638\n",
      "Epoch 974/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7819 - val_loss: 0.5251 - val_accuracy: 0.7714\n",
      "Epoch 975/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7768 - val_loss: 0.5326 - val_accuracy: 0.7663\n",
      "Epoch 976/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7794 - val_loss: 0.5501 - val_accuracy: 0.7236\n",
      "Epoch 977/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7727 - val_loss: 0.5251 - val_accuracy: 0.7714\n",
      "Epoch 978/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7785 - val_loss: 0.5260 - val_accuracy: 0.7613\n",
      "Epoch 979/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7743 - val_loss: 0.5256 - val_accuracy: 0.7638\n",
      "Epoch 980/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7727 - val_loss: 0.5380 - val_accuracy: 0.7487\n",
      "Epoch 981/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7768 - val_loss: 0.5295 - val_accuracy: 0.7688\n",
      "Epoch 982/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7794 - val_loss: 0.5248 - val_accuracy: 0.7714\n",
      "Epoch 983/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7768 - val_loss: 0.5302 - val_accuracy: 0.7638\n",
      "Epoch 984/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7718 - val_loss: 0.5414 - val_accuracy: 0.7714\n",
      "Epoch 985/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7727 - val_loss: 0.5329 - val_accuracy: 0.7487\n",
      "Epoch 986/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7794 - val_loss: 0.5364 - val_accuracy: 0.7714\n",
      "Epoch 987/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7777 - val_loss: 0.5370 - val_accuracy: 0.7714\n",
      "Epoch 988/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7743 - val_loss: 0.5383 - val_accuracy: 0.7714\n",
      "Epoch 989/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7743 - val_loss: 0.5386 - val_accuracy: 0.7714\n",
      "Epoch 990/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7760 - val_loss: 0.5249 - val_accuracy: 0.7714\n",
      "Epoch 991/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7785 - val_loss: 0.5310 - val_accuracy: 0.7563\n",
      "Epoch 992/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7802 - val_loss: 0.5297 - val_accuracy: 0.7663\n",
      "Epoch 993/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7685 - val_loss: 0.5248 - val_accuracy: 0.7638\n",
      "Epoch 994/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7760 - val_loss: 0.5302 - val_accuracy: 0.7638\n",
      "Epoch 995/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7760 - val_loss: 0.5403 - val_accuracy: 0.7462\n",
      "Epoch 996/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7735 - val_loss: 0.5337 - val_accuracy: 0.7688\n",
      "Epoch 997/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7802 - val_loss: 0.5544 - val_accuracy: 0.7588\n",
      "Epoch 998/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7768 - val_loss: 0.5562 - val_accuracy: 0.7513\n",
      "Epoch 999/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7768 - val_loss: 0.5268 - val_accuracy: 0.7613\n",
      "Epoch 1000/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7735 - val_loss: 0.5426 - val_accuracy: 0.7688\n"
     ]
    }
   ],
   "source": [
    "history = model_3.fit(X_train,y_train, validation_data=(X_valid, y_valid), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5372ab8d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'ro', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4b7c62",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39f0eb08",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5211468935012817, 'accuracy': 0.7793624401092529}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(X_train, y_train, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66dfd4e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5239536166191101, 'accuracy': 0.7713567614555359}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(X_valid, y_valid, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1054301",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "179a534c",
   "metadata": {},
   "source": [
    "# Evaluate and apply to test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1bfc65",
   "metadata": {},
   "source": [
    "[Loss](https://www.analyticsvidhya.com/blog/2022/06/understanding-loss-function-in-deep-learning/)\n",
    "\n",
    "[Accuracy and other metrics](https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234)\n",
    "\n",
    "[Confusion matrices](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ae8130e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5225900411605835, 'accuracy': 0.7688442468643188}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(X_valid, y_valid, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "81e9985d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.8090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5084015130996704, 'accuracy': 0.8090452551841736}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(X_valid, y_valid, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0ce35d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5425947308540344, 'accuracy': 0.7688442468643188}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(X_valid, y_valid, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6d1e718d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step\n",
      "Accuracy:  TravelInsurance_0    0.808564\n",
      "TravelInsurance_1    0.808564\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[240,  11],\n",
       "       [ 65,  81]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = np.round(model_2.predict(X_test),0)\n",
    "errors = y_test != test_predictions\n",
    "correct = y_test == test_predictions\n",
    "print(\"Accuracy: \", np.sum(correct)/len(y_test))\n",
    "confusion_matrix(y_test.values.argmax(axis = 1),test_predictions.argmax(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48963ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
