{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive statistics in *pandas*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook you will see examples of a range of basic statistics available in *pandas*.\n",
    "\n",
    "We can only really scratch the surface of what is available in *pandas*  and other libraries that have extended the range of *pandas* facilities.  After all, *pandas* was intended to be a data analysis toolset - so having a rich collection of statistical analysis tools and packages should not be surprising.\n",
    "\n",
    "There are two types of statistical functions we'll cover - the aggregate (where a set is summarised with a single value) and the additive (where the set size is retained, with values changed or augmented by additional values).\n",
    "\n",
    "Aggregate functions include:\n",
    "- `count`\t...  Number of non-null observations\n",
    "- `sum`\t...  Sum of values\n",
    "- `mean`\t...  Mean of values\n",
    "- `mad`\t...  Mean absolute deviation\n",
    "- `median` ... Arithmetic median of values\n",
    "- `min`\t...  Minimum\n",
    "- `max`\t...  Maximum\n",
    "- `mode`\t...  Mode (most frequent)\n",
    "- `abs`\t...  Absolute value\n",
    "- `prod`\t...  Product of values\n",
    "- `std`\t...  Unbiased standard deviation\n",
    "- `var`\t...  Unbiased variance\n",
    "- `sem`\t...  Unbiased standard error of the mean\n",
    "- `quantile` ...  Sample quantile (value at %)\n",
    "\n",
    "Additive functions include:\n",
    "- `cumsum`  ...\tCumulative sum\n",
    "- `cumprod` ...\tCumulative product\n",
    "- `cummax`  ...\tCumulative maximum\n",
    "- `cummin`  ...\tCumulative minimum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data samples to use as examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to need a range of data samples to use throughout this Notebook, so we'll set them up in the following cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A numeric series.\n",
    "aseries = pd.Series([1, 2, 4, 5, 1, -4, 2, 8])\n",
    "\n",
    "# A numeric series with at least one NaN.\n",
    "aseriesnan = pd.Series([30, 42, 24, 75, 82, np.nan, 20, 34])\n",
    "\n",
    "# A non-numeric series.\n",
    "nonnumeric_series = pd.Series(['Andy', 'Arnold', 'Bill', 'Anne', 'Xavier',\n",
    "                               'Walter', 'Angelina', 'Anne'])     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A DataFrame with two numeric columns.\n",
    "adf = pd.DataFrame({'size': [1, 2, 4, 5, 1, 4, 2, 8],\n",
    "                    'cost': [30, 42, 24, 75, 82, 50, 20, 34]})\n",
    "\n",
    "# A DataFrame with two numeric columns, one with at least one NaN.\n",
    "adfnan = pd.DataFrame({'size': [1, 2, 4, 5, 1, 4, 2, 8],\n",
    "                       'cost': [30, 42, 24, 75, 82, np.nan, 20, 34]})\n",
    "\n",
    "# A DataFrame with a non-numeric column.\n",
    "adfnonnumeric = pd.DataFrame({'size': [1, 2, 4, 5, 1, 4, 2, 8],\n",
    "                              'cost': [30, 42, 24, 75, 82, np.nan, 20, 34],\n",
    "                              'owner': ['Bill', 'Arnold', 'Bill', 'Ann', 'Xavier',\n",
    "                                        'Walter', 'Bill', 'Anne']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate functions\n",
    "The aggregate functions will be applied to the column of a `Series` if it is compatible with the data type of the series values,  and will be applied to all the compatible columns of a `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing the values in a Series.\n",
    "print(aseries.sum())\n",
    "print(aseriesnan.sum())\n",
    "print(nonnumeric_series.sum())\n",
    "\n",
    "# Note, it is always checking how functions behave in the presence of NaNs and unusual types.  \n",
    "# The output of the sum applied to the nonnumeric_series was a little unexpected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfnonnumeric.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the aggregate function can be applied to the type of values in a column, then it will be.\n",
    "\n",
    "So, `max` can be applied as a numeric or string maximum depending on the type of values in the set.  \n",
    "\n",
    "(Also, in a set with mixed types of values in a column there are ways to make the aggregate functions only 'see' specific types of value within the data, but we don't cover them in this module.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfnonnumeric.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Aggregation by row or by column in a `DataFrame`\n",
    "In a `DataFrame` you can choose to apply the function along the columns or along the rows by specifying the `axis` value. The default is `axis=0` meaning apply to columns, but you can set `axis=1` to apply to rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Include or exclude NaNs\n",
    "By default any `NaN`s encountered are ignored, but if they are important they can be included in the aggregation by setting `skipna=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.sum(skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfnan.sum(skipna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Locating the min or max in a Series or DataFrame\n",
    "It is sometimes useful to know the index label for the minimum or maximum value in a Series or DataFrame.\n",
    "\n",
    "The `idxmin()` and `idxmax()` functions on Series and DataFrame compute the index labels with the minimum and maximum corresponding values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aseries.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.idxmin(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfnan.idxmin(axis=1, skipna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there are multiple rows (or columns) matching the minimum or maximum value, `idxmin()` and `idxmax()` return the **first** matching index  _(it also works where we supply names for the index labels, overriding the default index numbering)_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create a DataFrame with five values in a single column,\n",
    "# the row index values are e d c b a.\n",
    "df2 = pd.DataFrame([2, 1, 1, 3, np.nan], columns=['A'], index=list('edcba'))\n",
    "df2['A'].idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The additive functions\n",
    "With these functions, the dataset is treated one row at a time, in sequence - so the order of the elements in the dataset will make a difference to the output of the function.   The examples we will look at are the cumulative functions in which each value is dependent on the rows that come before that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'The series': aseries, 'The cumulative sum': aseries.cumsum(), \n",
    "              'The cumulative max': aseries.cummax(), 'The cumulative min': aseries.cummin()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulative functions preserve the location of the `NaN`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfnonnumeric.cummax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick collection of descriptive stats\n",
    "Sometimes it's useful just to get a quick impression of a dataset.\n",
    "\n",
    "The `describe()` method throws a handful of useful functions at a dataset all in one method.\n",
    "\n",
    "*Warning* `describe()` skips `NaN`s - this cannot be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aseriesnan.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When applied to non-numeric Series we get a different collection of functions applied:\n",
    "a simple summary of the count of the elements, the number of unique values, the most frequently occurring value and its frequency of occurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonnumeric_series.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Warning*: simply applying `describe()` to a mixed DataFrame will generate statistics for each *numeric* column: it will ignore the non-numeric columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfnonnumeric.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, adding `include='all'` will retain each column from the original and apply the required functions to each.   \n",
    "\n",
    "(The `include` value can be a list of `dtypes` to include, and you can have an `exclude` parameter giving dtypes to exclude from the result.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfnonnumeric.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you wondering about those rows with a percentage index label?  They represent the 25, 50 and 75 percentile values - that is the value at which 25% of the dataset have values below this value (or 50% or 75%).\n",
    "\n",
    "So, in the above result 50% of the values in the `cost` column are below 34.\n",
    "\n",
    "It is possible to supply `describe()` with a list of the percentile values (between 0.0 and 1.0) you want displayed (note that you always seem to get the 50 percentile value):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aseries.describe(percentiles=[.05, .25, .75, .95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.describe(percentiles=[.05, .25, .75, .95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What next\n",
    "\n",
    "If you are working through this Notebook as part of the module activities, return to the module materials now.\n",
    "\n",
    "If you are working through this set of Notebooks as a whole, move on to `04.3 Simple visualisations in pandas`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
